---
title: 5 How to do feature selection using recursive feature elimination
author: ZERO
date: '2018-03-28'
slug: 5-how-to-do-feature-selection-using-recursive-feature-elimination
categories:
  - machine learning
tags:
  - caret
thumbnailImagePosition: left
thumbnailImage: https://i.loli.net/2018/03/28/5abaee8867c4c.jpg
metaAlignment: center
coverMeta: out
---



<p>You might need <em>a rigorous way to determine the important variables</em> first before feeding them to the ML algorithm. This is important.</p>
<p>A good choice of selecting the important features is the <em>recursive feature elimination (RFE)</em></p>
<p>RFE works in 3 broad steps:</p>
<p>Step 1: Build a ML model on a training dataset and estimate the feature importances on the test dataset.（在确定自由度的情况下，评价变量在测试数据集中的重要性）</p>
<p>Step 2: Keeping priority to the most important variables, iterate through by building models of given sizes. Ranking of the predictors is recalculated in each iteration.（把刚才的过程在不同的自由度下迭代执行）</p>
<p>Step 3: The model performances are compared across different subset sizes to arrive at the optimal number and list of final predictors.（比较不同自由度的测试错误率，给出最佳自由度模型选择）</p>
<div id="load-package-and-data" class="section level1">
<h1>Load Package And Data</h1>
<pre class="r"><code>load(&quot;../../data/craet_4.Rdata&quot;)
library(tidyverse)
library(caret)</code></pre>
</div>
<div id="feature-select" class="section level1">
<h1>Feature select</h1>
<pre class="r"><code>set.seed(100)
options(warn=-1)

subsets &lt;- c(1:5, 10, 15, 18)

#Step 1: Build a ML model on a training dataset and estimate the feature importances on the test dataset.（在确定自由度的情况下，评价变量在测试数据集中的重要性）
ctrl &lt;- rfeControl(functions = rfFuncs,
                   method = &quot;repeatedcv&quot;,
                   repeats = 5,
                   verbose = FALSE)
#Step 2: Keeping priority to the most important variables, iterate through by building models of given sizes. Ranking of the predictors is recalculated in each iteration.（把刚才的过程在不同的自由度下迭代执行
lmProfile &lt;- rfe(x=trainData[, 1:18], y=trainData$Purchase,
                 sizes = subsets,
                 rfeControl = ctrl)

#Step 3: The model performances are compared across different subset sizes to arrive at the optimal number and list of final predictors.（比较不同自由度的测试错误率，给出最佳自由度模型选择
lmProfile</code></pre>
<pre><code>## 
## Recursive feature selection
## 
## Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 
## 
## Resampling performance over subset size:
## 
##  Variables Accuracy  Kappa AccuracySD KappaSD Selected
##          1   0.7433 0.4554    0.04107 0.08692         
##          2   0.8143 0.6063    0.04037 0.08559         
##          3   0.8187 0.6147    0.04194 0.08896        *
##          4   0.8058 0.5904    0.04253 0.08750         
##          5   0.7988 0.5743    0.04379 0.09258         
##         10   0.8024 0.5810    0.04464 0.09557         
##         15   0.8070 0.5879    0.04215 0.09079         
##         18   0.8065 0.5879    0.03882 0.08297         
## 
## The top 3 variables (out of 3):
##    LoyalCH, PriceDiff, StoreID</code></pre>
<div id="input" class="section level2">
<h2>input</h2>
<ul>
<li><p>Size: sizes determines what all model sizes (the number of most important features) the rfe should consider</p></li>
<li>rfeControl():
<ul>
<li>what type of algorithm should be used <em>rfFuncs:: random forest based</em></li>
<li>what cross validation method should be used.
<ul>
<li>cross validation method is <em>repeatedcv</em></li>
<li>which implements k-Fold cross validation repeated 5 times</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="output" class="section level2">
<h2>output</h2>
<p>The Output Shows: - accuracy<br />
- kappa (and their standard deviation) for the different model sizes we provided - The final selected model subset size is marked with a * in the rightmost Selected column.</p>
<pre class="r"><code>save.image(&quot;../../data/craet_5.Rdata&quot;)
sessionInfo()</code></pre>
<pre><code>## R version 3.4.3 (2017-11-30)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Sierra 10.12.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] methods   stats     graphics  grDevices utils     datasets  base     
## 
## other attached packages:
##  [1] caret_6.0-78    lattice_0.20-35 forcats_0.3.0   stringr_1.3.0  
##  [5] dplyr_0.7.4     purrr_0.2.4     readr_1.1.1     tidyr_0.8.0    
##  [9] tibble_1.4.2    ggplot2_2.2.1   tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##  [1] httr_1.3.1          ddalpha_1.3.1.1     sfsmisc_1.1-2      
##  [4] jsonlite_1.5        splines_3.4.3       foreach_1.4.4      
##  [7] prodlim_1.6.1       modelr_0.1.1        assertthat_0.2.0   
## [10] stats4_3.4.3        DRR_0.0.3           cellranger_1.1.0   
## [13] yaml_2.1.18         robustbase_0.92-8   ipred_0.9-6        
## [16] pillar_1.2.1        backports_1.1.2     glue_1.2.0         
## [19] digest_0.6.15       randomForest_4.6-12 rvest_0.3.2        
## [22] colorspace_1.3-2    recipes_0.1.2       htmltools_0.3.6    
## [25] Matrix_1.2-12       plyr_1.8.4          psych_1.7.8        
## [28] timeDate_3043.102   pkgconfig_2.0.1     CVST_0.2-1         
## [31] broom_0.4.3         haven_1.1.1         bookdown_0.7       
## [34] scales_0.5.0.9000   gower_0.1.2         lava_1.6           
## [37] withr_2.1.1.9000    nnet_7.3-12         lazyeval_0.2.1     
## [40] cli_1.0.0           mnormt_1.5-5        survival_2.41-3    
## [43] magrittr_1.5        crayon_1.3.4        readxl_1.0.0       
## [46] evaluate_0.10.1     nlme_3.1-131.1      MASS_7.3-49        
## [49] xml2_1.2.0          dimRed_0.1.0        foreign_0.8-69     
## [52] class_7.3-14        blogdown_0.5        tools_3.4.3        
## [55] hms_0.4.2           kernlab_0.9-25      munsell_0.4.3      
## [58] bindrcpp_0.2        e1071_1.6-8         compiler_3.4.3     
## [61] RcppRoll_0.2.2      rlang_0.2.0.9000    grid_3.4.3         
## [64] iterators_1.0.9     rmarkdown_1.9       gtable_0.2.0       
## [67] ModelMetrics_1.1.0  codetools_0.2-15    reshape2_1.4.3     
## [70] R6_2.2.2            lubridate_1.7.3     knitr_1.20         
## [73] bindr_0.1.1         rprojroot_1.3-2     stringi_1.1.7      
## [76] parallel_3.4.3      Rcpp_0.12.16        rpart_4.1-13       
## [79] tidyselect_0.2.4    DEoptimR_1.0-8      xfun_0.1</code></pre>
</div>
<div id="reference" class="section level2">
<h2><strong>Reference</strong></h2>
<ul>
<li><a href="https://www.machinelearningplus.com/caret-package/">How to do feature selection using recursive feature elimination (rfe)?</a></li>
</ul>
</div>
</div>
