---
title: NLP part 03 sentiment analysis
author: ZERO
date: '2018-09-17'
slug: nlp-part-03-sentiment-analysis
categories:
  - machine learning
tags:
  - NLP
keywords:
  - tech
thumbnailImagePosition: left
thumbnailImage: https://i.loli.net/2018/08/13/5b70bd4dc9763.jpg
metaAlignment: center
coverMeta: out
---



<!--more-->
<div id="case-study-sentiment-analysis" class="section level1">
<h1>Case Study: Sentiment Analysis</h1>
<div id="data-prep" class="section level3">
<h3>Data Prep</h3>
<pre class="python"><code>import pandas as pd
import numpy as np

# Read in the data
df = pd.read_csv(&#39;/Users/zero/Desktop/NLP/raw-data/Amazon_Unlocked_Mobile.csv&#39;)

# ÂØπÊï∞ÊçÆËøõË°åÈááÊ†∑‰ª•Âä†Âø´ËÆ°ÁÆóÈÄüÂ∫¶
# Comment out this line to match with lecture
df = df.sample(frac=0.1, random_state=10)

df.head()</code></pre>
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
<thead>
<pre><code>&lt;tr style=&quot;text-align: right;&quot;&gt;
  &lt;th&gt;&lt;/th&gt;
  &lt;th&gt;Product Name&lt;/th&gt;
  &lt;th&gt;Brand Name&lt;/th&gt;
  &lt;th&gt;Price&lt;/th&gt;
  &lt;th&gt;Rating&lt;/th&gt;
  &lt;th&gt;Reviews&lt;/th&gt;
  &lt;th&gt;Review Votes&lt;/th&gt;
&lt;/tr&gt;</code></pre>
</thead>
<tbody>
<pre><code>&lt;tr&gt;
  &lt;th&gt;394349&lt;/th&gt;
  &lt;td&gt;Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat...&lt;/td&gt;
  &lt;td&gt;NaN&lt;/td&gt;
  &lt;td&gt;244.95&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;Very good one! Better than Samsung S and iphon...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;34377&lt;/th&gt;
  &lt;td&gt;Apple iPhone 5c 8GB (Pink) - Verizon Wireless&lt;/td&gt;
  &lt;td&gt;Apple&lt;/td&gt;
  &lt;td&gt;194.99&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
  &lt;td&gt;The phone needed a SIM card, would have been n...&lt;/td&gt;
  &lt;td&gt;1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;248521&lt;/th&gt;
  &lt;td&gt;Motorola Droid RAZR MAXX XT912 M Verizon Smart...&lt;/td&gt;
  &lt;td&gt;Motorola&lt;/td&gt;
  &lt;td&gt;174.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I was 3 months away from my upgrade and my Str...&lt;/td&gt;
  &lt;td&gt;3.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;167661&lt;/th&gt;
  &lt;td&gt;CNPGD [U.S. Office Extended Warranty] Smartwat...&lt;/td&gt;
  &lt;td&gt;CNPGD&lt;/td&gt;
  &lt;td&gt;49.99&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
  &lt;td&gt;an experience i want to forget&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;73287&lt;/th&gt;
  &lt;td&gt;Apple iPhone 7 Unlocked Phone 256 GB - US Vers...&lt;/td&gt;
  &lt;td&gt;Apple&lt;/td&gt;
  &lt;td&gt;922.00&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;GREAT PHONE WORK ACCORDING MY EXPECTATIONS.&lt;/td&gt;
  &lt;td&gt;1.0&lt;/td&gt;
&lt;/tr&gt;</code></pre>
</tbody>
</table>
</div>
<pre class="python"><code>np.where(df[&#39;Rating&#39;] &gt; 3, 1, 0)</code></pre>
<pre><code>array([1, 0, 1, ..., 1, 0, 0])</code></pre>
<pre class="python"><code># Drop missing values
df.dropna(inplace=True)

# Remove any &#39;neutral&#39; ratings equal to 3
# filter rows
df = df[df[&#39;Rating&#39;] != 3]

# Encode 4s and 5s as 1 (rated positively)
# Encode 1s and 2s as 0 (rated poorly)
# class labels
df[&#39;Positively Rated&#39;] = np.where(df[&#39;Rating&#39;] &gt; 3, 1, 0)
df.head(10)</code></pre>
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
<thead>
<pre><code>&lt;tr style=&quot;text-align: right;&quot;&gt;
  &lt;th&gt;&lt;/th&gt;
  &lt;th&gt;Product Name&lt;/th&gt;
  &lt;th&gt;Brand Name&lt;/th&gt;
  &lt;th&gt;Price&lt;/th&gt;
  &lt;th&gt;Rating&lt;/th&gt;
  &lt;th&gt;Reviews&lt;/th&gt;
  &lt;th&gt;Review Votes&lt;/th&gt;
  &lt;th&gt;Positively Rated&lt;/th&gt;
&lt;/tr&gt;</code></pre>
</thead>
<tbody>
<pre><code>&lt;tr&gt;
  &lt;th&gt;34377&lt;/th&gt;
  &lt;td&gt;Apple iPhone 5c 8GB (Pink) - Verizon Wireless&lt;/td&gt;
  &lt;td&gt;Apple&lt;/td&gt;
  &lt;td&gt;194.99&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
  &lt;td&gt;The phone needed a SIM card, would have been n...&lt;/td&gt;
  &lt;td&gt;1.0&lt;/td&gt;
  &lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;248521&lt;/th&gt;
  &lt;td&gt;Motorola Droid RAZR MAXX XT912 M Verizon Smart...&lt;/td&gt;
  &lt;td&gt;Motorola&lt;/td&gt;
  &lt;td&gt;174.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I was 3 months away from my upgrade and my Str...&lt;/td&gt;
  &lt;td&gt;3.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;167661&lt;/th&gt;
  &lt;td&gt;CNPGD [U.S. Office Extended Warranty] Smartwat...&lt;/td&gt;
  &lt;td&gt;CNPGD&lt;/td&gt;
  &lt;td&gt;49.99&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
  &lt;td&gt;an experience i want to forget&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;73287&lt;/th&gt;
  &lt;td&gt;Apple iPhone 7 Unlocked Phone 256 GB - US Vers...&lt;/td&gt;
  &lt;td&gt;Apple&lt;/td&gt;
  &lt;td&gt;922.00&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;GREAT PHONE WORK ACCORDING MY EXPECTATIONS.&lt;/td&gt;
  &lt;td&gt;1.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;277158&lt;/th&gt;
  &lt;td&gt;Nokia N8 Unlocked GSM Touch Screen Phone Featu...&lt;/td&gt;
  &lt;td&gt;Nokia&lt;/td&gt;
  &lt;td&gt;95.00&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I fell in love with this phone because it did ...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;100311&lt;/th&gt;
  &lt;td&gt;Blackberry Torch 2 9810 Unlocked Phone with 1....&lt;/td&gt;
  &lt;td&gt;BlackBerry&lt;/td&gt;
  &lt;td&gt;77.49&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I am pleased with this Blackberry phone! The p...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;251669&lt;/th&gt;
  &lt;td&gt;Motorola Moto E (1st Generation) - Black - 4 G...&lt;/td&gt;
  &lt;td&gt;Motorola&lt;/td&gt;
  &lt;td&gt;89.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;Great product, best value for money smartphone...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;279878&lt;/th&gt;
  &lt;td&gt;OtterBox 77-29864 Defender Series Hybrid Case ...&lt;/td&gt;
  &lt;td&gt;OtterBox&lt;/td&gt;
  &lt;td&gt;9.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I&#39;ve bought 3 no problems. Fast delivery.&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;406017&lt;/th&gt;
  &lt;td&gt;Verizon HTC Rezound 4G Android Smarphone - 8MP...&lt;/td&gt;
  &lt;td&gt;HTC&lt;/td&gt;
  &lt;td&gt;74.99&lt;/td&gt;
  &lt;td&gt;4&lt;/td&gt;
  &lt;td&gt;Great phone for the price...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;302567&lt;/th&gt;
  &lt;td&gt;RCA M1 Unlocked Cell Phone, Dual Sim, 5Mp Came...&lt;/td&gt;
  &lt;td&gt;RCA&lt;/td&gt;
  &lt;td&gt;159.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;My mom is not good with new technoloy but this...&lt;/td&gt;
  &lt;td&gt;4.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;</code></pre>
</tbody>
</table>
</div>
<pre class="python"><code># Most ratings are positive
# More than 50% is positive
df[&#39;Positively Rated&#39;].mean()</code></pre>
<pre><code>0.7471776686078667</code></pre>
<pre class="python"><code>from sklearn.model_selection import train_test_split

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(df[&#39;Reviews&#39;], 
                                                    df[&#39;Positively Rated&#39;], 
                                                    random_state=0)</code></pre>
<pre class="python"><code>print(&#39;X_train first entry:\n\n&#39;, X_train.iloc[0])
print(&#39;\n\nX_train shape: &#39;, X_train.shape)</code></pre>
<pre><code>X_train first entry:

 Everything about it is awesome!


X_train shape:  (23052,)</code></pre>
</div>
</div>
<div id="countvectorizer" class="section level1">
<h1>CountVectorizer</h1>
<p>Construct a sparse matrix</p>
<pre class="python"><code>from sklearn.feature_extraction.text import CountVectorizer

# Fit the CountVectorizer to the training data
# init countvertoizer
init_countVectorizer = CountVectorizer()
# and then fit it
vect = init_countVectorizer.fit(X_train)</code></pre>
<pre class="python"><code># step is 2000
#sparse matrix
vect.get_feature_names()[::2000]</code></pre>
<pre><code>[&#39;00&#39;,
 &#39;arroja&#39;,
 &#39;comapa√±ias&#39;,
 &#39;dvds&#39;,
 &#39;golden&#39;,
 &#39;lands&#39;,
 &#39;oil&#39;,
 &#39;razonable&#39;,
 &#39;smallsliver&#39;,
 &#39;tweak&#39;]</code></pre>
<pre class="python"><code>len(vect.get_feature_names())</code></pre>
<pre><code>19601</code></pre>
<pre class="python"><code>19601/2000</code></pre>
<pre><code>9.8005</code></pre>
<pre class="python"><code># transform the documents in the training data to a document-term matrix
X_train_vectorized = vect.transform(X_train)

X_train_vectorized</code></pre>
<pre><code>&lt;23052x19601 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;
    with 613289 stored elements in Compressed Sparse Row format&gt;</code></pre>
<pre class="python"><code>print(type(X_train_vectorized)) </code></pre>
<pre><code>&lt;class &#39;scipy.sparse.csr.csr_matrix&#39;&gt;</code></pre>
<pre class="python"><code>from sklearn.linear_model import LogisticRegression

# Train the model
model = LogisticRegression()
model.fit(X_train_vectorized, y_train)</code></pre>
<pre><code>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,
          penalty=&#39;l2&#39;, random_state=None, solver=&#39;liblinear&#39;, tol=0.0001,
          verbose=0, warm_start=False)</code></pre>
<pre class="python"><code>from sklearn.metrics import roc_auc_score

# Predict the transformed test documents
predictions = model.predict(vect.transform(X_test))

print(&#39;AUC: &#39;, roc_auc_score(y_test, predictions))</code></pre>
<pre><code>AUC:  0.897433277667</code></pre>
<pre class="python"><code># get the feature names as numpy array
feature_names = np.array(vect.get_feature_names())

# Sort the coefficients from the model
sorted_coef_index = model.coef_[0].argsort()

# Find the 10 smallest and 10 largest coefficients
# The 10 largest coefficients are being indexed using [:-11:-1] 
# so the list returned is in order of largest to smallest
print(&#39;Smallest Coefs:\n{}\n&#39;.format(feature_names[sorted_coef_index[:10]]))
print(&#39;Largest Coefs: \n{}&#39;.format(feature_names[sorted_coef_index[:-11:-1]]))</code></pre>
<pre><code>Smallest Coefs:
[&#39;worst&#39; &#39;terrible&#39; &#39;slow&#39; &#39;junk&#39; &#39;poor&#39; &#39;sucks&#39; &#39;horrible&#39; &#39;useless&#39;
 &#39;waste&#39; &#39;disappointed&#39;]

Largest Coefs: 
[&#39;excelent&#39; &#39;excelente&#39; &#39;excellent&#39; &#39;perfectly&#39; &#39;love&#39; &#39;perfect&#39; &#39;exactly&#39;
 &#39;great&#39; &#39;best&#39; &#39;awesome&#39;]</code></pre>
</div>
<div id="tfidf" class="section level1">
<h1>Tfidf</h1>
<p>üî• feature: limit frequency threshold</p>
<pre class="python"><code>from sklearn.feature_extraction.text import TfidfVectorizer

# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5
vect = TfidfVectorizer(min_df=5).fit(X_train)
len(vect.get_feature_names())</code></pre>
<pre><code>5442</code></pre>
<pre class="python"><code>X_train_vectorized = vect.transform(X_train)

model = LogisticRegression()
model.fit(X_train_vectorized, y_train)

predictions = model.predict(vect.transform(X_test))

print(&#39;AUC: &#39;, roc_auc_score(y_test, predictions))</code></pre>
<pre><code>AUC:  0.889951006492</code></pre>
<pre class="python"><code>feature_names = np.array(vect.get_feature_names())

sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()

print(&#39;Smallest tfidf:\n{}\n&#39;.format(feature_names[sorted_tfidf_index[:10]]))
print(&#39;Largest tfidf: \n{}&#39;.format(feature_names[sorted_tfidf_index[:-11:-1]]))</code></pre>
<pre><code>Smallest tfidf:
[&#39;61&#39; &#39;printer&#39; &#39;approach&#39; &#39;adjustment&#39; &#39;consequences&#39; &#39;length&#39; &#39;emailing&#39;
 &#39;degrees&#39; &#39;handsfree&#39; &#39;chipset&#39;]

Largest tfidf: 
[&#39;unlocked&#39; &#39;handy&#39; &#39;useless&#39; &#39;cheat&#39; &#39;up&#39; &#39;original&#39; &#39;exelent&#39; &#39;exelente&#39;
 &#39;exellent&#39; &#39;satisfied&#39;]</code></pre>
<pre class="python"><code>sorted_coef_index = model.coef_[0].argsort()

print(&#39;Smallest Coefs:\n{}\n&#39;.format(feature_names[sorted_coef_index[:10]]))
print(&#39;Largest Coefs: \n{}&#39;.format(feature_names[sorted_coef_index[:-11:-1]]))</code></pre>
<pre><code>Smallest Coefs:
[&#39;not&#39; &#39;slow&#39; &#39;disappointed&#39; &#39;worst&#39; &#39;terrible&#39; &#39;never&#39; &#39;return&#39; &#39;doesn&#39;
 &#39;horrible&#39; &#39;waste&#39;]

Largest Coefs: 
[&#39;great&#39; &#39;love&#39; &#39;excellent&#39; &#39;good&#39; &#39;best&#39; &#39;perfect&#39; &#39;price&#39; &#39;awesome&#39; &#39;far&#39;
 &#39;perfectly&#39;]</code></pre>
<pre class="python"><code>vect.transform([&#39;not an issue, phone is working&#39;,
                                    &#39;an issue, phone is not working&#39;])</code></pre>
<pre><code>&lt;2x5442 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;
    with 12 stored elements in Compressed Sparse Row format&gt;</code></pre>
<pre class="python"><code># These reviews are treated the same by our current model
print(model.predict(vect.transform([&#39;not an issue, phone is working&#39;,
                                    &#39;an issue, phone is not working&#39;])))</code></pre>
<pre><code>[0 0]</code></pre>
</div>
<div id="n-grams" class="section level1">
<h1>n-grams</h1>
<p>üî• ‚Äúback as‚Äù or ‚Äúis not‚Äù is grams</p>
<pre class="python"><code># Fit the CountVectorizer to the training data specifiying a minimum 
# document frequency of 5 and extracting 1-grams and 2-grams
# min_df
# ngram_range

vect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)

X_train_vectorized = vect.transform(X_train)

len(vect.get_feature_names())</code></pre>
<pre><code>29072</code></pre>
<pre class="python"><code>vect.get_feature_names()[3000:3010]</code></pre>
<pre><code>[&#39;back as&#39;,
 &#39;back asap&#39;,
 &#39;back because&#39;,
 &#39;back but&#39;,
 &#39;back button&#39;,
 &#39;back camera&#39;,
 &#39;back case&#39;,
 &#39;back cover&#39;,
 &#39;back for&#39;,
 &#39;back from&#39;]</code></pre>
<pre class="python"><code>model = LogisticRegression()
model.fit(X_train_vectorized, y_train)

predictions = model.predict(vect.transform(X_test))

print(&#39;AUC: &#39;, roc_auc_score(y_test, predictions))</code></pre>
<pre><code>AUC:  0.91106617946</code></pre>
<pre class="python"><code>feature_names = np.array(vect.get_feature_names())

sorted_coef_index = model.coef_[0].argsort()

print(&#39;Smallest Coefs:\n{}\n&#39;.format(feature_names[sorted_coef_index[:10]]))
print(&#39;Largest Coefs: \n{}&#39;.format(feature_names[sorted_coef_index[:-11:-1]]))</code></pre>
<pre><code>Smallest Coefs:
[&#39;no good&#39; &#39;junk&#39; &#39;poor&#39; &#39;slow&#39; &#39;worst&#39; &#39;broken&#39; &#39;not good&#39; &#39;terrible&#39;
 &#39;defective&#39; &#39;horrible&#39;]

Largest Coefs: 
[&#39;excellent&#39; &#39;excelente&#39; &#39;excelent&#39; &#39;perfect&#39; &#39;great&#39; &#39;love&#39; &#39;awesome&#39;
 &#39;no problems&#39; &#39;good&#39; &#39;best&#39;]</code></pre>
<pre class="python"><code># These reviews are now correctly identified
# why ü§î
print(model.predict(vect.transform([&#39;not an issue, phone is working&#39;,
                                    &#39;an issue, phone is not working&#39;])))</code></pre>
<pre><code>[1 0]</code></pre>
</div>
