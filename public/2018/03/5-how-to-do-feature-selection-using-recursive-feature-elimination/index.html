

  
    
  


  





  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.32.2 with theme Tranquilpeak 0.4.1-BETA">
    <title>5 How to do feature selection using recursive feature elimination</title>
    <meta name="author" content="Jixing Liu">
    <meta name="keywords" content=", R">

    <link rel="icon" href="img/R_py.png">
    

    
    <meta name="description" content="You might need a rigorous way to determine the important variables first before feeding them to the ML algorithm. This is important.
A good choice of selecting the important features is the recursive feature elimination (RFE)
RFE works in 3 broad steps:
Step 1: Build a ML model on a training dataset and estimate the feature importances on the test dataset.ï¼ˆåœ¨ç¡®å®šè‡ªç”±åº¦çš„æƒ…å†µä¸‹ï¼Œè¯„ä»·å˜é‡åœ¨æµ‹è¯•æ•°æ®é›†ä¸­çš„é‡è¦æ€§ï¼‰
Step 2: Keeping priority to the most important variables, iterate through by building models of given sizes.">
    <meta property="og:description" content="You might need a rigorous way to determine the important variables first before feeding them to the ML algorithm. This is important.
A good choice of selecting the important features is the recursive feature elimination (RFE)
RFE works in 3 broad steps:
Step 1: Build a ML model on a training dataset and estimate the feature importances on the test dataset.ï¼ˆåœ¨ç¡®å®šè‡ªç”±åº¦çš„æƒ…å†µä¸‹ï¼Œè¯„ä»·å˜é‡åœ¨æµ‹è¯•æ•°æ®é›†ä¸­çš„é‡è¦æ€§ï¼‰
Step 2: Keeping priority to the most important variables, iterate through by building models of given sizes.">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="5 How to do feature selection using recursive feature elimination">
    <meta property="og:url" content="/2018/03/5-how-to-do-feature-selection-using-recursive-feature-elimination/">
    <meta property="og:site_name" content="student zero ">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="student zero ">
    <meta name="twitter:description" content="You might need a rigorous way to determine the important variables first before feeding them to the ML algorithm. This is important.
A good choice of selecting the important features is the recursive feature elimination (RFE)
RFE works in 3 broad steps:
Step 1: Build a ML model on a training dataset and estimate the feature importances on the test dataset.ï¼ˆåœ¨ç¡®å®šè‡ªç”±åº¦çš„æƒ…å†µä¸‹ï¼Œè¯„ä»·å˜é‡åœ¨æµ‹è¯•æ•°æ®é›†ä¸­çš„é‡è¦æ€§ï¼‰
Step 2: Keeping priority to the most important variables, iterate through by building models of given sizes.">
    
      <meta name="twitter:creator" content="@studentZero475">
    
    

    
    

    
      <meta property="og:image" content="https://i.loli.net/2018/02/26/5a937bb148b02.jpg">
    

    
      <meta property="og:image" content="https://i.loli.net/2018/03/28/5abaee8867c4c.jpg">
    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-hbs5om8csx9a8yrv5hnhpi2qqdv4ykuslajwbramhqxvleqbfklxgek50hye.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <link rel="stylesheet" href="/css/monokai-sublime.css" rel="stylesheet" id="theme-stylesheet">
<script src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">student zero </a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <h1 class="sidebar-profile-title">5 How to do feature selection using recursive feature elimination</h1>
        <a href="/#about">
          <img class="sidebar-profile-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Jixing Liu</h4>
        
          <h5 class="sidebar-profile-bio">In God I trust. All others must bring data.</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives/">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories/">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags/">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://twitter.com/studentZero475">
    
      <i class="sidebar-button-icon fa fa-lg fa-twitter"></i>
      
      <span class="sidebar-button-desc">Twitter</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.r-bloggers.com/">
    
      <i class="sidebar-button-icon fa fa-lg fa-book"></i>
      
      <span class="sidebar-button-desc">R-bloggers</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      

    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaOut
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-center">
  
    <h1 class="post-title" itemprop="headline">
      5 How to do feature selection using recursive feature elimination
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-03-28T00:00:00Z">
        
  March 28, 2018

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/machine-learning">machine learning</a>
    
  


  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <p>You might need <em>a rigorous way to determine the important variables</em> first before feeding them to the ML algorithm. This is important.</p>
<p>A good choice of selecting the important features is the <em>recursive feature elimination (RFE)</em></p>
<p>RFE works in 3 broad steps:</p>
<p>Step 1: Build a ML model on a training dataset and estimate the feature importances on the test dataset.ï¼ˆåœ¨ç¡®å®šè‡ªç”±åº¦çš„æƒ…å†µä¸‹ï¼Œè¯„ä»·å˜é‡åœ¨æµ‹è¯•æ•°æ®é›†ä¸­çš„é‡è¦æ€§ï¼‰</p>
<p>Step 2: Keeping priority to the most important variables, iterate through by building models of given sizes. Ranking of the predictors is recalculated in each iteration.ï¼ˆæŠŠåˆšæ‰çš„è¿‡ç¨‹åœ¨ä¸åŒçš„è‡ªç”±åº¦ä¸‹è¿­ä»£æ‰§è¡Œï¼‰</p>
<p>Step 3: The model performances are compared across different subset sizes to arrive at the optimal number and list of final predictors.ï¼ˆæ¯”è¾ƒä¸åŒè‡ªç”±åº¦çš„æµ‹è¯•é”™è¯¯ç‡ï¼Œç»™å‡ºæœ€ä½³è‡ªç”±åº¦æ¨¡å‹é€‰æ‹©ï¼‰</p>
<div id="load-package-and-data" class="section level1">
<h1>Load Package And Data</h1>
<pre class="r"><code># Load Package And Data
load(&quot;../../data/craet_4.Rdata&quot;)
library(tidyverse)
library(caret)
#Set Parallel Processing - Decrease computation time
if (!require(&quot;doMC&quot;)) install.packages(&quot;doMC&quot;)
library(doMC)
registerDoMC(cores = 4)</code></pre>
</div>
<div id="feature-select" class="section level1">
<h1>Feature select</h1>
<pre class="r"><code>set.seed(100)
options(warn=-1)

subsets &lt;- c(1:5, 10, 15, 18)

#Step 1: Build a ML model on a training dataset and estimate the feature importances on the test dataset.ï¼ˆåœ¨ç¡®å®šè‡ªç”±åº¦çš„æƒ…å†µä¸‹ï¼Œè¯„ä»·å˜é‡åœ¨æµ‹è¯•æ•°æ®é›†ä¸­çš„é‡è¦æ€§ï¼‰
ctrl &lt;- rfeControl(functions = rfFuncs,
                   method = &quot;repeatedcv&quot;,#repeated K-fold cross-validation
                   number = 10,#10-fold cross-validations
                   repeats = 5, #five separate 10-fold cross-validations are used
                   verbose = FALSE)
#Step 2: Keeping priority to the most important variables, iterate through by building models of given sizes. Ranking of the predictors is recalculated in each iteration.ï¼ˆæŠŠåˆšæ‰çš„è¿‡ç¨‹åœ¨ä¸åŒçš„è‡ªç”±åº¦ä¸‹è¿­ä»£æ‰§è¡Œ
lmProfile &lt;- rfe(x=trainData[, 1:18], y=trainData$Purchase,
                 sizes = subsets,
                 rfeControl = ctrl)

#Step 3: The model performances are compared across different subset sizes to arrive at the optimal number and list of final predictors.ï¼ˆæ¯”è¾ƒä¸åŒè‡ªç”±åº¦çš„æµ‹è¯•é”™è¯¯ç‡ï¼Œç»™å‡ºæœ€ä½³è‡ªç”±åº¦æ¨¡å‹é€‰æ‹©
lmProfile</code></pre>
<pre><code>## 
## Recursive feature selection
## 
## Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 
## 
## Resampling performance over subset size:
## 
##  Variables Accuracy  Kappa AccuracySD KappaSD Selected
##          1   0.7442 0.4569    0.04125 0.08753         
##          2   0.8124 0.6031    0.04002 0.08505         
##          3   0.8182 0.6136    0.04170 0.08790        *
##          4   0.8047 0.5879    0.04314 0.08993         
##          5   0.8000 0.5770    0.04215 0.08861         
##         10   0.8035 0.5826    0.04112 0.08815         
##         15   0.8089 0.5918    0.04209 0.09076         
##         18   0.8084 0.5918    0.04118 0.08894         
## 
## The top 3 variables (out of 3):
##    LoyalCH, PriceDiff, StoreID</code></pre>
<div id="input" class="section level2">
<h2>input</h2>
<ul>
<li><p>Size: sizes determines what all model sizes (the number of most important features) the rfe should consider</p></li>
<li>rfeControl():
<ul>
<li>functions: what type of algorithm should be used <strong>rfFuncs:: random forest based</strong>
<ul>
<li>methods: repeated K-fold cross-validation</li>
<li>number: 10-fold cross-validations</li>
<li>repeats: five separate 10-fold cross-validations are used</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="output" class="section level2">
<h2>output</h2>
<p>The Output Shows: - accuracy<br />
- kappa (and their standard deviation) for the different model sizes we provided - The final selected model subset size is marked with a * in the rightmost Selected column.</p>
<pre class="r"><code>save.image(&quot;../../data/craet_5.Rdata&quot;)
sessionInfo()</code></pre>
<pre><code>## R version 3.4.3 (2017-11-30)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Sierra 10.12.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] parallel  methods   stats     graphics  grDevices utils     datasets 
## [8] base     
## 
## other attached packages:
##  [1] doMC_1.3.5      iterators_1.0.9 foreach_1.4.4   caret_6.0-78   
##  [5] lattice_0.20-35 forcats_0.3.0   stringr_1.3.0   dplyr_0.7.4    
##  [9] purrr_0.2.4     readr_1.1.1     tidyr_0.8.0     tibble_1.4.2   
## [13] ggplot2_2.2.1   tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##  [1] httr_1.3.1          ddalpha_1.3.1.1     sfsmisc_1.1-2      
##  [4] jsonlite_1.5        splines_3.4.3       prodlim_1.6.1      
##  [7] modelr_0.1.1        assertthat_0.2.0    stats4_3.4.3       
## [10] DRR_0.0.3           cellranger_1.1.0    yaml_2.1.18        
## [13] robustbase_0.92-8   ipred_0.9-6         pillar_1.2.1       
## [16] backports_1.1.2     glue_1.2.0          digest_0.6.15      
## [19] randomForest_4.6-12 rvest_0.3.2         colorspace_1.3-2   
## [22] recipes_0.1.2       htmltools_0.3.6     Matrix_1.2-12      
## [25] plyr_1.8.4          psych_1.7.8         timeDate_3043.102  
## [28] pkgconfig_2.0.1     CVST_0.2-1          broom_0.4.3        
## [31] haven_1.1.1         bookdown_0.7        scales_0.5.0.9000  
## [34] gower_0.1.2         lava_1.6            withr_2.1.1.9000   
## [37] nnet_7.3-12         lazyeval_0.2.1      cli_1.0.0          
## [40] mnormt_1.5-5        survival_2.41-3     magrittr_1.5       
## [43] crayon_1.3.4        readxl_1.0.0        evaluate_0.10.1    
## [46] nlme_3.1-131.1      MASS_7.3-49         xml2_1.2.0         
## [49] dimRed_0.1.0        foreign_0.8-69      class_7.3-14       
## [52] blogdown_0.5        tools_3.4.3         hms_0.4.2          
## [55] kernlab_0.9-25      munsell_0.4.3       bindrcpp_0.2       
## [58] e1071_1.6-8         compiler_3.4.3      RcppRoll_0.2.2     
## [61] rlang_0.2.0.9000    grid_3.4.3          rmarkdown_1.9      
## [64] gtable_0.2.0        ModelMetrics_1.1.0  codetools_0.2-15   
## [67] reshape2_1.4.3      R6_2.2.2            lubridate_1.7.3    
## [70] knitr_1.20          bindr_0.1.1         rprojroot_1.3-2    
## [73] stringi_1.1.7       Rcpp_0.12.16        rpart_4.1-13       
## [76] tidyselect_0.2.4    DEoptimR_1.0-8      xfun_0.1</code></pre>
</div>
<div id="reference" class="section level2">
<h2><strong>Reference</strong></h2>
<ul>
<li><a href="https://www.machinelearningplus.com/caret-package/">How to do feature selection using recursive feature elimination (rfe)?</a></li>
</ul>
</div>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="//tags/caret/">caret</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/03/6-training-and-tuning-the-model/" data-tooltip="6 Training and Tuning the model">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/03/4-how-to-visualize-the-importance-of-variables-using-featureplot/" data-tooltip="4 How To Visualize The Importance Of Variables Using featurePlot">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/03/5-how-to-do-feature-selection-using-recursive-feature-elimination/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/03/5-how-to-do-feature-selection-using-recursive-feature-elimination/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/03/5-how-to-do-feature-selection-using-recursive-feature-elimination/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2018 Jixing Liu. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/03/6-training-and-tuning-the-model/" data-tooltip="6 Training and Tuning the model">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/03/4-how-to-visualize-the-importance-of-variables-using-featureplot/" data-tooltip="4 How To Visualize The Importance Of Variables Using featurePlot">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/03/5-how-to-do-feature-selection-using-recursive-feature-elimination/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/03/5-how-to-do-feature-selection-using-recursive-feature-elimination/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/03/5-how-to-do-feature-selection-using-recursive-feature-elimination/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2018%2F03%2F5-how-to-do-feature-selection-using-recursive-feature-elimination%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2018%2F03%2F5-how-to-do-feature-selection-using-recursive-feature-elimination%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2F2018%2F03%2F5-how-to-do-feature-selection-using-recursive-feature-elimination%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Jixing Liu</h4>
    
      <div id="about-card-bio">In God I trust. All others must bring data.</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Data Scientist
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        China
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/04/run-python-from-r/">
                <h3 class="media-heading">Run Python From R</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">R is mainly known for data analysis, statistical modeling and visualization. While python is popular for deep learning and natural language processing.
Python and R were ranked top 2 tools for data science and machine learning. If you really want to boost your career in data science world, these are the languages you need to focus on.
How To Call Or Run Python From R? RStudio developed a package called reticulate which provides a medium to run Python packages and functions from R.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/04/9-ensembling-the-predictions/">
                <h3 class="media-heading">9 Ensembling The Predictions</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Load Package And Data load(&quot;../../data/craet_8.Rdata&quot;) library(tidyverse) library(caret) #Set Parallel Processing - Decrease computation time if (!require(&quot;doMC&quot;)) install.packages(&quot;doMC&quot;) library(doMC) registerDoMC(cores = 4)  Train Multiple Models So now we have predictions from multiple individual models.To do this we had to run the train() function once for each model, store the models and pass it to the res
library(caretEnsemble) # Stacking Algorithms - Run multiple algos in one call. trainControl &lt;- trainControl(method=&quot;repeatedcv&quot;, number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE) algorithmList &lt;- c(&#39;rf&#39;, &#39;adaboost&#39;, &#39;earth&#39;, &#39;svmRadial&#39;) set.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/8-how-to-evaluate-performance-of-multiple-machine-learning-algorithms/">
                <h3 class="media-heading">8 How To Evaluate Performance Of Multiple Machine Learning Algorithms?</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Load Package And Data load(&quot;../../data/craet_7.Rdata&quot;) library(tidyverse) library(caret) #Set Parallel Processing - Decrease computation time if (!require(&quot;doMC&quot;)) install.packages(&quot;doMC&quot;) library(doMC) registerDoMC(cores = 4)  Caret provides the resamples() function where you can provide multiple machine learning models and collectively evaluate them Define the training control fitControl &lt;- trainControl( method = &#39;cv&#39;, # k-fold cross validation number = 5, # number of folds savePredictions = &#39;final&#39;, # saves predictions for optimal tuning parameter classProbs = T, # should class probabilities be returned summaryFunction=twoClassSummary # results summary function )   train models set.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/7-how-to-do-hyperparameter-tuning/">
                <h3 class="media-heading">7 How To Do Hyperparameter Tuning </h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Load Package And Data load(&quot;../../data/craet_6.Rdata&quot;) library(tidyverse) library(caret) # Set Parallel Processing - Decrease computation time if (!require(&quot;doMC&quot;)) install.packages(&quot;doMC&quot;) library(doMC) registerDoMC(cores = 4) Hyper parameter tuning using tuneGrid Model Tuning Parameter Set
 Cross Validation Set
Cross validationÂ methodÂ can be one amongst:  â€˜bootâ€™: Bootstrap sampling â€˜boot632â€™: Bootstrap sampling with 63.2% bias correction applied â€˜optimism_bootâ€™: The optimism bootstrap estimator â€˜boot_allâ€™: All boot methods. â€˜cvâ€™: k-Fold cross validation â€˜repeatedcvâ€™: Repeated k-Fold cross validation â€˜oobâ€™: Out of Bag cross validation â€˜LOOCVâ€™: Leave one out cross validation â€˜LGOCVâ€™: Leave group out cross validation  Training And Tuning</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/6-training-and-tuning-the-model/">
                <h3 class="media-heading">6 Training and Tuning the model</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Load Package And Data  Training 1. How to train the model and interpret the results? Once you have chosen an algorithm, building the model is fairly easy using the train() function
train() does multiple other things like:
Cross validating the model Tune the hyper parameters for optimal model performance Choose the optimal model based on a given evaluation metric Preprocess the predictors (what we did so far using preProcess())   2.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/5-how-to-do-feature-selection-using-recursive-feature-elimination/">
                <h3 class="media-heading">5 How to do feature selection using recursive feature elimination</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">You might need a rigorous way to determine the important variables first before feeding them to the ML algorithm. This is important.
A good choice of selecting the important features is the recursive feature elimination (RFE)
RFE works in 3 broad steps:
Step 1: Build a ML model on a training dataset and estimate the feature importances on the test dataset.ï¼ˆåœ¨ç¡®å®šè‡ªç”±åº¦çš„æƒ…å†µä¸‹ï¼Œè¯„ä»·å˜é‡åœ¨æµ‹è¯•æ•°æ®é›†ä¸­çš„é‡è¦æ€§ï¼‰
Step 2: Keeping priority to the most important variables, iterate through by building models of given sizes.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/4-how-to-visualize-the-importance-of-variables-using-featureplot/">
                <h3 class="media-heading">4 How To Visualize The Importance Of Variables Using featurePlot</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Load Package And Data load(&quot;../../data/craet_3-3.Rdata&quot;) library(tidyverse) library(caret)  Q: How The Predictors Influence The Y é€‰æ‹©é‡è¦çš„å˜é‡: é€šè¿‡è§‚å¯Ÿåœ¨Yçš„åˆ†ç»„ä¸‹å„ä¸ªå˜é‡çš„åˆ†å¸ƒæƒ…å†µ
ä¸€èˆ¬æœ‰ ç®±çº¿å›¾ å’Œ å¯†åº¦å›¾
 box-plot featurePlot(x = trainData[, 1:18], y = trainData$Purchase, plot = &quot;box&quot;,#&quot;density&quot; strip=strip.custom(par.strip.text=list(cex=.7)), scales = list(x = list(relation=&quot;free&quot;), y = list(relation=&quot;free&quot;)))  Density featurePlot(x = trainData[, 1:18], y = trainData$Purchase, plot = &quot;density&quot;, strip=strip.custom(par.strip.text=list(cex=.7)), scales = list(x = list(relation=&quot;free&quot;), y = list(relation=&quot;free&quot;))) save.image(&quot;../../data/craet_4.Rdata&quot;)  </div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/scraping-and-wranging-tables-from-research-articles/">
                <h3 class="media-heading">Scraping and Wranging Tables from Research Articles</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">What do you do when you want to use results from the literature to anchor your own analysis? weâ€™ll go through a practical scenario on scraping an html table from a Nature Genetics article into R and wrangling the data into a useful format.
01. Scraping a html table from a webpage #load packages library(&quot;rvest&quot;) library(&quot;knitr&quot;) library(tidyverse) #scraping web page url &lt;- &quot;https://www.nature.com/articles/ng.2802/tables/2&quot; #====ğŸ”¥find where is the table lives on this webpage==== table_path=&#39;//*[@id=&quot;content&quot;]/div/div/figure/div[1]/div/div[1]/table&#39; #get the table nature_genetics_table2 &lt;- url %&gt;% read_html() %&gt;% html_nodes(xpath=table_path) %&gt;% html_table(fill=T) %&gt;% .</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/how-to-create-dummy-variables-and-normalization/">
                <h3 class="media-heading">3.3 How To Create Dummy Variables And Normalization</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Load Package And Data load(&quot;../../data/craet_3-2.Rdata&quot;) library(tidyverse) library(caret)  Why Dummy Variables å¯¹äºå­—ç¬¦å‹çš„å› å­å˜é‡ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå®ƒè½¬å˜ä¸ºæœ‰åºçš„æ•°å€¼ï¼Œä¸€èˆ¬è½¬ä¸º 0ï¼Œ1 çš„äºŒå˜é‡ï¼Œ è¿™æ ·0 å°±ä»£è¡¨åŸºç¡€æ°´å¹³ï¼Œ 1ä»£è¡¨æ¯”è¾ƒç»„
 How # One-Hot Encoding # Creating dummy variables is converting a categorical variable to as many binary variables as here are categories. dummies_model &lt;- dummyVars(Purchase ~ ., data=trainData) # Create the dummy variables using predict. The Y variable (Purchase) will not be present in trainData_mat. trainData_mat &lt;- predict(dummies_model, newdata = trainData) # # Convert to dataframe trainData &lt;- data.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/why-should-i-trust-you/">
                <h3 class="media-heading">Why should I trust you ğŸ¤–?</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ä¸»è¦é›†ä¸­åœ¨æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–ä¸Š; æœ€å¥½çš„æ¨¡å‹é€šå¸¸æ˜¯é€šè¿‡åƒç²¾åº¦æˆ–è€…é”™è¯¯è¿™æ ·çš„æ€§èƒ½åº¦é‡æ¥é€‰æ‹©çš„ï¼Œè€Œä¸”å¦‚æœå®ƒé€šè¿‡äº†è¿™äº›æ€§èƒ½æ ‡å‡†çš„æŸäº›é˜ˆå€¼ï¼Œæˆ‘ä»¬å€¾å‘äºå‡è®¾ä¸€ä¸ªæ¨¡å‹æ˜¯è¶³å¤Ÿå¥½çš„ã€‚åœ¨æœºå™¨å­¦ä¹ çš„è®¸å¤šåº”ç”¨ä¸­ï¼Œç”¨æˆ·ä¼šä½¿ç”¨ä¸€ä¸ªæ¨¡å‹æ¥å¸®åŠ©åšå†³å®šï¼Œ ä¾‹å¦‚ï¼šä¸€ä½åŒ»ç”Ÿä¸ä¼šå¯¹ç—…äººè¿›è¡Œæ‰‹æœ¯ï¼Œä»…ä»…å› ä¸ºè¿™ä¸ªæ¨¡å‹è¯´ä¸åº”è¯¥è¿›è¡Œæ‰‹æœ¯ï¼Ÿ
ç”±äºå¤æ‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯é»‘ç›’å­ï¼Œè€Œä¸”å¤ªå¤æ‚ï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹åšå‡ºçš„åˆ†ç±»å†³å®šé€šå¸¸å¾ˆéš¾è¢«äººç±»çš„å¤§è„‘æ‰€ç†è§£ï¼Œä½†æ˜¯èƒ½å¤Ÿç†è§£å’Œè§£é‡Šè¿™äº›æ¨¡å‹å¯¹äºæé«˜æ¨¡å‹è´¨é‡ï¼Œæé«˜ä¿¡ä»»åº¦å’Œé€æ˜åº¦ä»¥åŠå‡å°‘åè§éå¸¸é‡è¦ï¼Œå› ä¸ºäººç±»å¾€å¾€å…·æœ‰è‰¯å¥½çš„ç›´è§‰å’Œå› æœæ¨ç†ï¼Œè¿™äº›éƒ½æ˜¯éš¾ä»¥åœ¨æ•°æ®è¯„ä¼°æŒ‡æ ‡ä¸­æ•è·ã€‚
å› æ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå½¢è±¡çš„ç†è§£å®ƒä»¬çš„å·¥ä½œåŸç†ï¼šä¸ºä»€ä¹ˆä¸€ä¸ªæ¨¡å‹å°†å…·æœ‰ç‰¹å®šæ ‡ç­¾çš„æ¡ˆä¾‹è¿›è¡Œå‡†ç¡®åˆ†ç±»ã€‚eg: ä¸ºä»€ä¹ˆä¸€ä¸ªä¹³è…ºè‚¿å—æ ·æœ¬è¢«å½’ç±»ä¸ºâ€œæ¶æ€§â€è€Œä¸æ˜¯â€œè‰¯æ€§ï¼Œä»…ä»…å› ä¸ºå®ƒé•¿å¾—ä¸‘å—ï¼Ÿ
 Local Interpretable Model-Agnostic Explanations (LIME) is an attempt to make these complex models at least partly understandable. The method has been published in â€œWhy Should I Trust You?â€ Explaining the Predictions of Any Classifier. By Marco Tulio Ribeiro, Sameer Singh and Carlos Guestrin from the University of Washington in Seattle
 How LIME works  lime is able to explain all models for which we can obtain prediction probabilities (in R, that is every model that works with predict(type = â€œprobâ€)).</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         18 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('https://i.loli.net/2018/02/26/5a9416186c149.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js" integrity="sha256-IFHWFEbU2/+wNycDECKgjIRSirRNIDp2acEB5fvdVRU=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js" integrity="sha256-+mpyNVJsNt4rVXCw0F+pAOiB3YxmHgrbJsx4ecPuUaI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js" integrity="sha256-vMxgR/7FtLovVA+IPrR7+xTgIgARH7y9VZQnmmi0HDI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js" integrity="sha256-N0qFUh7/9vLvia87dDndewmsgsyYoNkdA212tPc+2NI=" crossorigin="anonymous"></script>


<script src="/js/script-kr8dyqj6rb6ortyib7whfo9x9p6td6zo8t1v4fdz4ecx5kwybsdlmk1slygn.min.js"></script>


<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>

  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2018\/03\/5-how-to-do-feature-selection-using-recursive-feature-elimination\/';
          
            this.page.identifier = '\/2018\/03\/5-how-to-do-feature-selection-using-recursive-feature-elimination\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'jixing';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>

