

  
    
  


  





  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.32.2 with theme Tranquilpeak 0.4.1-BETA">
    <title>Why should I trust you ğŸ¤–?</title>
    <meta name="author" content="Jixing Liu">
    <meta name="keywords" content=", R">

    <link rel="icon" href="img/R_py.png">
    

    
    <meta name="description" content="ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ä¸»è¦é›†ä¸­åœ¨æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–ä¸Š; æœ€å¥½çš„æ¨¡å‹é€šå¸¸æ˜¯é€šè¿‡åƒç²¾åº¦æˆ–è€…é”™è¯¯è¿™æ ·çš„æ€§èƒ½åº¦é‡æ¥é€‰æ‹©çš„ï¼Œè€Œä¸”å¦‚æœå®ƒé€šè¿‡äº†è¿™äº›æ€§èƒ½æ ‡å‡†çš„æŸäº›é˜ˆå€¼ï¼Œæˆ‘ä»¬å€¾å‘äºå‡è®¾ä¸€ä¸ªæ¨¡å‹æ˜¯è¶³å¤Ÿå¥½çš„ã€‚åœ¨æœºå™¨å­¦ä¹ çš„è®¸å¤šåº”ç”¨ä¸­ï¼Œç”¨æˆ·ä¼šä½¿ç”¨ä¸€ä¸ªæ¨¡å‹æ¥å¸®åŠ©åšå†³å®šï¼Œ ä¾‹å¦‚ï¼šä¸€ä½åŒ»ç”Ÿä¸ä¼šå¯¹ç—…äººè¿›è¡Œæ‰‹æœ¯ï¼Œä»…ä»…å› ä¸ºè¿™ä¸ªæ¨¡å‹è¯´ä¸åº”è¯¥è¿›è¡Œæ‰‹æœ¯ï¼Ÿ
ç”±äºå¤æ‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯é»‘ç›’å­ï¼Œè€Œä¸”å¤ªå¤æ‚ï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹åšå‡ºçš„åˆ†ç±»å†³å®šé€šå¸¸å¾ˆéš¾è¢«äººç±»çš„å¤§è„‘æ‰€ç†è§£ï¼Œä½†æ˜¯èƒ½å¤Ÿç†è§£å’Œè§£é‡Šè¿™äº›æ¨¡å‹å¯¹äºæé«˜æ¨¡å‹è´¨é‡ï¼Œæé«˜ä¿¡ä»»åº¦å’Œé€æ˜åº¦ä»¥åŠå‡å°‘åè§éå¸¸é‡è¦ï¼Œå› ä¸ºäººç±»å¾€å¾€å…·æœ‰è‰¯å¥½çš„ç›´è§‰å’Œå› æœæ¨ç†ï¼Œè¿™äº›éƒ½æ˜¯éš¾ä»¥åœ¨æ•°æ®è¯„ä¼°æŒ‡æ ‡ä¸­æ•è·ã€‚
å› æ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå½¢è±¡çš„ç†è§£å®ƒä»¬çš„å·¥ä½œåŸç†ï¼šä¸ºä»€ä¹ˆä¸€ä¸ªæ¨¡å‹å°†å…·æœ‰ç‰¹å®šæ ‡ç­¾çš„æ¡ˆä¾‹è¿›è¡Œå‡†ç¡®åˆ†ç±»ã€‚eg: ä¸ºä»€ä¹ˆä¸€ä¸ªä¹³è…ºè‚¿å—æ ·æœ¬è¢«å½’ç±»ä¸ºâ€œæ¶æ€§â€è€Œä¸æ˜¯â€œè‰¯æ€§ï¼Œä»…ä»…å› ä¸ºå®ƒé•¿å¾—ä¸‘å—ï¼Ÿ
 Local Interpretable Model-Agnostic Explanations (LIME) is an attempt to make these complex models at least partly understandable. The method has been published in â€œWhy Should I Trust You?â€ Explaining the Predictions of Any Classifier. By Marco Tulio Ribeiro, Sameer Singh and Carlos Guestrin from the University of Washington in Seattle
 How LIME works  lime is able to explain all models for which we can obtain prediction probabilities (in R, that is every model that works with predict(type = â€œprobâ€)).">
    <meta property="og:description" content="ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ä¸»è¦é›†ä¸­åœ¨æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–ä¸Š; æœ€å¥½çš„æ¨¡å‹é€šå¸¸æ˜¯é€šè¿‡åƒç²¾åº¦æˆ–è€…é”™è¯¯è¿™æ ·çš„æ€§èƒ½åº¦é‡æ¥é€‰æ‹©çš„ï¼Œè€Œä¸”å¦‚æœå®ƒé€šè¿‡äº†è¿™äº›æ€§èƒ½æ ‡å‡†çš„æŸäº›é˜ˆå€¼ï¼Œæˆ‘ä»¬å€¾å‘äºå‡è®¾ä¸€ä¸ªæ¨¡å‹æ˜¯è¶³å¤Ÿå¥½çš„ã€‚åœ¨æœºå™¨å­¦ä¹ çš„è®¸å¤šåº”ç”¨ä¸­ï¼Œç”¨æˆ·ä¼šä½¿ç”¨ä¸€ä¸ªæ¨¡å‹æ¥å¸®åŠ©åšå†³å®šï¼Œ ä¾‹å¦‚ï¼šä¸€ä½åŒ»ç”Ÿä¸ä¼šå¯¹ç—…äººè¿›è¡Œæ‰‹æœ¯ï¼Œä»…ä»…å› ä¸ºè¿™ä¸ªæ¨¡å‹è¯´ä¸åº”è¯¥è¿›è¡Œæ‰‹æœ¯ï¼Ÿ
ç”±äºå¤æ‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯é»‘ç›’å­ï¼Œè€Œä¸”å¤ªå¤æ‚ï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹åšå‡ºçš„åˆ†ç±»å†³å®šé€šå¸¸å¾ˆéš¾è¢«äººç±»çš„å¤§è„‘æ‰€ç†è§£ï¼Œä½†æ˜¯èƒ½å¤Ÿç†è§£å’Œè§£é‡Šè¿™äº›æ¨¡å‹å¯¹äºæé«˜æ¨¡å‹è´¨é‡ï¼Œæé«˜ä¿¡ä»»åº¦å’Œé€æ˜åº¦ä»¥åŠå‡å°‘åè§éå¸¸é‡è¦ï¼Œå› ä¸ºäººç±»å¾€å¾€å…·æœ‰è‰¯å¥½çš„ç›´è§‰å’Œå› æœæ¨ç†ï¼Œè¿™äº›éƒ½æ˜¯éš¾ä»¥åœ¨æ•°æ®è¯„ä¼°æŒ‡æ ‡ä¸­æ•è·ã€‚
å› æ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå½¢è±¡çš„ç†è§£å®ƒä»¬çš„å·¥ä½œåŸç†ï¼šä¸ºä»€ä¹ˆä¸€ä¸ªæ¨¡å‹å°†å…·æœ‰ç‰¹å®šæ ‡ç­¾çš„æ¡ˆä¾‹è¿›è¡Œå‡†ç¡®åˆ†ç±»ã€‚eg: ä¸ºä»€ä¹ˆä¸€ä¸ªä¹³è…ºè‚¿å—æ ·æœ¬è¢«å½’ç±»ä¸ºâ€œæ¶æ€§â€è€Œä¸æ˜¯â€œè‰¯æ€§ï¼Œä»…ä»…å› ä¸ºå®ƒé•¿å¾—ä¸‘å—ï¼Ÿ
 Local Interpretable Model-Agnostic Explanations (LIME) is an attempt to make these complex models at least partly understandable. The method has been published in â€œWhy Should I Trust You?â€ Explaining the Predictions of Any Classifier. By Marco Tulio Ribeiro, Sameer Singh and Carlos Guestrin from the University of Washington in Seattle
 How LIME works  lime is able to explain all models for which we can obtain prediction probabilities (in R, that is every model that works with predict(type = â€œprobâ€)).">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Why should I trust you ğŸ¤–?">
    <meta property="og:url" content="/2018/03/why-should-i-trust-you/">
    <meta property="og:site_name" content="student zero ">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="student zero ">
    <meta name="twitter:description" content="ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ä¸»è¦é›†ä¸­åœ¨æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–ä¸Š; æœ€å¥½çš„æ¨¡å‹é€šå¸¸æ˜¯é€šè¿‡åƒç²¾åº¦æˆ–è€…é”™è¯¯è¿™æ ·çš„æ€§èƒ½åº¦é‡æ¥é€‰æ‹©çš„ï¼Œè€Œä¸”å¦‚æœå®ƒé€šè¿‡äº†è¿™äº›æ€§èƒ½æ ‡å‡†çš„æŸäº›é˜ˆå€¼ï¼Œæˆ‘ä»¬å€¾å‘äºå‡è®¾ä¸€ä¸ªæ¨¡å‹æ˜¯è¶³å¤Ÿå¥½çš„ã€‚åœ¨æœºå™¨å­¦ä¹ çš„è®¸å¤šåº”ç”¨ä¸­ï¼Œç”¨æˆ·ä¼šä½¿ç”¨ä¸€ä¸ªæ¨¡å‹æ¥å¸®åŠ©åšå†³å®šï¼Œ ä¾‹å¦‚ï¼šä¸€ä½åŒ»ç”Ÿä¸ä¼šå¯¹ç—…äººè¿›è¡Œæ‰‹æœ¯ï¼Œä»…ä»…å› ä¸ºè¿™ä¸ªæ¨¡å‹è¯´ä¸åº”è¯¥è¿›è¡Œæ‰‹æœ¯ï¼Ÿ
ç”±äºå¤æ‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯é»‘ç›’å­ï¼Œè€Œä¸”å¤ªå¤æ‚ï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹åšå‡ºçš„åˆ†ç±»å†³å®šé€šå¸¸å¾ˆéš¾è¢«äººç±»çš„å¤§è„‘æ‰€ç†è§£ï¼Œä½†æ˜¯èƒ½å¤Ÿç†è§£å’Œè§£é‡Šè¿™äº›æ¨¡å‹å¯¹äºæé«˜æ¨¡å‹è´¨é‡ï¼Œæé«˜ä¿¡ä»»åº¦å’Œé€æ˜åº¦ä»¥åŠå‡å°‘åè§éå¸¸é‡è¦ï¼Œå› ä¸ºäººç±»å¾€å¾€å…·æœ‰è‰¯å¥½çš„ç›´è§‰å’Œå› æœæ¨ç†ï¼Œè¿™äº›éƒ½æ˜¯éš¾ä»¥åœ¨æ•°æ®è¯„ä¼°æŒ‡æ ‡ä¸­æ•è·ã€‚
å› æ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå½¢è±¡çš„ç†è§£å®ƒä»¬çš„å·¥ä½œåŸç†ï¼šä¸ºä»€ä¹ˆä¸€ä¸ªæ¨¡å‹å°†å…·æœ‰ç‰¹å®šæ ‡ç­¾çš„æ¡ˆä¾‹è¿›è¡Œå‡†ç¡®åˆ†ç±»ã€‚eg: ä¸ºä»€ä¹ˆä¸€ä¸ªä¹³è…ºè‚¿å—æ ·æœ¬è¢«å½’ç±»ä¸ºâ€œæ¶æ€§â€è€Œä¸æ˜¯â€œè‰¯æ€§ï¼Œä»…ä»…å› ä¸ºå®ƒé•¿å¾—ä¸‘å—ï¼Ÿ
 Local Interpretable Model-Agnostic Explanations (LIME) is an attempt to make these complex models at least partly understandable. The method has been published in â€œWhy Should I Trust You?â€ Explaining the Predictions of Any Classifier. By Marco Tulio Ribeiro, Sameer Singh and Carlos Guestrin from the University of Washington in Seattle
 How LIME works  lime is able to explain all models for which we can obtain prediction probabilities (in R, that is every model that works with predict(type = â€œprobâ€)).">
    
      <meta name="twitter:creator" content="@studentZero475">
    
    

    
    

    
      <meta property="og:image" content="https://i.loli.net/2018/02/26/5a937bb148b02.jpg">
    

    
      <meta property="og:image" content="https://i.loli.net/2018/02/11/5a7fa56fd7333.jpg">
    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-hbs5om8csx9a8yrv5hnhpi2qqdv4ykuslajwbramhqxvleqbfklxgek50hye.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <link rel="stylesheet" href="/css/monokai-sublime.css" rel="stylesheet" id="theme-stylesheet">
<script src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">student zero </a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <h1 class="sidebar-profile-title">Why should I trust you ğŸ¤–?</h1>
        <a href="/#about">
          <img class="sidebar-profile-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Jixing Liu</h4>
        
          <h5 class="sidebar-profile-bio">Clinical Doctor turned Bioinformatician turned Data Scientist</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives/">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories/">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags/">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://twitter.com/studentZero475">
    
      <i class="sidebar-button-icon fa fa-lg fa-twitter"></i>
      
      <span class="sidebar-button-desc">Twitter</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.r-bloggers.com/">
    
      <i class="sidebar-button-icon fa fa-lg fa-book"></i>
      
      <span class="sidebar-button-desc">R-bloggers</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      

    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaOut
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-center">
  
    <h1 class="post-title" itemprop="headline">
      Why should I trust you ğŸ¤–?
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-03-26T00:00:00Z">
        
  March 26, 2018

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/machine-learning">machine learning</a>
    
  


  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <p>ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ä¸»è¦é›†ä¸­åœ¨æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–ä¸Š; æœ€å¥½çš„æ¨¡å‹é€šå¸¸æ˜¯é€šè¿‡åƒç²¾åº¦æˆ–è€…é”™è¯¯è¿™æ ·çš„æ€§èƒ½åº¦é‡æ¥é€‰æ‹©çš„ï¼Œè€Œä¸”å¦‚æœå®ƒé€šè¿‡äº†è¿™äº›æ€§èƒ½æ ‡å‡†çš„æŸäº›é˜ˆå€¼ï¼Œæˆ‘ä»¬å€¾å‘äºå‡è®¾ä¸€ä¸ªæ¨¡å‹æ˜¯è¶³å¤Ÿå¥½çš„ã€‚åœ¨æœºå™¨å­¦ä¹ çš„è®¸å¤šåº”ç”¨ä¸­ï¼Œç”¨æˆ·ä¼šä½¿ç”¨ä¸€ä¸ªæ¨¡å‹æ¥å¸®åŠ©åšå†³å®šï¼Œ ä¾‹å¦‚ï¼šä¸€ä½åŒ»ç”Ÿä¸ä¼šå¯¹ç—…äººè¿›è¡Œæ‰‹æœ¯ï¼Œä»…ä»…å› ä¸ºè¿™ä¸ªæ¨¡å‹è¯´ä¸åº”è¯¥è¿›è¡Œæ‰‹æœ¯ï¼Ÿ</p>
<p>ç”±äºå¤æ‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯é»‘ç›’å­ï¼Œè€Œä¸”å¤ªå¤æ‚ï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹åšå‡ºçš„åˆ†ç±»å†³å®šé€šå¸¸å¾ˆéš¾è¢«äººç±»çš„å¤§è„‘æ‰€ç†è§£ï¼Œä½†æ˜¯èƒ½å¤Ÿç†è§£å’Œè§£é‡Šè¿™äº›æ¨¡å‹å¯¹äºæé«˜æ¨¡å‹è´¨é‡ï¼Œæé«˜ä¿¡ä»»åº¦å’Œé€æ˜åº¦ä»¥åŠå‡å°‘åè§éå¸¸é‡è¦ï¼Œå› ä¸ºäººç±»å¾€å¾€å…·æœ‰è‰¯å¥½çš„ç›´è§‰å’Œå› æœæ¨ç†ï¼Œè¿™äº›éƒ½æ˜¯éš¾ä»¥åœ¨æ•°æ®è¯„ä¼°æŒ‡æ ‡ä¸­æ•è·ã€‚</p>
<p>å› æ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå½¢è±¡çš„ç†è§£å®ƒä»¬çš„å·¥ä½œåŸç†ï¼šä¸ºä»€ä¹ˆä¸€ä¸ªæ¨¡å‹å°†å…·æœ‰ç‰¹å®šæ ‡ç­¾çš„æ¡ˆä¾‹è¿›è¡Œå‡†ç¡®åˆ†ç±»ã€‚eg: ä¸ºä»€ä¹ˆä¸€ä¸ªä¹³è…ºè‚¿å—æ ·æœ¬è¢«å½’ç±»ä¸ºâ€œæ¶æ€§â€è€Œä¸æ˜¯â€œè‰¯æ€§ï¼Œä»…ä»…å› ä¸ºå®ƒé•¿å¾—ä¸‘å—ï¼Ÿ</p>
<blockquote>
<p><a href="https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime">Local Interpretable Model-Agnostic Explanations (LIME)</a> is an attempt to make these complex models at least partly understandable. The method has been published in <a href="https://arxiv.org/pdf/1602.04938.pdf">â€œWhy Should I Trust You?â€</a> Explaining the Predictions of Any Classifier. By Marco Tulio Ribeiro, Sameer Singh and Carlos Guestrin from the University of Washington in Seattle</p>
</blockquote>
<div id="how-lime-works" class="section level2">
<h2><strong>How LIME works</strong></h2>
<blockquote>
<p>lime is able to explain all models for which we can obtain prediction probabilities (in R, that is every model that works with predict(type = â€œprobâ€)). It makes use of the fact that linear models are easy to explain because they are based on linear relationships between features and class labels: The complex model function is approximated by locally fitting linear models to permutations of the original training set.On each permutation, a linear model is being fit and weights are given so that incorrect classification of instances that are more similar to the original data are penalized (positive weights support a decision, negative weights contradict them). This will give an approximation of how much (and in which way) each feature contributed to a decision made by the model</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7fa56fd7333.jpg" width="30%" /></p>
<blockquote>
<p>We take the image on the left and divide it into interpretable components</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7faba0d302a.jpg" width="30%" /></p>
<blockquote>
<p>we then generate a data set of perturbed instances by turning some of the interpretable components â€œoï¬€â€. For each perturbed instance, we get the probability that a tree frog is in the image according to the model.</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7fac3ca8787.jpg" width="30%" /></p>
<blockquote>
<p>We then learn a simple (linear) model on this data set, which is locally weightedâ€”that is, we care more about making mistakes in perturbed instances that are more similar to the original image</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7fac8382a86.jpg" width="30%" /></p>
<blockquote>
<p>the end, we present the superpixels with highest positive weights as an explanation, graying out everything else</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7faf16f0320.jpg" width="30%" /></p>
<p>ğŸ¤–é¢„æµ‹è¿™å¼ å›¾æ˜¯ä¸ªæ ‘è›™æ˜¯å› ä¸ºè¿™ä¸ªéƒ¨åˆ†,æ‰€ä»¥ğŸ¤–é¢„æµ‹ç»“æœæ˜¯æ¯”è¾ƒå¯ä¿¡çš„ã€‚ <img src="https://i.loli.net/2018/02/11/5a7faebabe34e.jpg" style="display: block; margin: auto;" /></p>
<p>ğŸ¤–é¢„æµ‹è¿™å¼ å›¾æ˜¯å°çƒæ˜¯æ ¹æ®è¿™äº›éƒ¨åˆ†ï¼Œæ‰€ä»¥ğŸ¤–é¢„æµ‹ç»“æœæ˜¯ä¸å¯ä¿¡çš„ã€‚ <img src="https://i.loli.net/2018/02/11/5a7fb61ecb060.jpg" style="display: block; margin: auto;" /></p>
</div>
<div id="example-in-r" class="section level2">
<h2><strong>Example in R</strong></h2>
<div id="prepare-the-breast-cancer-data" class="section level3">
<h3>01.Prepare the breast cancer data</h3>
<p>This <strong>data</strong> of example comes from the book of <strong>R in action</strong></p>
<pre class="r"><code>loc &lt;- &quot;http://archive.ics.uci.edu/ml/machine-learning-databases/&quot;
ds  &lt;- &quot;breast-cancer-wisconsin/breast-cancer-wisconsin.data&quot;
url &lt;- paste(loc, ds, sep=&quot;&quot;)

breast &lt;- read.table(url, sep=&quot;,&quot;, header=FALSE, na.strings=&quot;?&quot;)
names(breast) &lt;- c(&quot;ID&quot;, &quot;clumpThickness&quot;, &quot;sizeUniformity&quot;,
                   &quot;shapeUniformity&quot;, &quot;maginalAdhesion&quot;, 
                   &quot;singleEpithelialCellSize&quot;, &quot;bareNuclei&quot;, 
                   &quot;blandChromatin&quot;, &quot;normalNucleoli&quot;, &quot;mitosis&quot;, &quot;class&quot;)

df &lt;- breast[-1]
df$class &lt;- factor(df$class, levels=c(2,4), 
                   labels=c(&quot;benign&quot;, &quot;malignant&quot;))

set.seed(1234)
train &lt;- sample(nrow(df), 0.7*nrow(df))
df.train &lt;- df[train,]
df.validate &lt;- df[-train,]
table(df.train$class)</code></pre>
<pre><code>## 
##    benign malignant 
##       329       160</code></pre>
<pre class="r"><code>table(df.validate$class)</code></pre>
<pre><code>## 
##    benign malignant 
##       129        81</code></pre>
</div>
<div id="create-decision-tree-model" class="section level3">
<h3>02 Create decision tree model</h3>
<pre class="r"><code>library(rpart)
set.seed(1234)
dtree &lt;- rpart(class ~ ., data=df.train, method=&quot;class&quot;,      
               parms=list(split=&quot;information&quot;))
dtree$cptable</code></pre>
<pre><code>##         CP nsplit rel error  xerror       xstd
## 1 0.800000      0   1.00000 1.00000 0.06484605
## 2 0.046875      1   0.20000 0.30625 0.04150018
## 3 0.012500      3   0.10625 0.20625 0.03467089
## 4 0.010000      4   0.09375 0.18125 0.03264401</code></pre>
<pre class="r"><code>plotcp(dtree)</code></pre>
<p><img src="/post/2018-02-11-why-should-i-trust-you_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>dtree.pruned &lt;- prune(dtree, cp=.0125)</code></pre>
</div>
<div id="predict" class="section level3">
<h3>03 predict</h3>
<pre class="r"><code>dtree.pred &lt;- predict(dtree.pruned, df.validate, type=&quot;class&quot;)
(dtree.perf &lt;- table(df.validate$class, dtree.pred, 
                    dnn=c(&quot;Actual&quot;, &quot;Predicted&quot;)))</code></pre>
<pre><code>##            Predicted
## Actual      benign malignant
##   benign       122         7
##   malignant      2        79</code></pre>
</div>
<div id="plot-decision-tree" class="section level3">
<h3>04 plot decision tree</h3>
<pre class="r"><code>#plot01
library(rpart.plot)
prp(dtree.pruned, type = 2, extra = 104,  
    fallen.leaves = TRUE, main=&quot;Decision Tree&quot;)
#plot02
library(partykit)</code></pre>
<p><img src="/post/2018-02-11-why-should-i-trust-you_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>library(dplyr)
dtree.pruned %&gt;% as.party() %&gt;% plot()</code></pre>
<p><img src="/post/2018-02-11-why-should-i-trust-you_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
</div>
<div id="lime-why-should-i-trust-you" class="section level3">
<h3>LIME: why should I trust you ğŸ¤–?</h3>
<pre class="r"><code>library(lime)
explainer &lt;- lime(df.train, model = dtree.pruned)

# Explain new observation
#[model_type](https://github.com/thomasp85/lime/blob/master/R/models.R)
model_type.rpart &lt;- function(x, ...) &#39;classification&#39;#defined model_type method
test.data &lt;- 
  df.validate %&gt;% 
  dplyr::select(-class) %&gt;% 
  head(3)
explanation &lt;- lime::explain(test.data, explainer, n_labels = 1, n_features = 2)

# The output is provided in a consistent tabular format and includes the
# output from the model.
head(explanation)</code></pre>
<pre><code>##       model_type case     label label_prob  model_r2 model_intercept
## 1 classification    3    benign  0.9933993 0.1809444      0.05042991
## 2 classification    3    benign  0.9933993 0.1809444      0.05042991
## 3 classification    4 malignant  0.9507042 0.1918642      0.54743276
## 4 classification    4 malignant  0.9507042 0.1918642      0.54743276
## 5 classification    5    benign  0.9933993 0.1924691      0.05378321
## 6 classification    5    benign  0.9933993 0.1924691      0.05378321
##   model_prediction                  feature feature_value feature_weight
## 1        0.4637659           blandChromatin             3   -0.001977357
## 2        0.4637659           sizeUniformity             1    0.415313316
## 3        0.9524157 singleEpithelialCellSize             3    0.002885248
## 4        0.9524157           sizeUniformity             8    0.402097681
## 5        0.4712710          maginalAdhesion             3   -0.004533032
## 6        0.4712710           sizeUniformity             1    0.422020822
##                        feature_desc                      data
## 1           2 &lt; blandChromatin &lt;= 3 3, 1, 1, 1, 2, 2, 3, 1, 1
## 2               sizeUniformity &lt;= 4 3, 1, 1, 1, 2, 2, 3, 1, 1
## 3 2 &lt; singleEpithelialCellSize &lt;= 4 6, 8, 8, 1, 3, 4, 3, 7, 1
## 4                4 &lt; sizeUniformity 6, 8, 8, 1, 3, 4, 3, 7, 1
## 5              maginalAdhesion &lt;= 3 4, 1, 1, 3, 2, 1, 3, 1, 1
## 6               sizeUniformity &lt;= 4 4, 1, 1, 3, 2, 1, 3, 1, 1
##               prediction
## 1 0.99339934, 0.00660066
## 2 0.99339934, 0.00660066
## 3 0.04929577, 0.95070423
## 4 0.04929577, 0.95070423
## 5 0.99339934, 0.00660066
## 6 0.99339934, 0.00660066</code></pre>
<pre class="r"><code># And can be visualised directly
plot_features(explanation)</code></pre>
<p><img src="/post/2018-02-11-why-should-i-trust-you_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
</div>
<div id="links" class="section level2">
<h2><strong>Links</strong></h2>
<ul>
<li><a href="http://archive.ics.uci.edu/ml/datasets/Chronic_Kidney_Disease">CKD data set</a></li>
<li><a href="https://github.com/marcotcr/lime">open-source Python code for LIME</a></li>
<li><a href="https://github.com/thomasp85/lime">R package for LIME</a></li>
</ul>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="//tags/lime/">LIME</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/03/how-to-create-dummy-variables-and-normalization/" data-tooltip="3.3 How To Create Dummy Variables And Normalization">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/03/3-2-statistic-description-and-impute-missing-value/" data-tooltip="3.2 statistic description and impute missing value">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/03/why-should-i-trust-you/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/03/why-should-i-trust-you/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/03/why-should-i-trust-you/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2018 Jixing Liu. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/03/how-to-create-dummy-variables-and-normalization/" data-tooltip="3.3 How To Create Dummy Variables And Normalization">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/03/3-2-statistic-description-and-impute-missing-value/" data-tooltip="3.2 statistic description and impute missing value">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/03/why-should-i-trust-you/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/03/why-should-i-trust-you/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/03/why-should-i-trust-you/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2018%2F03%2Fwhy-should-i-trust-you%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2018%2F03%2Fwhy-should-i-trust-you%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2F2018%2F03%2Fwhy-should-i-trust-you%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Jixing Liu</h4>
    
      <div id="about-card-bio">Clinical Doctor turned Bioinformatician turned Data Scientist</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Data Scientist
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        China
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/8-how-to-evaluate-performance-of-multiple-machine-learning-algorithms/">
                <h3 class="media-heading">8 How To Evaluate Performance Of Multiple Machine Learning Algorithms?</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Load Package And Data load(&quot;../../data/craet_7.Rdata&quot;) library(tidyverse) library(caret) #Set Parallel Processing - Decrease computation time if (!require(&quot;doMC&quot;)) install.packages(&quot;doMC&quot;) library(doMC) registerDoMC(cores = 4)  Caret provides the resamples() function where you can provide multiple machine learning models and collectively evaluate them Define the training control fitControl &lt;- trainControl( method = &#39;cv&#39;, # k-fold cross validation number = 5, # number of folds savePredictions = &#39;final&#39;, # saves predictions for optimal tuning parameter classProbs = T, # should class probabilities be returned summaryFunction=twoClassSummary # results summary function )   train models set.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/7-how-to-do-hyperparameter-tuning/">
                <h3 class="media-heading">7 How To Do Hyperparameter Tuning </h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Load Package And Data load(&quot;../../data/craet_6.Rdata&quot;) library(tidyverse) library(caret) # Set Parallel Processing - Decrease computation time if (!require(&quot;doMC&quot;)) install.packages(&quot;doMC&quot;) library(doMC) registerDoMC(cores = 4) Hyper parameter tuning using tuneGrid Model Tuning Parameter Set
 Cross Validation Set
Cross validationÂ methodÂ can be one amongst:  â€˜bootâ€™: Bootstrap sampling â€˜boot632â€™: Bootstrap sampling with 63.2% bias correction applied â€˜optimism_bootâ€™: The optimism bootstrap estimator â€˜boot_allâ€™: All boot methods. â€˜cvâ€™: k-Fold cross validation â€˜repeatedcvâ€™: Repeated k-Fold cross validation â€˜oobâ€™: Out of Bag cross validation â€˜LOOCVâ€™: Leave one out cross validation â€˜LGOCVâ€™: Leave group out cross validation  Training And Tuning</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/6-training-and-tuning-the-model/">
                <h3 class="media-heading">6 Training and Tuning the model</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Load Package And Data  Training 1. How to train the model and interpret the results? Once you have chosen an algorithm, building the model is fairly easy using the train() function
train() does multiple other things like:
Cross validating the model Tune the hyper parameters for optimal model performance Choose the optimal model based on a given evaluation metric Preprocess the predictors (what we did so far using preProcess())   2.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/5-how-to-do-feature-selection-using-recursive-feature-elimination/">
                <h3 class="media-heading">5 How to do feature selection using recursive feature elimination</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">You might need a rigorous way to determine the important variables first before feeding them to the ML algorithm. This is important.
A good choice of selecting the important features is the recursive feature elimination (RFE)
RFE works in 3 broad steps:
Step 1: Build a ML model on a training dataset and estimate the feature importances on the test dataset.ï¼ˆåœ¨ç¡®å®šè‡ªç”±åº¦çš„æƒ…å†µä¸‹ï¼Œè¯„ä»·å˜é‡åœ¨æµ‹è¯•æ•°æ®é›†ä¸­çš„é‡è¦æ€§ï¼‰
Step 2: Keeping priority to the most important variables, iterate through by building models of given sizes.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/4-how-to-visualize-the-importance-of-variables-using-featureplot/">
                <h3 class="media-heading">4 How To Visualize The Importance Of Variables Using featurePlot</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Load Package And Data load(&quot;../../data/craet_3-3.Rdata&quot;) library(tidyverse) library(caret)  Q: How The Predictors Influence The Y é€‰æ‹©é‡è¦çš„å˜é‡: é€šè¿‡è§‚å¯Ÿåœ¨Yçš„åˆ†ç»„ä¸‹å„ä¸ªå˜é‡çš„åˆ†å¸ƒæƒ…å†µ
ä¸€èˆ¬æœ‰ ç®±çº¿å›¾ å’Œ å¯†åº¦å›¾
 box-plot featurePlot(x = trainData[, 1:18], y = trainData$Purchase, plot = &quot;box&quot;,#&quot;density&quot; strip=strip.custom(par.strip.text=list(cex=.7)), scales = list(x = list(relation=&quot;free&quot;), y = list(relation=&quot;free&quot;)))  Density featurePlot(x = trainData[, 1:18], y = trainData$Purchase, plot = &quot;density&quot;, strip=strip.custom(par.strip.text=list(cex=.7)), scales = list(x = list(relation=&quot;free&quot;), y = list(relation=&quot;free&quot;))) save.image(&quot;../../data/craet_4.Rdata&quot;)  </div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/scraping-and-wranging-tables-from-research-articles/">
                <h3 class="media-heading">Scraping and Wranging Tables from Research Articles</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">What do you do when you want to use results from the literature to anchor your own analysis? weâ€™ll go through a practical scenario on scraping an html table from a Nature Genetics article into R and wrangling the data into a useful format.
01. Scraping a html table from a webpage #load packages library(&quot;rvest&quot;) library(&quot;knitr&quot;) library(tidyverse) #scraping web page url &lt;- &quot;https://www.nature.com/articles/ng.2802/tables/2&quot; #====ğŸ”¥find where is the table lives on this webpage==== table_path=&#39;//*[@id=&quot;content&quot;]/div/div/figure/div[1]/div/div[1]/table&#39; #get the table nature_genetics_table2 &lt;- url %&gt;% read_html() %&gt;% html_nodes(xpath=table_path) %&gt;% html_table(fill=T) %&gt;% .</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/how-to-create-dummy-variables-and-normalization/">
                <h3 class="media-heading">3.3 How To Create Dummy Variables And Normalization</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Load Package And Data load(&quot;../../data/craet_3-2.Rdata&quot;) library(tidyverse) library(caret)  Why Dummy Variables å¯¹äºå­—ç¬¦å‹çš„å› å­å˜é‡ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå®ƒè½¬å˜ä¸ºæœ‰åºçš„æ•°å€¼ï¼Œä¸€èˆ¬è½¬ä¸º 0ï¼Œ1 çš„äºŒå˜é‡ï¼Œ è¿™æ ·0 å°±ä»£è¡¨åŸºç¡€æ°´å¹³ï¼Œ 1ä»£è¡¨æ¯”è¾ƒç»„
 How # One-Hot Encoding # Creating dummy variables is converting a categorical variable to as many binary variables as here are categories. dummies_model &lt;- dummyVars(Purchase ~ ., data=trainData) # Create the dummy variables using predict. The Y variable (Purchase) will not be present in trainData_mat. trainData_mat &lt;- predict(dummies_model, newdata = trainData) # # Convert to dataframe trainData &lt;- data.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/why-should-i-trust-you/">
                <h3 class="media-heading">Why should I trust you ğŸ¤–?</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ä¸»è¦é›†ä¸­åœ¨æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–ä¸Š; æœ€å¥½çš„æ¨¡å‹é€šå¸¸æ˜¯é€šè¿‡åƒç²¾åº¦æˆ–è€…é”™è¯¯è¿™æ ·çš„æ€§èƒ½åº¦é‡æ¥é€‰æ‹©çš„ï¼Œè€Œä¸”å¦‚æœå®ƒé€šè¿‡äº†è¿™äº›æ€§èƒ½æ ‡å‡†çš„æŸäº›é˜ˆå€¼ï¼Œæˆ‘ä»¬å€¾å‘äºå‡è®¾ä¸€ä¸ªæ¨¡å‹æ˜¯è¶³å¤Ÿå¥½çš„ã€‚åœ¨æœºå™¨å­¦ä¹ çš„è®¸å¤šåº”ç”¨ä¸­ï¼Œç”¨æˆ·ä¼šä½¿ç”¨ä¸€ä¸ªæ¨¡å‹æ¥å¸®åŠ©åšå†³å®šï¼Œ ä¾‹å¦‚ï¼šä¸€ä½åŒ»ç”Ÿä¸ä¼šå¯¹ç—…äººè¿›è¡Œæ‰‹æœ¯ï¼Œä»…ä»…å› ä¸ºè¿™ä¸ªæ¨¡å‹è¯´ä¸åº”è¯¥è¿›è¡Œæ‰‹æœ¯ï¼Ÿ
ç”±äºå¤æ‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯é»‘ç›’å­ï¼Œè€Œä¸”å¤ªå¤æ‚ï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹åšå‡ºçš„åˆ†ç±»å†³å®šé€šå¸¸å¾ˆéš¾è¢«äººç±»çš„å¤§è„‘æ‰€ç†è§£ï¼Œä½†æ˜¯èƒ½å¤Ÿç†è§£å’Œè§£é‡Šè¿™äº›æ¨¡å‹å¯¹äºæé«˜æ¨¡å‹è´¨é‡ï¼Œæé«˜ä¿¡ä»»åº¦å’Œé€æ˜åº¦ä»¥åŠå‡å°‘åè§éå¸¸é‡è¦ï¼Œå› ä¸ºäººç±»å¾€å¾€å…·æœ‰è‰¯å¥½çš„ç›´è§‰å’Œå› æœæ¨ç†ï¼Œè¿™äº›éƒ½æ˜¯éš¾ä»¥åœ¨æ•°æ®è¯„ä¼°æŒ‡æ ‡ä¸­æ•è·ã€‚
å› æ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå½¢è±¡çš„ç†è§£å®ƒä»¬çš„å·¥ä½œåŸç†ï¼šä¸ºä»€ä¹ˆä¸€ä¸ªæ¨¡å‹å°†å…·æœ‰ç‰¹å®šæ ‡ç­¾çš„æ¡ˆä¾‹è¿›è¡Œå‡†ç¡®åˆ†ç±»ã€‚eg: ä¸ºä»€ä¹ˆä¸€ä¸ªä¹³è…ºè‚¿å—æ ·æœ¬è¢«å½’ç±»ä¸ºâ€œæ¶æ€§â€è€Œä¸æ˜¯â€œè‰¯æ€§ï¼Œä»…ä»…å› ä¸ºå®ƒé•¿å¾—ä¸‘å—ï¼Ÿ
 Local Interpretable Model-Agnostic Explanations (LIME) is an attempt to make these complex models at least partly understandable. The method has been published in â€œWhy Should I Trust You?â€ Explaining the Predictions of Any Classifier. By Marco Tulio Ribeiro, Sameer Singh and Carlos Guestrin from the University of Washington in Seattle
 How LIME works  lime is able to explain all models for which we can obtain prediction probabilities (in R, that is every model that works with predict(type = â€œprobâ€)).</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/3-2-statistic-description-and-impute-missing-value/">
                <h3 class="media-heading">3.2 statistic description and impute missing value</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">åŠ è½½æ•°æ®å’ŒåŒ… load(&quot;../../data/caret.Rdata&quot;) library(tidyverse) library(caret) åœ¨è¿›è¡Œæ•°æ®æ•´ç†ä¹‹å‰ æˆ‘ä»¬å…ˆçœ‹çœ‹è®­ç»ƒæ•°æ®çš„ç»Ÿè®¡æè¿°
skimråŒ…å¯¹åˆ—çš„ç»Ÿè®¡æä¾›äº†æ–¹ä¾¿çš„å‡½æ•°
skimr::skim_to_wide() è¾“å‡ºä¸€ä¸ªåŒ…å«åˆ—ç»Ÿè®¡æè¿°çš„æ•°æ®æ¡†
library(skimr) skimmed &lt;- skim_to_wide(trainData) skimmed[, c(1:5, 9:11, 13, 15:16)] ## # A tibble: 18 x 11 ## type variable missing complete n mean sd p0 median p100 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 factor Purchase 0 857 857 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 factor Store7 0 857 857 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 integâ€¦ SpecialCH 2 855 857 &quot; 0.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/3-1-how-to-split-the-dataset-into-training-and-validation/">
                <h3 class="media-heading">3.1 How to split the dataset into training and validation?</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">æ•°æ®å‡†å¤‡å¥½äº†ä¹‹åçš„ç¬¬ä¸€æ­¥å°±æ˜¯æ‹†åˆ†æ•°æ®é›†ä¸ºè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ï¼Œä¸€èˆ¬æ˜¯ 8:2 çš„æ¯”ä¾‹ã€‚
ä¸ºä»€ä¹ˆæ‹†åˆ†æ•°æ®å‘¢ï¼Ÿ
å½“æˆ‘ä»¬åœ¨æ„å»ºä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹ä¸Šæ—¶ï¼ŒçœŸæ­£çš„ç›®çš„æ˜¯ä¸ºäº†é¢„æµ‹çœŸæ˜¯ä¸–ç•Œçš„æ•°æ®ï¼Œè€Œæœºå™¨å­¦ä¹ æ¨¡å‹æ˜¯ä¾é ç®—æ³•å­¦ä¹ è®­ç»ƒæ•°æ®å­¦ä¹ Y ä¸ X çš„å…³ç³»ï¼Œè¿™ç§çš„å…³ç³»çš„å­¦ä¹ å¥½åçš„è¯„åˆ¤æ˜¯è¦ä¾é æ²¡æœ‰å‚ä¸å­¦ä¹ æ¨¡å‹çš„æ•°æ®ä¸é¢„æµ‹æ•°æ®ä¹‹é—´çš„å·®è·æ¥è¯„åˆ¤çš„ã€‚
# Load the caret package library(caret) # Import dataset orange &lt;- read.csv(&#39;../../data/orange_juice_withmissing.csv&#39;) # Create the training and test datasets set.seed(100) # Step 1: Get row numbers for the training data trainRowNumbers &lt;- createDataPartition(orange$Purchase, p=0.8, list=FALSE) # Step 2: Create the training dataset trainData &lt;- orange[trainRowNumbers,] # Step 3: Create the test dataset testData &lt;- orange[-trainRowNumbers,] # Store X and Y for later use.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         16 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('https://i.loli.net/2018/02/26/5a9416186c149.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js" integrity="sha256-IFHWFEbU2/+wNycDECKgjIRSirRNIDp2acEB5fvdVRU=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js" integrity="sha256-+mpyNVJsNt4rVXCw0F+pAOiB3YxmHgrbJsx4ecPuUaI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js" integrity="sha256-vMxgR/7FtLovVA+IPrR7+xTgIgARH7y9VZQnmmi0HDI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js" integrity="sha256-N0qFUh7/9vLvia87dDndewmsgsyYoNkdA212tPc+2NI=" crossorigin="anonymous"></script>


<script src="/js/script-kr8dyqj6rb6ortyib7whfo9x9p6td6zo8t1v4fdz4ecx5kwybsdlmk1slygn.min.js"></script>


<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>

  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2018\/03\/why-should-i-trust-you\/';
          
            this.page.identifier = '\/2018\/03\/why-should-i-trust-you\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'jixing';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>

