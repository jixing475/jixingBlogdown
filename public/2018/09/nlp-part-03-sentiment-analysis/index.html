

  
    
  


  





  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.32.2 with theme Tranquilpeak 0.4.1-BETA">
    <title>NLP part 03 sentiment analysis</title>
    <meta name="author" content="Jixing Liu">
    <meta name="keywords" content="tech, R">

    <link rel="icon" href="img/R_py.png">
    

    
    <meta name="description" content="Case Study: Sentiment Analysis Data Prep import pandas as pd import numpy as np # Read in the data df = pd.read_csv(&#39;/Users/zero/Desktop/NLP/raw-data/Amazon_Unlocked_Mobile.csv&#39;) # 对数据进行采样以加快计算速度 # Comment out this line to match with lecture df = df.sample(frac=0.1, random_state=10) df.head()   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }   &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;Product Name&lt;/th&gt; &lt;th&gt;Brand Name&lt;/th&gt; &lt;th&gt;Price&lt;/th&gt; &lt;th&gt;Rating&lt;/th&gt; &lt;th&gt;Reviews&lt;/th&gt; &lt;th&gt;Review Votes&lt;/th&gt; &lt;/tr&gt;   &lt;tr&gt; &lt;th&gt;394349&lt;/th&gt; &lt;td&gt;Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat.">
    <meta property="og:description" content="Case Study: Sentiment Analysis Data Prep import pandas as pd import numpy as np # Read in the data df = pd.read_csv(&#39;/Users/zero/Desktop/NLP/raw-data/Amazon_Unlocked_Mobile.csv&#39;) # 对数据进行采样以加快计算速度 # Comment out this line to match with lecture df = df.sample(frac=0.1, random_state=10) df.head()   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }   &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;Product Name&lt;/th&gt; &lt;th&gt;Brand Name&lt;/th&gt; &lt;th&gt;Price&lt;/th&gt; &lt;th&gt;Rating&lt;/th&gt; &lt;th&gt;Reviews&lt;/th&gt; &lt;th&gt;Review Votes&lt;/th&gt; &lt;/tr&gt;   &lt;tr&gt; &lt;th&gt;394349&lt;/th&gt; &lt;td&gt;Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat.">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="NLP part 03 sentiment analysis">
    <meta property="og:url" content="/2018/09/nlp-part-03-sentiment-analysis/">
    <meta property="og:site_name" content="student zero ">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="student zero ">
    <meta name="twitter:description" content="Case Study: Sentiment Analysis Data Prep import pandas as pd import numpy as np # Read in the data df = pd.read_csv(&#39;/Users/zero/Desktop/NLP/raw-data/Amazon_Unlocked_Mobile.csv&#39;) # 对数据进行采样以加快计算速度 # Comment out this line to match with lecture df = df.sample(frac=0.1, random_state=10) df.head()   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }   &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;Product Name&lt;/th&gt; &lt;th&gt;Brand Name&lt;/th&gt; &lt;th&gt;Price&lt;/th&gt; &lt;th&gt;Rating&lt;/th&gt; &lt;th&gt;Reviews&lt;/th&gt; &lt;th&gt;Review Votes&lt;/th&gt; &lt;/tr&gt;   &lt;tr&gt; &lt;th&gt;394349&lt;/th&gt; &lt;td&gt;Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat.">
    
      <meta name="twitter:creator" content="@studentZero475">
    
    

    
    

    
      <meta property="og:image" content="https://i.loli.net/2018/02/26/5a937bb148b02.jpg">
    

    
      <meta property="og:image" content="https://i.loli.net/2018/08/13/5b70bd4dc9763.jpg">
    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-hbs5om8csx9a8yrv5hnhpi2qqdv4ykuslajwbramhqxvleqbfklxgek50hye.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <link rel="stylesheet" href="/css/monokai-sublime.css" rel="stylesheet" id="theme-stylesheet">
<script src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">student zero </a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <h1 class="sidebar-profile-title">NLP part 03 sentiment analysis</h1>
        <a href="/#about">
          <img class="sidebar-profile-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Jixing Liu</h4>
        
          <h5 class="sidebar-profile-bio">Reading And Writing</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives/">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories/">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags/">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/page/about/">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://twitter.com/studentZero475">
    
      <i class="sidebar-button-icon fa fa-lg fa-twitter"></i>
      
      <span class="sidebar-button-desc">Twitter</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.r-bloggers.com/">
    
      <i class="sidebar-button-icon fa fa-lg fa-book"></i>
      
      <span class="sidebar-button-desc">R-bloggers</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      

    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaOut
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-center">
  
    <h1 class="post-title" itemprop="headline">
      NLP part 03 sentiment analysis
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-09-17T00:00:00Z">
        
  September 17, 2018

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/machine-learning">machine learning</a>
    
  


  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <!--more-->
<div id="case-study-sentiment-analysis" class="section level1">
<h1>Case Study: Sentiment Analysis</h1>
<div id="data-prep" class="section level3">
<h3>Data Prep</h3>
<pre class="python"><code>import pandas as pd
import numpy as np

# Read in the data
df = pd.read_csv(&#39;/Users/zero/Desktop/NLP/raw-data/Amazon_Unlocked_Mobile.csv&#39;)

# 对数据进行采样以加快计算速度
# Comment out this line to match with lecture
df = df.sample(frac=0.1, random_state=10)

df.head()</code></pre>
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
<thead>
<pre><code>&lt;tr style=&quot;text-align: right;&quot;&gt;
  &lt;th&gt;&lt;/th&gt;
  &lt;th&gt;Product Name&lt;/th&gt;
  &lt;th&gt;Brand Name&lt;/th&gt;
  &lt;th&gt;Price&lt;/th&gt;
  &lt;th&gt;Rating&lt;/th&gt;
  &lt;th&gt;Reviews&lt;/th&gt;
  &lt;th&gt;Review Votes&lt;/th&gt;
&lt;/tr&gt;</code></pre>
</thead>
<tbody>
<pre><code>&lt;tr&gt;
  &lt;th&gt;394349&lt;/th&gt;
  &lt;td&gt;Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat...&lt;/td&gt;
  &lt;td&gt;NaN&lt;/td&gt;
  &lt;td&gt;244.95&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;Very good one! Better than Samsung S and iphon...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;34377&lt;/th&gt;
  &lt;td&gt;Apple iPhone 5c 8GB (Pink) - Verizon Wireless&lt;/td&gt;
  &lt;td&gt;Apple&lt;/td&gt;
  &lt;td&gt;194.99&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
  &lt;td&gt;The phone needed a SIM card, would have been n...&lt;/td&gt;
  &lt;td&gt;1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;248521&lt;/th&gt;
  &lt;td&gt;Motorola Droid RAZR MAXX XT912 M Verizon Smart...&lt;/td&gt;
  &lt;td&gt;Motorola&lt;/td&gt;
  &lt;td&gt;174.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I was 3 months away from my upgrade and my Str...&lt;/td&gt;
  &lt;td&gt;3.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;167661&lt;/th&gt;
  &lt;td&gt;CNPGD [U.S. Office Extended Warranty] Smartwat...&lt;/td&gt;
  &lt;td&gt;CNPGD&lt;/td&gt;
  &lt;td&gt;49.99&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
  &lt;td&gt;an experience i want to forget&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;73287&lt;/th&gt;
  &lt;td&gt;Apple iPhone 7 Unlocked Phone 256 GB - US Vers...&lt;/td&gt;
  &lt;td&gt;Apple&lt;/td&gt;
  &lt;td&gt;922.00&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;GREAT PHONE WORK ACCORDING MY EXPECTATIONS.&lt;/td&gt;
  &lt;td&gt;1.0&lt;/td&gt;
&lt;/tr&gt;</code></pre>
</tbody>
</table>
</div>
<pre class="python"><code>np.where(df[&#39;Rating&#39;] &gt; 3, 1, 0)</code></pre>
<pre><code>array([1, 0, 1, ..., 1, 0, 0])</code></pre>
<pre class="python"><code># Drop missing values
df.dropna(inplace=True)

# Remove any &#39;neutral&#39; ratings equal to 3
# filter rows
df = df[df[&#39;Rating&#39;] != 3]

# Encode 4s and 5s as 1 (rated positively)
# Encode 1s and 2s as 0 (rated poorly)
# class labels
df[&#39;Positively Rated&#39;] = np.where(df[&#39;Rating&#39;] &gt; 3, 1, 0)
df.head(10)</code></pre>
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
<thead>
<pre><code>&lt;tr style=&quot;text-align: right;&quot;&gt;
  &lt;th&gt;&lt;/th&gt;
  &lt;th&gt;Product Name&lt;/th&gt;
  &lt;th&gt;Brand Name&lt;/th&gt;
  &lt;th&gt;Price&lt;/th&gt;
  &lt;th&gt;Rating&lt;/th&gt;
  &lt;th&gt;Reviews&lt;/th&gt;
  &lt;th&gt;Review Votes&lt;/th&gt;
  &lt;th&gt;Positively Rated&lt;/th&gt;
&lt;/tr&gt;</code></pre>
</thead>
<tbody>
<pre><code>&lt;tr&gt;
  &lt;th&gt;34377&lt;/th&gt;
  &lt;td&gt;Apple iPhone 5c 8GB (Pink) - Verizon Wireless&lt;/td&gt;
  &lt;td&gt;Apple&lt;/td&gt;
  &lt;td&gt;194.99&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
  &lt;td&gt;The phone needed a SIM card, would have been n...&lt;/td&gt;
  &lt;td&gt;1.0&lt;/td&gt;
  &lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;248521&lt;/th&gt;
  &lt;td&gt;Motorola Droid RAZR MAXX XT912 M Verizon Smart...&lt;/td&gt;
  &lt;td&gt;Motorola&lt;/td&gt;
  &lt;td&gt;174.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I was 3 months away from my upgrade and my Str...&lt;/td&gt;
  &lt;td&gt;3.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;167661&lt;/th&gt;
  &lt;td&gt;CNPGD [U.S. Office Extended Warranty] Smartwat...&lt;/td&gt;
  &lt;td&gt;CNPGD&lt;/td&gt;
  &lt;td&gt;49.99&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
  &lt;td&gt;an experience i want to forget&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;73287&lt;/th&gt;
  &lt;td&gt;Apple iPhone 7 Unlocked Phone 256 GB - US Vers...&lt;/td&gt;
  &lt;td&gt;Apple&lt;/td&gt;
  &lt;td&gt;922.00&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;GREAT PHONE WORK ACCORDING MY EXPECTATIONS.&lt;/td&gt;
  &lt;td&gt;1.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;277158&lt;/th&gt;
  &lt;td&gt;Nokia N8 Unlocked GSM Touch Screen Phone Featu...&lt;/td&gt;
  &lt;td&gt;Nokia&lt;/td&gt;
  &lt;td&gt;95.00&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I fell in love with this phone because it did ...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;100311&lt;/th&gt;
  &lt;td&gt;Blackberry Torch 2 9810 Unlocked Phone with 1....&lt;/td&gt;
  &lt;td&gt;BlackBerry&lt;/td&gt;
  &lt;td&gt;77.49&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I am pleased with this Blackberry phone! The p...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;251669&lt;/th&gt;
  &lt;td&gt;Motorola Moto E (1st Generation) - Black - 4 G...&lt;/td&gt;
  &lt;td&gt;Motorola&lt;/td&gt;
  &lt;td&gt;89.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;Great product, best value for money smartphone...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;279878&lt;/th&gt;
  &lt;td&gt;OtterBox 77-29864 Defender Series Hybrid Case ...&lt;/td&gt;
  &lt;td&gt;OtterBox&lt;/td&gt;
  &lt;td&gt;9.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I&#39;ve bought 3 no problems. Fast delivery.&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;406017&lt;/th&gt;
  &lt;td&gt;Verizon HTC Rezound 4G Android Smarphone - 8MP...&lt;/td&gt;
  &lt;td&gt;HTC&lt;/td&gt;
  &lt;td&gt;74.99&lt;/td&gt;
  &lt;td&gt;4&lt;/td&gt;
  &lt;td&gt;Great phone for the price...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;302567&lt;/th&gt;
  &lt;td&gt;RCA M1 Unlocked Cell Phone, Dual Sim, 5Mp Came...&lt;/td&gt;
  &lt;td&gt;RCA&lt;/td&gt;
  &lt;td&gt;159.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;My mom is not good with new technoloy but this...&lt;/td&gt;
  &lt;td&gt;4.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;</code></pre>
</tbody>
</table>
</div>
<pre class="python"><code># Most ratings are positive
# More than 50% is positive
df[&#39;Positively Rated&#39;].mean()</code></pre>
<pre><code>0.7471776686078667</code></pre>
<pre class="python"><code>from sklearn.model_selection import train_test_split

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(df[&#39;Reviews&#39;], 
                                                    df[&#39;Positively Rated&#39;], 
                                                    random_state=0)</code></pre>
<pre class="python"><code>print(&#39;X_train first entry:\n\n&#39;, X_train.iloc[0])
print(&#39;\n\nX_train shape: &#39;, X_train.shape)</code></pre>
<pre><code>X_train first entry:

 Everything about it is awesome!


X_train shape:  (23052,)</code></pre>
</div>
</div>
<div id="countvectorizer" class="section level1">
<h1>CountVectorizer</h1>
<p>Construct a sparse matrix</p>
<pre class="python"><code>from sklearn.feature_extraction.text import CountVectorizer

# Fit the CountVectorizer to the training data
# init countvertoizer
init_countVectorizer = CountVectorizer()
# and then fit it
vect = init_countVectorizer.fit(X_train)</code></pre>
<pre class="python"><code># step is 2000
#sparse matrix
vect.get_feature_names()[::2000]</code></pre>
<pre><code>[&#39;00&#39;,
 &#39;arroja&#39;,
 &#39;comapañias&#39;,
 &#39;dvds&#39;,
 &#39;golden&#39;,
 &#39;lands&#39;,
 &#39;oil&#39;,
 &#39;razonable&#39;,
 &#39;smallsliver&#39;,
 &#39;tweak&#39;]</code></pre>
<pre class="python"><code>len(vect.get_feature_names())</code></pre>
<pre><code>19601</code></pre>
<pre class="python"><code>19601/2000</code></pre>
<pre><code>9.8005</code></pre>
<pre class="python"><code># transform the documents in the training data to a document-term matrix
X_train_vectorized = vect.transform(X_train)

X_train_vectorized</code></pre>
<pre><code>&lt;23052x19601 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;
    with 613289 stored elements in Compressed Sparse Row format&gt;</code></pre>
<pre class="python"><code>print(type(X_train_vectorized)) </code></pre>
<pre><code>&lt;class &#39;scipy.sparse.csr.csr_matrix&#39;&gt;</code></pre>
<pre class="python"><code>from sklearn.linear_model import LogisticRegression

# Train the model
model = LogisticRegression()
model.fit(X_train_vectorized, y_train)</code></pre>
<pre><code>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,
          penalty=&#39;l2&#39;, random_state=None, solver=&#39;liblinear&#39;, tol=0.0001,
          verbose=0, warm_start=False)</code></pre>
<pre class="python"><code>from sklearn.metrics import roc_auc_score

# Predict the transformed test documents
predictions = model.predict(vect.transform(X_test))

print(&#39;AUC: &#39;, roc_auc_score(y_test, predictions))</code></pre>
<pre><code>AUC:  0.897433277667</code></pre>
<pre class="python"><code># get the feature names as numpy array
feature_names = np.array(vect.get_feature_names())

# Sort the coefficients from the model
sorted_coef_index = model.coef_[0].argsort()

# Find the 10 smallest and 10 largest coefficients
# The 10 largest coefficients are being indexed using [:-11:-1] 
# so the list returned is in order of largest to smallest
print(&#39;Smallest Coefs:\n{}\n&#39;.format(feature_names[sorted_coef_index[:10]]))
print(&#39;Largest Coefs: \n{}&#39;.format(feature_names[sorted_coef_index[:-11:-1]]))</code></pre>
<pre><code>Smallest Coefs:
[&#39;worst&#39; &#39;terrible&#39; &#39;slow&#39; &#39;junk&#39; &#39;poor&#39; &#39;sucks&#39; &#39;horrible&#39; &#39;useless&#39;
 &#39;waste&#39; &#39;disappointed&#39;]

Largest Coefs: 
[&#39;excelent&#39; &#39;excelente&#39; &#39;excellent&#39; &#39;perfectly&#39; &#39;love&#39; &#39;perfect&#39; &#39;exactly&#39;
 &#39;great&#39; &#39;best&#39; &#39;awesome&#39;]</code></pre>
</div>
<div id="tfidf" class="section level1">
<h1>Tfidf</h1>
<p>🔥 feature: limit frequency threshold</p>
<pre class="python"><code>from sklearn.feature_extraction.text import TfidfVectorizer

# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5
vect = TfidfVectorizer(min_df=5).fit(X_train)
len(vect.get_feature_names())</code></pre>
<pre><code>5442</code></pre>
<pre class="python"><code>X_train_vectorized = vect.transform(X_train)

model = LogisticRegression()
model.fit(X_train_vectorized, y_train)

predictions = model.predict(vect.transform(X_test))

print(&#39;AUC: &#39;, roc_auc_score(y_test, predictions))</code></pre>
<pre><code>AUC:  0.889951006492</code></pre>
<pre class="python"><code>feature_names = np.array(vect.get_feature_names())

sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()

print(&#39;Smallest tfidf:\n{}\n&#39;.format(feature_names[sorted_tfidf_index[:10]]))
print(&#39;Largest tfidf: \n{}&#39;.format(feature_names[sorted_tfidf_index[:-11:-1]]))</code></pre>
<pre><code>Smallest tfidf:
[&#39;61&#39; &#39;printer&#39; &#39;approach&#39; &#39;adjustment&#39; &#39;consequences&#39; &#39;length&#39; &#39;emailing&#39;
 &#39;degrees&#39; &#39;handsfree&#39; &#39;chipset&#39;]

Largest tfidf: 
[&#39;unlocked&#39; &#39;handy&#39; &#39;useless&#39; &#39;cheat&#39; &#39;up&#39; &#39;original&#39; &#39;exelent&#39; &#39;exelente&#39;
 &#39;exellent&#39; &#39;satisfied&#39;]</code></pre>
<pre class="python"><code>sorted_coef_index = model.coef_[0].argsort()

print(&#39;Smallest Coefs:\n{}\n&#39;.format(feature_names[sorted_coef_index[:10]]))
print(&#39;Largest Coefs: \n{}&#39;.format(feature_names[sorted_coef_index[:-11:-1]]))</code></pre>
<pre><code>Smallest Coefs:
[&#39;not&#39; &#39;slow&#39; &#39;disappointed&#39; &#39;worst&#39; &#39;terrible&#39; &#39;never&#39; &#39;return&#39; &#39;doesn&#39;
 &#39;horrible&#39; &#39;waste&#39;]

Largest Coefs: 
[&#39;great&#39; &#39;love&#39; &#39;excellent&#39; &#39;good&#39; &#39;best&#39; &#39;perfect&#39; &#39;price&#39; &#39;awesome&#39; &#39;far&#39;
 &#39;perfectly&#39;]</code></pre>
<pre class="python"><code>vect.transform([&#39;not an issue, phone is working&#39;,
                                    &#39;an issue, phone is not working&#39;])</code></pre>
<pre><code>&lt;2x5442 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;
    with 12 stored elements in Compressed Sparse Row format&gt;</code></pre>
<pre class="python"><code># These reviews are treated the same by our current model
print(model.predict(vect.transform([&#39;not an issue, phone is working&#39;,
                                    &#39;an issue, phone is not working&#39;])))</code></pre>
<pre><code>[0 0]</code></pre>
</div>
<div id="n-grams" class="section level1">
<h1>n-grams</h1>
<p>🔥 “back as” or “is not” is grams</p>
<pre class="python"><code># Fit the CountVectorizer to the training data specifiying a minimum 
# document frequency of 5 and extracting 1-grams and 2-grams
# min_df
# ngram_range

vect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)

X_train_vectorized = vect.transform(X_train)

len(vect.get_feature_names())</code></pre>
<pre><code>29072</code></pre>
<pre class="python"><code>vect.get_feature_names()[3000:3010]</code></pre>
<pre><code>[&#39;back as&#39;,
 &#39;back asap&#39;,
 &#39;back because&#39;,
 &#39;back but&#39;,
 &#39;back button&#39;,
 &#39;back camera&#39;,
 &#39;back case&#39;,
 &#39;back cover&#39;,
 &#39;back for&#39;,
 &#39;back from&#39;]</code></pre>
<pre class="python"><code>model = LogisticRegression()
model.fit(X_train_vectorized, y_train)

predictions = model.predict(vect.transform(X_test))

print(&#39;AUC: &#39;, roc_auc_score(y_test, predictions))</code></pre>
<pre><code>AUC:  0.91106617946</code></pre>
<pre class="python"><code>feature_names = np.array(vect.get_feature_names())

sorted_coef_index = model.coef_[0].argsort()

print(&#39;Smallest Coefs:\n{}\n&#39;.format(feature_names[sorted_coef_index[:10]]))
print(&#39;Largest Coefs: \n{}&#39;.format(feature_names[sorted_coef_index[:-11:-1]]))</code></pre>
<pre><code>Smallest Coefs:
[&#39;no good&#39; &#39;junk&#39; &#39;poor&#39; &#39;slow&#39; &#39;worst&#39; &#39;broken&#39; &#39;not good&#39; &#39;terrible&#39;
 &#39;defective&#39; &#39;horrible&#39;]

Largest Coefs: 
[&#39;excellent&#39; &#39;excelente&#39; &#39;excelent&#39; &#39;perfect&#39; &#39;great&#39; &#39;love&#39; &#39;awesome&#39;
 &#39;no problems&#39; &#39;good&#39; &#39;best&#39;]</code></pre>
<pre class="python"><code># These reviews are now correctly identified
# why 🤔
print(model.predict(vect.transform([&#39;not an issue, phone is working&#39;,
                                    &#39;an issue, phone is not working&#39;])))</code></pre>
<pre><code>[1 0]</code></pre>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="//tags/nlp/">NLP</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/09/nlp-part04-word-count-use-r/" data-tooltip="NLP part04 word count use R">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/09/nlp-part-03-sentiment-analysis/" data-tooltip="NLP part 03 sentiment analysis">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/09/nlp-part-03-sentiment-analysis/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/09/nlp-part-03-sentiment-analysis/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/09/nlp-part-03-sentiment-analysis/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2019 Jixing Liu. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/09/nlp-part04-word-count-use-r/" data-tooltip="NLP part04 word count use R">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/09/nlp-part-03-sentiment-analysis/" data-tooltip="NLP part 03 sentiment analysis">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/09/nlp-part-03-sentiment-analysis/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/09/nlp-part-03-sentiment-analysis/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/09/nlp-part-03-sentiment-analysis/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2018%2F09%2Fnlp-part-03-sentiment-analysis%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2018%2F09%2Fnlp-part-03-sentiment-analysis%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2F2018%2F09%2Fnlp-part-03-sentiment-analysis%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Jixing Liu</h4>
    
      <div id="about-card-bio">Reading And Writing</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Data Scientist
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        China
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/06/multi-classfication-machine-learning/">
                <h3 class="media-heading">multi-classfication machine learning</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"> </div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/06/multi-label-classfication/">
                <h3 class="media-heading">多标签分类问题</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Difference between multi-class classification &amp; multi-label classification is that in multi-class problems the classes are mutually exclusive, whereas for multi-label problems each label represents a different classification task, but the tasks are somehow related.
  multi-class classification makes the assumption that each sample is assigned to one and only one label: a fruit can be either an apple or a pear but not both at the same time.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/06/drug-discovery/">
                <h3 class="media-heading">新药研发</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">确定致病机制 1. 皇后确诊乳腺癌  2. 药物遍寻均无效  3. 精准医疗项目启动 生物信息分析 特异化突变基因鉴定 蛋白通路与疾病关联性 XYZ蛋白三维晶体结构 XYZ蛋白药物结合口袋突变前后分析    先导化合物 1. 计算机辅助药物设计:  在 蛋白质三维结构基础上，彻底分析突变后XYZ蛋白结合口袋周围理化性质
 突变前：小分子包围在疏水口袋，亲水氨基酸R125、E154与其形成氢键铆钉作用，使其牢牢稳固在蛋白质中 突变后：疏水环境大致不变，但氨基酸N125、I154(无法形成氢键)造成很大空隙，亲水性转换为疏水口袋，稳定性降低     2. 分子动力学方法  分子动力学方法对XYZ蛋白突变后与小分子Hormone间相互作用状况进行了计算模拟分析, 目的:以期得到蛋白质在突变后的小分子结合信息
 计算中心首席科学家是这么解释分析结果的:
突变后XYZ蛋白Region A区域没有变化，对该部分不做任何修改； Region B区域中，小分子下方出现巨大空洞，需要对该部分进行补漏； Region B区域巨大空袭，在小分子稳定结合时，下方出现由10~13个水分子组成的“水氢键网络体系”； “水氢键网络体系”中，水分子能量Energy（球体大小）和占有率Occupancy（球体颜色）均能表达出蛋白质局部区域理化性质。 &gt; 具体总结：Region B区域绝大多数水分子能量Energy极小、占有率Occupancy较小，说明该区域极为疏水；但其中W1水分子，能量较好、占有率较高，说明W1水分子极为稳定，周围氨基酸为极亲水性氨基酸，将来可以通过替换W1水分子或通过桥键作用对其进行化学修饰  ; ;
 3. 基于体内原生激素Hormone的药物设计:化学片段增长设计法  首先设计的化学片段，将能够有效的到达W1水分子附近或将其替换掉, 福斯坦国立大学化学院研究团队，共设计母核结构50枚，且均具备有机合成实验方法实现的可能性
 ; ;
 4. 分子对接方法判定最佳化学母核结构  利用分子对接方法，将50枚母核结构分别对接进入突变后蛋白质XYZ结构中， 利用分子对接权重值, 判定3枚小分子药物在对接结果中占据较好的权重位置。奥古斯汀·Khan将此结果呈现给，福斯坦国立大学化学院研究团队，经过再三斟酌分析，决定采用C2、C1和C3进行后期化学结构改造
      5.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/06/deep-work/">
                <h3 class="media-heading">Deep Work</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">最近在读 卡尔.纽波特的 深度工作, 以下是阅读的一点感悟和笔记.
 深度工作是 21 世纪的超级力量
 作者介绍: 卡尔·纽波特，畅销书作家，人气博主，创办了在美国很受欢迎的博客“学习黑客”，破解工作和学习领域的成功模式。
 关于本书 这是一本自我管理类书籍，讲述了在碎片化时代，如何训练大脑排除干扰，提高大脑的深度思维能力，创造更多价值。这本书的英文原版2016年在美国出版，一发行就占据了亚马逊美国网站的职场励志书榜首。
几个问题:
在职场中，为什么有些人越忙碌越无法产出有价值的成果？ 又该如何通过训练大脑排除干扰，提高深度思维能力，创造更多价值？  这本书从2个方面解释了大部分人无法进行深度工作的原因，并给出了培养深度工作的4个步骤，分别是:
选择适合自己的深度工作模式 将工作内化成习惯 像经商一样去执行 适当减少整体工作时间遵循这几个步骤进行刻意练习   概念介绍 深度工作(Deep Work): 在没有干扰的情况下专注的进行职业活动, 使个人的认知能力达到极限, 这种努力能够创造新价值, 提升技能, 而且难以复制.
肤浅工作(shallow work): 对认知要求不高的任务, 在收到干扰的情况下也能进行, 此类工作创造的价值不高, 且容易复制.
 深度工作的重要性 作者前面花了大量篇幅说明深度工作的重要性, 其中关于注意的论断深以为然.
快速学习复杂的技能, 这能为我们带来价值, 这件事需要深度工作.
但是现实生活中, 网络工具使我们分心, 导致专注能力的下降. 不分心是很难的, 我们都有一种冲动就是, 把自己的注意力转移到肤浅的事物上.
比如, 工作累了或者遇到难题了就要刷刷社交网络, 但是这种行为其实还是在消耗着你的注意力和能量. 你的意志力是有限的, 它在使用的过程中是不断的被消耗的. 而进入深度工作状态是需要意志力能量, 如何使得这个转化过程变得容易使我们应该掌握的技巧. 简而言之, 我们增加深度工作的评率, 而减小转移到肤浅工作的冲动和频率. 我们都有过类似的经历, 打开 word 文档, 准备写论文和报告, 一瞬间脑袋空白, 这时候平时不相干的事情, 突然都变得可爱起来, 比如: 洗完, 扫地, 洗衣服, 收拾房间, 下楼买💊, 总之只要是不是写论文, 什么其他能拖延这件事情的事, 我们都愿意干.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/05/the-hello-world-of-neural-network/">
                <h3 class="media-heading">The Hello World Of Neural Network</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  May 5, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">简单来说神经网络和我们一般的编程区别在于: 一个是输入数据和函数规则, 然后得到结果. 而神经网络是输入数据和答案, 通过迭代学习, 神经网络能学习出函数规则.如下图:
举个简单的例子, 这里有两组数据:
X: -1, 0, 1, 2, 3, 4 Y: -3, -1, 1, 3, 5, 7
你可以把 x 看做是数据, y 看做是答案, 现在你要做的是找到其中的函数关系, 这个关系能够帮助我们, 用 x 去预测 Y 的值(假设你没有学过解方程组).
最常用的方法就是归纳法, 首先你根据第一对数据猜一个对应关系规则, 拿着这个规则计算答案值, 评估计算的答案和真实答案差多远, 然后在调整你的规则, 继续评估, 直到你的规则能够拟合所有的数据.
这就是神经网络的逻辑过程.
我们来看一个简单的神经网络的例子
1.Import: 加载所需模块 import tensorflow as tf ## /Users/zero/anaconda3/envs/tfdeeplearning/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module &#39;tensorflow.python.framework.fast_tensor_util&#39; does not match runtime version 3.5 ## return f(*args, **kwds) import numpy as np from tensorflow import keras  2.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/04/analyze-and-visualize-your-iphone-s-health-app-data-in-r/">
                <h3 class="media-heading">使用 R 分析可视化你的 iPhone 健康 APP 数据</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">介绍 iPhone 的 health APP 存储着我们的私人健康数据, 这里有一篇帖子是用 Python 分析 health APP 的数据Apple Health Data How to Export Analyze Visualize Guide - ryanpraski.com , 而我更喜欢 R 的版本.
让我们赶紧开始吧!!
 首先获取数据并读取 从你的 health APP 应用中导出数据 在 R 中读取数据  加载包并读入数据 library(XML) library(tidyverse) library(lubridate) library(scales) library(here) library(ggthemes) xml &lt;- xmlParse(here(&quot;data/apple_health_export/export.xml&quot;)) summary(xml) ## $nameCounts ## ## Record ExportDate HealthData Me Workout ## 90037 1 1 1 1 ## ## $numNodes ## [1] 90041 Record 是我的主要数据, 有 90,037 条</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/03/tao_wang_bei_shang_guang/">
                <h3 class="media-heading">逃往北上广</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">奋斗，应该是一种生活方式, 登山并不全是为了登顶的那一刻
 只有不停奋斗的人生，才有意义，才活的有劲儿，混吃等死的日子其实是很艰难的，无聊死了，一头扎进人堆儿里不停的扑棱才有意思啊！
逃往北京、上海、广州、深圳
在家乡，在那个你生长了二三十年的小城镇，如果你拒绝过上和所有人一样循规蹈矩的生活，拒绝结婚生子，拒绝稳定工作，拒绝放弃影响你赚钱升职的爱好，那么你就变成了一头和周围的一切格格不入的怪物。
于是大家要挽救你，要教育你，要让你学会认命，停止毫无意义的折腾，这样你才能和大家一样“踏踏实实过日子”。
许多人因此选择了对抗，在愤怒中慢慢变得绝望，在绝望中变得麻木，在麻木中逃往虚无</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/10/pubchunks_extract_parts_of_scholarly_xml_articles/">
                <h3 class="media-heading">pubchunks：提取学术文章的某部分</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">背景 pubchunks 的目的是从XML格式的学术文章中获取部分数据。我们不需要了解XML及其所有的格式原理。只需知道我们的文件或XML字符串在哪里以及我们想要每篇文章的哪些部分。然后用户可以组合这些部分并做我们希望下游的任何事情; 例如,分析文本结构
 pubchunks中的函数 两个主要功能是：
pub_chunks()：获取XML部分 pub_tabularize()：强制输出pub_chunks()到data.frame中 pub_guess_publisher()：从XML文件或字符串猜测发布者 pub_sections()：部分pubchunks知道如何处理 pub_providers()：提供者（即发布者）pubchunks知道如何明确处理   支持的出版商 elife plos elsevier hindawi pensoft peerj copernicus frontiers f1000research   支持提取的部分有: Front - 发布者，期刊和文章元数据元素 Body - 文章的正文 Back - 文章的背面，致谢，作者贡献，参考文献 Title - 文章标题 Doi - 文章doi Categories - 发布商的类别，如果有的话 Author - 作者 Aff - 隶属关系（包括作者姓名） Keyword - 关键字 Abstract - 文章摘要 Executive_summary - 文章执行摘要 Refs - 参考文献 Refs_dois - 参考dois - 如果有的话 Publisher - 发布者名称 Journal_meta - 期刊元数据 Article_meta - 文章元数据 Acknowledgments - 致谢 Permissions - 文章权限 History - 日期，收到，出版，接受等   安装 #install.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/09/nlp-part04-word-count-use-r/">
                <h3 class="media-heading">NLP part04 word count use R</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Sep 9, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">What Is Clean Data Each variable is a column Each observation is a row Each type of observational unit is a table   A table with one-token-per-row.  A token is a meaningful unit of text, such as a word, that we are interested in using for analysis, and tokenization is the process of splitting text into tokens.
 text &lt;- c( &quot;Because I could not stop for Death -&quot;, &quot;He kindly stopped for me -&quot;, &quot;The Carriage held but just Ourselves -&quot;, &quot;and Immortality&quot; ) text ## [1] &quot;Because I could not stop for Death -&quot; ## [2] &quot;He kindly stopped for me -&quot; ## [3] &quot;The Carriage held but just Ourselves -&quot; ## [4] &quot;and Immortality&quot; library(dplyr) text_df &lt;- data_frame(line = 1:4, text = text) text_df ## # A tibble: 4 x 2 ## line text ## &lt;int&gt; &lt;chr&gt; ## 1 1 Because I could not stop for Death - ## 2 2 He kindly stopped for me - ## 3 3 The Carriage held but just Ourselves - ## 4 4 and Immortality library(tidytext) text_df %&gt;% unnest_tokens(word, text) ## # A tibble: 20 x 2 ## line word ## &lt;int&gt; &lt;chr&gt; ## 1 1 because ## 2 1 i ## 3 1 could ## 4 1 not ## 5 1 stop ## 6 1 for ## 7 1 death ## 8 2 he ## 9 2 kindly ## 10 2 stopped ## 11 2 for ## 12 2 me ## 13 3 the ## 14 3 carriage ## 15 3 held ## 16 3 but ## 17 3 just ## 18 3 ourselves ## 19 4 and ## 20 4 immortality For tidy text mining, the token that is stored in each row is most often a single word, but can also be an n-gram, sentence, or paragraph</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/09/nlp-part-03-sentiment-analysis/">
                <h3 class="media-heading">NLP part 03 sentiment analysis</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Sep 9, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Case Study: Sentiment Analysis Data Prep import pandas as pd import numpy as np # Read in the data df = pd.read_csv(&#39;/Users/zero/Desktop/NLP/raw-data/Amazon_Unlocked_Mobile.csv&#39;) # 对数据进行采样以加快计算速度 # Comment out this line to match with lecture df = df.sample(frac=0.1, random_state=10) df.head()   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }   &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;Product Name&lt;/th&gt; &lt;th&gt;Brand Name&lt;/th&gt; &lt;th&gt;Price&lt;/th&gt; &lt;th&gt;Rating&lt;/th&gt; &lt;th&gt;Reviews&lt;/th&gt; &lt;th&gt;Review Votes&lt;/th&gt; &lt;/tr&gt;   &lt;tr&gt; &lt;th&gt;394349&lt;/th&gt; &lt;td&gt;Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         57 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('https://i.loli.net/2018/02/26/5a9416186c149.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js" integrity="sha256-IFHWFEbU2/+wNycDECKgjIRSirRNIDp2acEB5fvdVRU=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js" integrity="sha256-+mpyNVJsNt4rVXCw0F+pAOiB3YxmHgrbJsx4ecPuUaI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js" integrity="sha256-vMxgR/7FtLovVA+IPrR7+xTgIgARH7y9VZQnmmi0HDI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js" integrity="sha256-N0qFUh7/9vLvia87dDndewmsgsyYoNkdA212tPc+2NI=" crossorigin="anonymous"></script>


<script src="/js/script-kr8dyqj6rb6ortyib7whfo9x9p6td6zo8t1v4fdz4ecx5kwybsdlmk1slygn.min.js"></script>


<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>

  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2018\/09\/nlp-part-03-sentiment-analysis\/';
          
            this.page.identifier = '\/2018\/09\/nlp-part-03-sentiment-analysis\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'jixing';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>

