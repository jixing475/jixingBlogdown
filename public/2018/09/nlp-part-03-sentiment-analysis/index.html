

  
    
  


  





  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.32.2 with theme Tranquilpeak 0.4.1-BETA">
    <title>NLP part 03 sentiment analysis</title>
    <meta name="author" content="Jixing Liu">
    <meta name="keywords" content="tech, R">

    <link rel="icon" href="img/R_py.png">
    

    
    <meta name="description" content="Case Study: Sentiment Analysis Data Prep import pandas as pd import numpy as np # Read in the data df = pd.read_csv(&#39;/Users/zero/Desktop/NLP/raw-data/Amazon_Unlocked_Mobile.csv&#39;) # å¯¹æ•°æ®è¿›è¡Œé‡‡æ ·ä»¥åŠ å¿«è®¡ç®—é€Ÿåº¦ # Comment out this line to match with lecture df = df.sample(frac=0.1, random_state=10) df.head()   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }   &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;Product Name&lt;/th&gt; &lt;th&gt;Brand Name&lt;/th&gt; &lt;th&gt;Price&lt;/th&gt; &lt;th&gt;Rating&lt;/th&gt; &lt;th&gt;Reviews&lt;/th&gt; &lt;th&gt;Review Votes&lt;/th&gt; &lt;/tr&gt;   &lt;tr&gt; &lt;th&gt;394349&lt;/th&gt; &lt;td&gt;Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat.">
    <meta property="og:description" content="Case Study: Sentiment Analysis Data Prep import pandas as pd import numpy as np # Read in the data df = pd.read_csv(&#39;/Users/zero/Desktop/NLP/raw-data/Amazon_Unlocked_Mobile.csv&#39;) # å¯¹æ•°æ®è¿›è¡Œé‡‡æ ·ä»¥åŠ å¿«è®¡ç®—é€Ÿåº¦ # Comment out this line to match with lecture df = df.sample(frac=0.1, random_state=10) df.head()   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }   &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;Product Name&lt;/th&gt; &lt;th&gt;Brand Name&lt;/th&gt; &lt;th&gt;Price&lt;/th&gt; &lt;th&gt;Rating&lt;/th&gt; &lt;th&gt;Reviews&lt;/th&gt; &lt;th&gt;Review Votes&lt;/th&gt; &lt;/tr&gt;   &lt;tr&gt; &lt;th&gt;394349&lt;/th&gt; &lt;td&gt;Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat.">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="NLP part 03 sentiment analysis">
    <meta property="og:url" content="/2018/09/nlp-part-03-sentiment-analysis/">
    <meta property="og:site_name" content="student zero ">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="student zero ">
    <meta name="twitter:description" content="Case Study: Sentiment Analysis Data Prep import pandas as pd import numpy as np # Read in the data df = pd.read_csv(&#39;/Users/zero/Desktop/NLP/raw-data/Amazon_Unlocked_Mobile.csv&#39;) # å¯¹æ•°æ®è¿›è¡Œé‡‡æ ·ä»¥åŠ å¿«è®¡ç®—é€Ÿåº¦ # Comment out this line to match with lecture df = df.sample(frac=0.1, random_state=10) df.head()   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }   &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;Product Name&lt;/th&gt; &lt;th&gt;Brand Name&lt;/th&gt; &lt;th&gt;Price&lt;/th&gt; &lt;th&gt;Rating&lt;/th&gt; &lt;th&gt;Reviews&lt;/th&gt; &lt;th&gt;Review Votes&lt;/th&gt; &lt;/tr&gt;   &lt;tr&gt; &lt;th&gt;394349&lt;/th&gt; &lt;td&gt;Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat.">
    
      <meta name="twitter:creator" content="@studentZero475">
    
    

    
    

    
      <meta property="og:image" content="https://i.loli.net/2018/02/26/5a937bb148b02.jpg">
    

    
      <meta property="og:image" content="https://i.loli.net/2018/08/13/5b70bd4dc9763.jpg">
    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-hbs5om8csx9a8yrv5hnhpi2qqdv4ykuslajwbramhqxvleqbfklxgek50hye.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <link rel="stylesheet" href="/css/monokai-sublime.css" rel="stylesheet" id="theme-stylesheet">
<script src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">student zero </a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <h1 class="sidebar-profile-title">NLP part 03 sentiment analysis</h1>
        <a href="/#about">
          <img class="sidebar-profile-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Jixing Liu</h4>
        
          <h5 class="sidebar-profile-bio">Reading And Writing</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives/">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories/">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags/">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://twitter.com/studentZero475">
    
      <i class="sidebar-button-icon fa fa-lg fa-twitter"></i>
      
      <span class="sidebar-button-desc">Twitter</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.r-bloggers.com/">
    
      <i class="sidebar-button-icon fa fa-lg fa-book"></i>
      
      <span class="sidebar-button-desc">R-bloggers</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      

    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaOut
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-center">
  
    <h1 class="post-title" itemprop="headline">
      NLP part 03 sentiment analysis
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-09-17T00:00:00Z">
        
  September 17, 2018

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/machine-learning">machine learning</a>
    
  


  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <!--more-->
<div id="case-study-sentiment-analysis" class="section level1">
<h1>Case Study: Sentiment Analysis</h1>
<div id="data-prep" class="section level3">
<h3>Data Prep</h3>
<pre class="python"><code>import pandas as pd
import numpy as np

# Read in the data
df = pd.read_csv(&#39;/Users/zero/Desktop/NLP/raw-data/Amazon_Unlocked_Mobile.csv&#39;)

# å¯¹æ•°æ®è¿›è¡Œé‡‡æ ·ä»¥åŠ å¿«è®¡ç®—é€Ÿåº¦
# Comment out this line to match with lecture
df = df.sample(frac=0.1, random_state=10)

df.head()</code></pre>
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
<thead>
<pre><code>&lt;tr style=&quot;text-align: right;&quot;&gt;
  &lt;th&gt;&lt;/th&gt;
  &lt;th&gt;Product Name&lt;/th&gt;
  &lt;th&gt;Brand Name&lt;/th&gt;
  &lt;th&gt;Price&lt;/th&gt;
  &lt;th&gt;Rating&lt;/th&gt;
  &lt;th&gt;Reviews&lt;/th&gt;
  &lt;th&gt;Review Votes&lt;/th&gt;
&lt;/tr&gt;</code></pre>
</thead>
<tbody>
<pre><code>&lt;tr&gt;
  &lt;th&gt;394349&lt;/th&gt;
  &lt;td&gt;Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat...&lt;/td&gt;
  &lt;td&gt;NaN&lt;/td&gt;
  &lt;td&gt;244.95&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;Very good one! Better than Samsung S and iphon...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;34377&lt;/th&gt;
  &lt;td&gt;Apple iPhone 5c 8GB (Pink) - Verizon Wireless&lt;/td&gt;
  &lt;td&gt;Apple&lt;/td&gt;
  &lt;td&gt;194.99&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
  &lt;td&gt;The phone needed a SIM card, would have been n...&lt;/td&gt;
  &lt;td&gt;1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;248521&lt;/th&gt;
  &lt;td&gt;Motorola Droid RAZR MAXX XT912 M Verizon Smart...&lt;/td&gt;
  &lt;td&gt;Motorola&lt;/td&gt;
  &lt;td&gt;174.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I was 3 months away from my upgrade and my Str...&lt;/td&gt;
  &lt;td&gt;3.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;167661&lt;/th&gt;
  &lt;td&gt;CNPGD [U.S. Office Extended Warranty] Smartwat...&lt;/td&gt;
  &lt;td&gt;CNPGD&lt;/td&gt;
  &lt;td&gt;49.99&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
  &lt;td&gt;an experience i want to forget&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;73287&lt;/th&gt;
  &lt;td&gt;Apple iPhone 7 Unlocked Phone 256 GB - US Vers...&lt;/td&gt;
  &lt;td&gt;Apple&lt;/td&gt;
  &lt;td&gt;922.00&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;GREAT PHONE WORK ACCORDING MY EXPECTATIONS.&lt;/td&gt;
  &lt;td&gt;1.0&lt;/td&gt;
&lt;/tr&gt;</code></pre>
</tbody>
</table>
</div>
<pre class="python"><code>np.where(df[&#39;Rating&#39;] &gt; 3, 1, 0)</code></pre>
<pre><code>array([1, 0, 1, ..., 1, 0, 0])</code></pre>
<pre class="python"><code># Drop missing values
df.dropna(inplace=True)

# Remove any &#39;neutral&#39; ratings equal to 3
# filter rows
df = df[df[&#39;Rating&#39;] != 3]

# Encode 4s and 5s as 1 (rated positively)
# Encode 1s and 2s as 0 (rated poorly)
# class labels
df[&#39;Positively Rated&#39;] = np.where(df[&#39;Rating&#39;] &gt; 3, 1, 0)
df.head(10)</code></pre>
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
<thead>
<pre><code>&lt;tr style=&quot;text-align: right;&quot;&gt;
  &lt;th&gt;&lt;/th&gt;
  &lt;th&gt;Product Name&lt;/th&gt;
  &lt;th&gt;Brand Name&lt;/th&gt;
  &lt;th&gt;Price&lt;/th&gt;
  &lt;th&gt;Rating&lt;/th&gt;
  &lt;th&gt;Reviews&lt;/th&gt;
  &lt;th&gt;Review Votes&lt;/th&gt;
  &lt;th&gt;Positively Rated&lt;/th&gt;
&lt;/tr&gt;</code></pre>
</thead>
<tbody>
<pre><code>&lt;tr&gt;
  &lt;th&gt;34377&lt;/th&gt;
  &lt;td&gt;Apple iPhone 5c 8GB (Pink) - Verizon Wireless&lt;/td&gt;
  &lt;td&gt;Apple&lt;/td&gt;
  &lt;td&gt;194.99&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
  &lt;td&gt;The phone needed a SIM card, would have been n...&lt;/td&gt;
  &lt;td&gt;1.0&lt;/td&gt;
  &lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;248521&lt;/th&gt;
  &lt;td&gt;Motorola Droid RAZR MAXX XT912 M Verizon Smart...&lt;/td&gt;
  &lt;td&gt;Motorola&lt;/td&gt;
  &lt;td&gt;174.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I was 3 months away from my upgrade and my Str...&lt;/td&gt;
  &lt;td&gt;3.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;167661&lt;/th&gt;
  &lt;td&gt;CNPGD [U.S. Office Extended Warranty] Smartwat...&lt;/td&gt;
  &lt;td&gt;CNPGD&lt;/td&gt;
  &lt;td&gt;49.99&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
  &lt;td&gt;an experience i want to forget&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;73287&lt;/th&gt;
  &lt;td&gt;Apple iPhone 7 Unlocked Phone 256 GB - US Vers...&lt;/td&gt;
  &lt;td&gt;Apple&lt;/td&gt;
  &lt;td&gt;922.00&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;GREAT PHONE WORK ACCORDING MY EXPECTATIONS.&lt;/td&gt;
  &lt;td&gt;1.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;277158&lt;/th&gt;
  &lt;td&gt;Nokia N8 Unlocked GSM Touch Screen Phone Featu...&lt;/td&gt;
  &lt;td&gt;Nokia&lt;/td&gt;
  &lt;td&gt;95.00&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I fell in love with this phone because it did ...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;100311&lt;/th&gt;
  &lt;td&gt;Blackberry Torch 2 9810 Unlocked Phone with 1....&lt;/td&gt;
  &lt;td&gt;BlackBerry&lt;/td&gt;
  &lt;td&gt;77.49&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I am pleased with this Blackberry phone! The p...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;251669&lt;/th&gt;
  &lt;td&gt;Motorola Moto E (1st Generation) - Black - 4 G...&lt;/td&gt;
  &lt;td&gt;Motorola&lt;/td&gt;
  &lt;td&gt;89.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;Great product, best value for money smartphone...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;279878&lt;/th&gt;
  &lt;td&gt;OtterBox 77-29864 Defender Series Hybrid Case ...&lt;/td&gt;
  &lt;td&gt;OtterBox&lt;/td&gt;
  &lt;td&gt;9.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;I&#39;ve bought 3 no problems. Fast delivery.&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;406017&lt;/th&gt;
  &lt;td&gt;Verizon HTC Rezound 4G Android Smarphone - 8MP...&lt;/td&gt;
  &lt;td&gt;HTC&lt;/td&gt;
  &lt;td&gt;74.99&lt;/td&gt;
  &lt;td&gt;4&lt;/td&gt;
  &lt;td&gt;Great phone for the price...&lt;/td&gt;
  &lt;td&gt;0.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;th&gt;302567&lt;/th&gt;
  &lt;td&gt;RCA M1 Unlocked Cell Phone, Dual Sim, 5Mp Came...&lt;/td&gt;
  &lt;td&gt;RCA&lt;/td&gt;
  &lt;td&gt;159.99&lt;/td&gt;
  &lt;td&gt;5&lt;/td&gt;
  &lt;td&gt;My mom is not good with new technoloy but this...&lt;/td&gt;
  &lt;td&gt;4.0&lt;/td&gt;
  &lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;</code></pre>
</tbody>
</table>
</div>
<pre class="python"><code># Most ratings are positive
# More than 50% is positive
df[&#39;Positively Rated&#39;].mean()</code></pre>
<pre><code>0.7471776686078667</code></pre>
<pre class="python"><code>from sklearn.model_selection import train_test_split

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(df[&#39;Reviews&#39;], 
                                                    df[&#39;Positively Rated&#39;], 
                                                    random_state=0)</code></pre>
<pre class="python"><code>print(&#39;X_train first entry:\n\n&#39;, X_train.iloc[0])
print(&#39;\n\nX_train shape: &#39;, X_train.shape)</code></pre>
<pre><code>X_train first entry:

 Everything about it is awesome!


X_train shape:  (23052,)</code></pre>
</div>
</div>
<div id="countvectorizer" class="section level1">
<h1>CountVectorizer</h1>
<p>Construct a sparse matrix</p>
<pre class="python"><code>from sklearn.feature_extraction.text import CountVectorizer

# Fit the CountVectorizer to the training data
# init countvertoizer
init_countVectorizer = CountVectorizer()
# and then fit it
vect = init_countVectorizer.fit(X_train)</code></pre>
<pre class="python"><code># step is 2000
#sparse matrix
vect.get_feature_names()[::2000]</code></pre>
<pre><code>[&#39;00&#39;,
 &#39;arroja&#39;,
 &#39;comapaÃ±ias&#39;,
 &#39;dvds&#39;,
 &#39;golden&#39;,
 &#39;lands&#39;,
 &#39;oil&#39;,
 &#39;razonable&#39;,
 &#39;smallsliver&#39;,
 &#39;tweak&#39;]</code></pre>
<pre class="python"><code>len(vect.get_feature_names())</code></pre>
<pre><code>19601</code></pre>
<pre class="python"><code>19601/2000</code></pre>
<pre><code>9.8005</code></pre>
<pre class="python"><code># transform the documents in the training data to a document-term matrix
X_train_vectorized = vect.transform(X_train)

X_train_vectorized</code></pre>
<pre><code>&lt;23052x19601 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;
    with 613289 stored elements in Compressed Sparse Row format&gt;</code></pre>
<pre class="python"><code>print(type(X_train_vectorized)) </code></pre>
<pre><code>&lt;class &#39;scipy.sparse.csr.csr_matrix&#39;&gt;</code></pre>
<pre class="python"><code>from sklearn.linear_model import LogisticRegression

# Train the model
model = LogisticRegression()
model.fit(X_train_vectorized, y_train)</code></pre>
<pre><code>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,
          penalty=&#39;l2&#39;, random_state=None, solver=&#39;liblinear&#39;, tol=0.0001,
          verbose=0, warm_start=False)</code></pre>
<pre class="python"><code>from sklearn.metrics import roc_auc_score

# Predict the transformed test documents
predictions = model.predict(vect.transform(X_test))

print(&#39;AUC: &#39;, roc_auc_score(y_test, predictions))</code></pre>
<pre><code>AUC:  0.897433277667</code></pre>
<pre class="python"><code># get the feature names as numpy array
feature_names = np.array(vect.get_feature_names())

# Sort the coefficients from the model
sorted_coef_index = model.coef_[0].argsort()

# Find the 10 smallest and 10 largest coefficients
# The 10 largest coefficients are being indexed using [:-11:-1] 
# so the list returned is in order of largest to smallest
print(&#39;Smallest Coefs:\n{}\n&#39;.format(feature_names[sorted_coef_index[:10]]))
print(&#39;Largest Coefs: \n{}&#39;.format(feature_names[sorted_coef_index[:-11:-1]]))</code></pre>
<pre><code>Smallest Coefs:
[&#39;worst&#39; &#39;terrible&#39; &#39;slow&#39; &#39;junk&#39; &#39;poor&#39; &#39;sucks&#39; &#39;horrible&#39; &#39;useless&#39;
 &#39;waste&#39; &#39;disappointed&#39;]

Largest Coefs: 
[&#39;excelent&#39; &#39;excelente&#39; &#39;excellent&#39; &#39;perfectly&#39; &#39;love&#39; &#39;perfect&#39; &#39;exactly&#39;
 &#39;great&#39; &#39;best&#39; &#39;awesome&#39;]</code></pre>
</div>
<div id="tfidf" class="section level1">
<h1>Tfidf</h1>
<p>ğŸ”¥ feature: limit frequency threshold</p>
<pre class="python"><code>from sklearn.feature_extraction.text import TfidfVectorizer

# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5
vect = TfidfVectorizer(min_df=5).fit(X_train)
len(vect.get_feature_names())</code></pre>
<pre><code>5442</code></pre>
<pre class="python"><code>X_train_vectorized = vect.transform(X_train)

model = LogisticRegression()
model.fit(X_train_vectorized, y_train)

predictions = model.predict(vect.transform(X_test))

print(&#39;AUC: &#39;, roc_auc_score(y_test, predictions))</code></pre>
<pre><code>AUC:  0.889951006492</code></pre>
<pre class="python"><code>feature_names = np.array(vect.get_feature_names())

sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()

print(&#39;Smallest tfidf:\n{}\n&#39;.format(feature_names[sorted_tfidf_index[:10]]))
print(&#39;Largest tfidf: \n{}&#39;.format(feature_names[sorted_tfidf_index[:-11:-1]]))</code></pre>
<pre><code>Smallest tfidf:
[&#39;61&#39; &#39;printer&#39; &#39;approach&#39; &#39;adjustment&#39; &#39;consequences&#39; &#39;length&#39; &#39;emailing&#39;
 &#39;degrees&#39; &#39;handsfree&#39; &#39;chipset&#39;]

Largest tfidf: 
[&#39;unlocked&#39; &#39;handy&#39; &#39;useless&#39; &#39;cheat&#39; &#39;up&#39; &#39;original&#39; &#39;exelent&#39; &#39;exelente&#39;
 &#39;exellent&#39; &#39;satisfied&#39;]</code></pre>
<pre class="python"><code>sorted_coef_index = model.coef_[0].argsort()

print(&#39;Smallest Coefs:\n{}\n&#39;.format(feature_names[sorted_coef_index[:10]]))
print(&#39;Largest Coefs: \n{}&#39;.format(feature_names[sorted_coef_index[:-11:-1]]))</code></pre>
<pre><code>Smallest Coefs:
[&#39;not&#39; &#39;slow&#39; &#39;disappointed&#39; &#39;worst&#39; &#39;terrible&#39; &#39;never&#39; &#39;return&#39; &#39;doesn&#39;
 &#39;horrible&#39; &#39;waste&#39;]

Largest Coefs: 
[&#39;great&#39; &#39;love&#39; &#39;excellent&#39; &#39;good&#39; &#39;best&#39; &#39;perfect&#39; &#39;price&#39; &#39;awesome&#39; &#39;far&#39;
 &#39;perfectly&#39;]</code></pre>
<pre class="python"><code>vect.transform([&#39;not an issue, phone is working&#39;,
                                    &#39;an issue, phone is not working&#39;])</code></pre>
<pre><code>&lt;2x5442 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;
    with 12 stored elements in Compressed Sparse Row format&gt;</code></pre>
<pre class="python"><code># These reviews are treated the same by our current model
print(model.predict(vect.transform([&#39;not an issue, phone is working&#39;,
                                    &#39;an issue, phone is not working&#39;])))</code></pre>
<pre><code>[0 0]</code></pre>
</div>
<div id="n-grams" class="section level1">
<h1>n-grams</h1>
<p>ğŸ”¥ â€œback asâ€ or â€œis notâ€ is grams</p>
<pre class="python"><code># Fit the CountVectorizer to the training data specifiying a minimum 
# document frequency of 5 and extracting 1-grams and 2-grams
# min_df
# ngram_range

vect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)

X_train_vectorized = vect.transform(X_train)

len(vect.get_feature_names())</code></pre>
<pre><code>29072</code></pre>
<pre class="python"><code>vect.get_feature_names()[3000:3010]</code></pre>
<pre><code>[&#39;back as&#39;,
 &#39;back asap&#39;,
 &#39;back because&#39;,
 &#39;back but&#39;,
 &#39;back button&#39;,
 &#39;back camera&#39;,
 &#39;back case&#39;,
 &#39;back cover&#39;,
 &#39;back for&#39;,
 &#39;back from&#39;]</code></pre>
<pre class="python"><code>model = LogisticRegression()
model.fit(X_train_vectorized, y_train)

predictions = model.predict(vect.transform(X_test))

print(&#39;AUC: &#39;, roc_auc_score(y_test, predictions))</code></pre>
<pre><code>AUC:  0.91106617946</code></pre>
<pre class="python"><code>feature_names = np.array(vect.get_feature_names())

sorted_coef_index = model.coef_[0].argsort()

print(&#39;Smallest Coefs:\n{}\n&#39;.format(feature_names[sorted_coef_index[:10]]))
print(&#39;Largest Coefs: \n{}&#39;.format(feature_names[sorted_coef_index[:-11:-1]]))</code></pre>
<pre><code>Smallest Coefs:
[&#39;no good&#39; &#39;junk&#39; &#39;poor&#39; &#39;slow&#39; &#39;worst&#39; &#39;broken&#39; &#39;not good&#39; &#39;terrible&#39;
 &#39;defective&#39; &#39;horrible&#39;]

Largest Coefs: 
[&#39;excellent&#39; &#39;excelente&#39; &#39;excelent&#39; &#39;perfect&#39; &#39;great&#39; &#39;love&#39; &#39;awesome&#39;
 &#39;no problems&#39; &#39;good&#39; &#39;best&#39;]</code></pre>
<pre class="python"><code># These reviews are now correctly identified
# why ğŸ¤”
print(model.predict(vect.transform([&#39;not an issue, phone is working&#39;,
                                    &#39;an issue, phone is not working&#39;])))</code></pre>
<pre><code>[1 0]</code></pre>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="//tags/nlp/">NLP</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/09/nlp-part04-word-count-use-r/" data-tooltip="NLP part04 word count use R">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/09/nlp-part-03-sentiment-analysis/" data-tooltip="NLP part 03 sentiment analysis">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/09/nlp-part-03-sentiment-analysis/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/09/nlp-part-03-sentiment-analysis/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/09/nlp-part-03-sentiment-analysis/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2019 Jixing Liu. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/09/nlp-part04-word-count-use-r/" data-tooltip="NLP part04 word count use R">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/09/nlp-part-03-sentiment-analysis/" data-tooltip="NLP part 03 sentiment analysis">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/09/nlp-part-03-sentiment-analysis/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/09/nlp-part-03-sentiment-analysis/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/09/nlp-part-03-sentiment-analysis/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2018%2F09%2Fnlp-part-03-sentiment-analysis%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2018%2F09%2Fnlp-part-03-sentiment-analysis%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2F2018%2F09%2Fnlp-part-03-sentiment-analysis%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Jixing Liu</h4>
    
      <div id="about-card-bio">Reading And Writing</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Data Scientist
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        China
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/05/the-hello-world-of-neural-network/">
                <h3 class="media-heading">The Hello World Of Neural Network</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  May 5, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">ç®€å•æ¥è¯´ç¥ç»ç½‘ç»œå’Œæˆ‘ä»¬ä¸€èˆ¬çš„ç¼–ç¨‹åŒºåˆ«åœ¨äº: ä¸€ä¸ªæ˜¯è¾“å…¥æ•°æ®å’Œå‡½æ•°è§„åˆ™, ç„¶åå¾—åˆ°ç»“æœ. è€Œç¥ç»ç½‘ç»œæ˜¯è¾“å…¥æ•°æ®å’Œç­”æ¡ˆ, é€šè¿‡è¿­ä»£å­¦ä¹ , ç¥ç»ç½‘ç»œèƒ½å­¦ä¹ å‡ºå‡½æ•°è§„åˆ™.å¦‚ä¸‹å›¾:
ä¸¾ä¸ªç®€å•çš„ä¾‹å­, è¿™é‡Œæœ‰ä¸¤ç»„æ•°æ®:
X: -1, 0, 1, 2, 3, 4 Y: -3, -1, 1, 3, 5, 7
ä½ å¯ä»¥æŠŠ x çœ‹åšæ˜¯æ•°æ®, y çœ‹åšæ˜¯ç­”æ¡ˆ, ç°åœ¨ä½ è¦åšçš„æ˜¯æ‰¾åˆ°å…¶ä¸­çš„å‡½æ•°å…³ç³», è¿™ä¸ªå…³ç³»èƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬, ç”¨ x å»é¢„æµ‹ Y çš„å€¼(å‡è®¾ä½ æ²¡æœ‰å­¦è¿‡è§£æ–¹ç¨‹ç»„).
æœ€å¸¸ç”¨çš„æ–¹æ³•å°±æ˜¯å½’çº³æ³•, é¦–å…ˆä½ æ ¹æ®ç¬¬ä¸€å¯¹æ•°æ®çŒœä¸€ä¸ªå¯¹åº”å…³ç³»è§„åˆ™, æ‹¿ç€è¿™ä¸ªè§„åˆ™è®¡ç®—ç­”æ¡ˆå€¼, è¯„ä¼°è®¡ç®—çš„ç­”æ¡ˆå’ŒçœŸå®ç­”æ¡ˆå·®å¤šè¿œ, ç„¶ååœ¨è°ƒæ•´ä½ çš„è§„åˆ™, ç»§ç»­è¯„ä¼°, ç›´åˆ°ä½ çš„è§„åˆ™èƒ½å¤Ÿæ‹Ÿåˆæ‰€æœ‰çš„æ•°æ®.
è¿™å°±æ˜¯ç¥ç»ç½‘ç»œçš„é€»è¾‘è¿‡ç¨‹.
æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œçš„ä¾‹å­
1.Import: åŠ è½½æ‰€éœ€æ¨¡å— import tensorflow as tf ## /Users/zero/anaconda3/envs/tfdeeplearning/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module &#39;tensorflow.python.framework.fast_tensor_util&#39; does not match runtime version 3.5 ## return f(*args, **kwds) import numpy as np from tensorflow import keras  2.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/04/analyze-and-visualize-your-iphone-s-health-app-data-in-r/">
                <h3 class="media-heading">ä½¿ç”¨ R åˆ†æå¯è§†åŒ–ä½ çš„ iPhone å¥åº· APP æ•°æ®</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">ä»‹ç» iPhone çš„ health APP å­˜å‚¨ç€æˆ‘ä»¬çš„ç§äººå¥åº·æ•°æ®, è¿™é‡Œæœ‰ä¸€ç¯‡å¸–å­æ˜¯ç”¨ Python åˆ†æ health APP çš„æ•°æ®Apple Health Data How to Export Analyze Visualize Guide - ryanpraski.com , è€Œæˆ‘æ›´å–œæ¬¢ R çš„ç‰ˆæœ¬.
è®©æˆ‘ä»¬èµ¶ç´§å¼€å§‹å§!!
 é¦–å…ˆè·å–æ•°æ®å¹¶è¯»å– ä»ä½ çš„ health APP åº”ç”¨ä¸­å¯¼å‡ºæ•°æ® åœ¨ R ä¸­è¯»å–æ•°æ®  åŠ è½½åŒ…å¹¶è¯»å…¥æ•°æ® library(XML) library(tidyverse) library(lubridate) library(scales) library(here) library(ggthemes) xml &lt;- xmlParse(here(&quot;data/apple_health_export/export.xml&quot;)) summary(xml) ## $nameCounts ## ## Record ExportDate HealthData Me Workout ## 90037 1 1 1 1 ## ## $numNodes ## [1] 90041 Record æ˜¯æˆ‘çš„ä¸»è¦æ•°æ®, æœ‰ 90,037 æ¡</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/03/tao_wang_bei_shang_guang/">
                <h3 class="media-heading">é€ƒå¾€åŒ—ä¸Šå¹¿</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">å¥‹æ–—ï¼Œåº”è¯¥æ˜¯ä¸€ç§ç”Ÿæ´»æ–¹å¼, ç™»å±±å¹¶ä¸å…¨æ˜¯ä¸ºäº†ç™»é¡¶çš„é‚£ä¸€åˆ»
 åªæœ‰ä¸åœå¥‹æ–—çš„äººç”Ÿï¼Œæ‰æœ‰æ„ä¹‰ï¼Œæ‰æ´»çš„æœ‰åŠ²å„¿ï¼Œæ··åƒç­‰æ­»çš„æ—¥å­å…¶å®æ˜¯å¾ˆè‰°éš¾çš„ï¼Œæ— èŠæ­»äº†ï¼Œä¸€å¤´æ‰è¿›äººå †å„¿é‡Œä¸åœçš„æ‰‘æ£±æ‰æœ‰æ„æ€å•Šï¼
é€ƒå¾€åŒ—äº¬ã€ä¸Šæµ·ã€å¹¿å·ã€æ·±åœ³
åœ¨å®¶ä¹¡ï¼Œåœ¨é‚£ä¸ªä½ ç”Ÿé•¿äº†äºŒä¸‰åå¹´çš„å°åŸé•‡ï¼Œå¦‚æœä½ æ‹’ç»è¿‡ä¸Šå’Œæ‰€æœ‰äººä¸€æ ·å¾ªè§„è¹ˆçŸ©çš„ç”Ÿæ´»ï¼Œæ‹’ç»ç»“å©šç”Ÿå­ï¼Œæ‹’ç»ç¨³å®šå·¥ä½œï¼Œæ‹’ç»æ”¾å¼ƒå½±å“ä½ èµšé’±å‡èŒçš„çˆ±å¥½ï¼Œé‚£ä¹ˆä½ å°±å˜æˆäº†ä¸€å¤´å’Œå‘¨å›´çš„ä¸€åˆ‡æ ¼æ ¼ä¸å…¥çš„æ€ªç‰©ã€‚
äºæ˜¯å¤§å®¶è¦æŒ½æ•‘ä½ ï¼Œè¦æ•™è‚²ä½ ï¼Œè¦è®©ä½ å­¦ä¼šè®¤å‘½ï¼Œåœæ­¢æ¯«æ— æ„ä¹‰çš„æŠ˜è…¾ï¼Œè¿™æ ·ä½ æ‰èƒ½å’Œå¤§å®¶ä¸€æ ·â€œè¸è¸å®å®è¿‡æ—¥å­â€ã€‚
è®¸å¤šäººå› æ­¤é€‰æ‹©äº†å¯¹æŠ—ï¼Œåœ¨æ„¤æ€’ä¸­æ…¢æ…¢å˜å¾—ç»æœ›ï¼Œåœ¨ç»æœ›ä¸­å˜å¾—éº»æœ¨ï¼Œåœ¨éº»æœ¨ä¸­é€ƒå¾€è™šæ— </div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/10/pubchunks_extract_parts_of_scholarly_xml_articles/">
                <h3 class="media-heading">pubchunksï¼šæå–å­¦æœ¯æ–‡ç« çš„æŸéƒ¨åˆ†</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">èƒŒæ™¯ pubchunks çš„ç›®çš„æ˜¯ä»XMLæ ¼å¼çš„å­¦æœ¯æ–‡ç« ä¸­è·å–éƒ¨åˆ†æ•°æ®ã€‚æˆ‘ä»¬ä¸éœ€è¦äº†è§£XMLåŠå…¶æ‰€æœ‰çš„æ ¼å¼åŸç†ã€‚åªéœ€çŸ¥é“æˆ‘ä»¬çš„æ–‡ä»¶æˆ–XMLå­—ç¬¦ä¸²åœ¨å“ªé‡Œä»¥åŠæˆ‘ä»¬æƒ³è¦æ¯ç¯‡æ–‡ç« çš„å“ªäº›éƒ¨åˆ†ã€‚ç„¶åç”¨æˆ·å¯ä»¥ç»„åˆè¿™äº›éƒ¨åˆ†å¹¶åšæˆ‘ä»¬å¸Œæœ›ä¸‹æ¸¸çš„ä»»ä½•äº‹æƒ…; ä¾‹å¦‚,åˆ†ææ–‡æœ¬ç»“æ„
 pubchunksä¸­çš„å‡½æ•° ä¸¤ä¸ªä¸»è¦åŠŸèƒ½æ˜¯ï¼š
pub_chunks()ï¼šè·å–XMLéƒ¨åˆ† pub_tabularize()ï¼šå¼ºåˆ¶è¾“å‡ºpub_chunks()åˆ°data.frameä¸­ pub_guess_publisher()ï¼šä»XMLæ–‡ä»¶æˆ–å­—ç¬¦ä¸²çŒœæµ‹å‘å¸ƒè€… pub_sections()ï¼šéƒ¨åˆ†pubchunksçŸ¥é“å¦‚ä½•å¤„ç† pub_providers()ï¼šæä¾›è€…ï¼ˆå³å‘å¸ƒè€…ï¼‰pubchunksçŸ¥é“å¦‚ä½•æ˜ç¡®å¤„ç†   æ”¯æŒçš„å‡ºç‰ˆå•† elife plos elsevier hindawi pensoft peerj copernicus frontiers f1000research   æ”¯æŒæå–çš„éƒ¨åˆ†æœ‰: Front - å‘å¸ƒè€…ï¼ŒæœŸåˆŠå’Œæ–‡ç« å…ƒæ•°æ®å…ƒç´  Body - æ–‡ç« çš„æ­£æ–‡ Back - æ–‡ç« çš„èƒŒé¢ï¼Œè‡´è°¢ï¼Œä½œè€…è´¡çŒ®ï¼Œå‚è€ƒæ–‡çŒ® Title - æ–‡ç« æ ‡é¢˜ Doi - æ–‡ç« doi Categories - å‘å¸ƒå•†çš„ç±»åˆ«ï¼Œå¦‚æœæœ‰çš„è¯ Author - ä½œè€… Aff - éš¶å±å…³ç³»ï¼ˆåŒ…æ‹¬ä½œè€…å§“åï¼‰ Keyword - å…³é”®å­— Abstract - æ–‡ç« æ‘˜è¦ Executive_summary - æ–‡ç« æ‰§è¡Œæ‘˜è¦ Refs - å‚è€ƒæ–‡çŒ® Refs_dois - å‚è€ƒdois - å¦‚æœæœ‰çš„è¯ Publisher - å‘å¸ƒè€…åç§° Journal_meta - æœŸåˆŠå…ƒæ•°æ® Article_meta - æ–‡ç« å…ƒæ•°æ® Acknowledgments - è‡´è°¢ Permissions - æ–‡ç« æƒé™ History - æ—¥æœŸï¼Œæ”¶åˆ°ï¼Œå‡ºç‰ˆï¼Œæ¥å—ç­‰   å®‰è£… #install.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/09/nlp-part04-word-count-use-r/">
                <h3 class="media-heading">NLP part04 word count use R</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Sep 9, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">What Is Clean Data Each variable is a column Each observation is a row Each type of observational unit is a table   A table with one-token-per-row.  A token is a meaningful unit of text, such as a word, that we are interested in using for analysis, and tokenization is the process of splitting text into tokens.
 text &lt;- c( &quot;Because I could not stop for Death -&quot;, &quot;He kindly stopped for me -&quot;, &quot;The Carriage held but just Ourselves -&quot;, &quot;and Immortality&quot; ) text ## [1] &quot;Because I could not stop for Death -&quot; ## [2] &quot;He kindly stopped for me -&quot; ## [3] &quot;The Carriage held but just Ourselves -&quot; ## [4] &quot;and Immortality&quot; library(dplyr) text_df &lt;- data_frame(line = 1:4, text = text) text_df ## # A tibble: 4 x 2 ## line text ## &lt;int&gt; &lt;chr&gt; ## 1 1 Because I could not stop for Death - ## 2 2 He kindly stopped for me - ## 3 3 The Carriage held but just Ourselves - ## 4 4 and Immortality library(tidytext) text_df %&gt;% unnest_tokens(word, text) ## # A tibble: 20 x 2 ## line word ## &lt;int&gt; &lt;chr&gt; ## 1 1 because ## 2 1 i ## 3 1 could ## 4 1 not ## 5 1 stop ## 6 1 for ## 7 1 death ## 8 2 he ## 9 2 kindly ## 10 2 stopped ## 11 2 for ## 12 2 me ## 13 3 the ## 14 3 carriage ## 15 3 held ## 16 3 but ## 17 3 just ## 18 3 ourselves ## 19 4 and ## 20 4 immortality For tidy text mining, the token that is stored in each row is most often a single word, but can also be an n-gram, sentence, or paragraph</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/09/nlp-part-03-sentiment-analysis/">
                <h3 class="media-heading">NLP part 03 sentiment analysis</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Sep 9, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Case Study: Sentiment Analysis Data Prep import pandas as pd import numpy as np # Read in the data df = pd.read_csv(&#39;/Users/zero/Desktop/NLP/raw-data/Amazon_Unlocked_Mobile.csv&#39;) # å¯¹æ•°æ®è¿›è¡Œé‡‡æ ·ä»¥åŠ å¿«è®¡ç®—é€Ÿåº¦ # Comment out this line to match with lecture df = df.sample(frac=0.1, random_state=10) df.head()   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }   &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;Product Name&lt;/th&gt; &lt;th&gt;Brand Name&lt;/th&gt; &lt;th&gt;Price&lt;/th&gt; &lt;th&gt;Rating&lt;/th&gt; &lt;th&gt;Reviews&lt;/th&gt; &lt;th&gt;Review Votes&lt;/th&gt; &lt;/tr&gt;   &lt;tr&gt; &lt;th&gt;394349&lt;/th&gt; &lt;td&gt;Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/09/nlp-part-03-sentiment-analysis/">
                <h3 class="media-heading">NLP part 03 sentiment analysis</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Sep 9, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><p></p></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/09/npl-use-python-part-01/">
                <h3 class="media-heading">NLP use python part 01</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Sep 9, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><p></p></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/09/will_data_scientists_be_replaced_by_machines_2018-09-10/">
                <h3 class="media-heading">æ•°æ®ç§‘å­¦å®¶ä¼šä¸ä¼šè¢«æœºå™¨å–?</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Sep 9, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">æ•°æ®ç§‘å­¦è‡ªåŠ¨åŒ– æ›¾ä»Šæ˜¯ä¸€ä¸ªçƒ­é—¨è¯é¢˜, å¤§å¤šæ•°äººéƒ½åœ¨è®¨è®ºæ‰€è°“çš„â€œè‡ªåŠ¨åŒ–â€å·¥å…·, äººä»¬å£°ç§°ä»–ä»¬çš„å·¥å…·å¯ä»¥è‡ªåŠ¨åŒ–æ•°æ®ç§‘å­¦è¿‡ç¨‹ã€‚ç»™äººä¸€ç§é”™è§‰, åªè¦å°†è¿™äº›å·¥å…·ä¸å¤§æ•°æ®æ¶æ„ç›¸ç»“åˆå°±å¯ä»¥è§£å†³ä»»ä½•ä¸šåŠ¡é—®é¢˜ã€‚
ä½†æ˜¯å…¶å®åœ¨å®é™…çš„æ•°æ®åˆ†æå·¥ä½œä¸­, è‡ªåŠ¨åŒ–å»ºæ¨¡éƒ¨åˆ†ä»…ä»…å åˆ°æ€»å·¥ä½œé‡çš„10%, å¤§å¤šæ•°çš„æ—¶é—´å’Œç²¾åŠ›èŠ±åœ¨äº† feature engineering å’Œ feature selectionã€‚ æ¯”èµ·æ„å»ºä¸€ä¸ªå¤æ‚çš„æ¨¡å‹, æˆ‘ä»¬æ›´åº”è¯¥å…³æ³¨çš„é—®é¢˜è¿™äº›é—®é¢˜ ä¾‹å¦‚: å®šä¹‰è¦è§£å†³çš„é—®é¢˜ï¼Œè·å–æ•°æ®ï¼Œæ¢ç´¢æ•°æ®ï¼Œéƒ¨ç½²é¡¹ç›®ï¼Œè°ƒè¯•å’Œç›‘è§†, è€Œè¿™äº›é—®é¢˜å¾€å¾€éƒ½æ— æ³•å®Œå…¨è‡ªåŠ¨åŒ–ã€‚
è¿™é‡Œ Berry å’Œ Linoff ä»æ‘„å½±çš„è§’åº¦ç»™äº†ä¸€ä¸ªæœ‰è¶£çš„æ¯”å–»:
 â€œThe camera can relieve the photographer from having to set the shutter speed, aperture and other settings every time a picture is taken. This makes the process easier for expert photographers and makes better photography accessible to people who are not experts. But this is still automating only a small part of the process of producing a photograph.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/08/some-opinion-about-data-science/">
                <h3 class="media-heading">Some Opinion For Data Scientist</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Aug 8, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Some View From Hadley    Pragmatically, if youâ€™re a data scientist, learning the basics of SQL is really important.    You should also have a minimal reading knowledge of R and Python, because so many data science teams use both .    Then I think youâ€™re better off specializing in one of these two and getting really good at it, rather than spreading yourself too thin and being mediocre at several languages.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         53 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('https://i.loli.net/2018/02/26/5a9416186c149.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js" integrity="sha256-IFHWFEbU2/+wNycDECKgjIRSirRNIDp2acEB5fvdVRU=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js" integrity="sha256-+mpyNVJsNt4rVXCw0F+pAOiB3YxmHgrbJsx4ecPuUaI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js" integrity="sha256-vMxgR/7FtLovVA+IPrR7+xTgIgARH7y9VZQnmmi0HDI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js" integrity="sha256-N0qFUh7/9vLvia87dDndewmsgsyYoNkdA212tPc+2NI=" crossorigin="anonymous"></script>


<script src="/js/script-kr8dyqj6rb6ortyib7whfo9x9p6td6zo8t1v4fdz4ecx5kwybsdlmk1slygn.min.js"></script>


<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>

  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2018\/09\/nlp-part-03-sentiment-analysis\/';
          
            this.page.identifier = '\/2018\/09\/nlp-part-03-sentiment-analysis\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'jixing';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>

