

  
    
  


  





  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.32.2 with theme Tranquilpeak 0.4.1-BETA">
    <title>NLP part04 word count use R</title>
    <meta name="author" content="Jixing Liu">
    <meta name="keywords" content="tech, R">

    <link rel="icon" href="img/R_py.png">
    

    
    <meta name="description" content="What Is Clean Data Each variable is a column Each observation is a row Each type of observational unit is a table   A table with one-token-per-row.  A token is a meaningful unit of text, such as a word, that we are interested in using for analysis, and tokenization is the process of splitting text into tokens.
 text &lt;- c( &quot;Because I could not stop for Death -&quot;, &quot;He kindly stopped for me -&quot;, &quot;The Carriage held but just Ourselves -&quot;, &quot;and Immortality&quot; ) text ## [1] &quot;Because I could not stop for Death -&quot; ## [2] &quot;He kindly stopped for me -&quot; ## [3] &quot;The Carriage held but just Ourselves -&quot; ## [4] &quot;and Immortality&quot; library(dplyr) text_df &lt;- data_frame(line = 1:4, text = text) text_df ## # A tibble: 4 x 2 ## line text ## &lt;int&gt; &lt;chr&gt; ## 1 1 Because I could not stop for Death - ## 2 2 He kindly stopped for me - ## 3 3 The Carriage held but just Ourselves - ## 4 4 and Immortality library(tidytext) text_df %&gt;% unnest_tokens(word, text) ## # A tibble: 20 x 2 ## line word ## &lt;int&gt; &lt;chr&gt; ## 1 1 because ## 2 1 i ## 3 1 could ## 4 1 not ## 5 1 stop ## 6 1 for ## 7 1 death ## 8 2 he ## 9 2 kindly ## 10 2 stopped ## 11 2 for ## 12 2 me ## 13 3 the ## 14 3 carriage ## 15 3 held ## 16 3 but ## 17 3 just ## 18 3 ourselves ## 19 4 and ## 20 4 immortality For tidy text mining, the token that is stored in each row is most often a single word, but can also be an n-gram, sentence, or paragraph">
    <meta property="og:description" content="What Is Clean Data Each variable is a column Each observation is a row Each type of observational unit is a table   A table with one-token-per-row.  A token is a meaningful unit of text, such as a word, that we are interested in using for analysis, and tokenization is the process of splitting text into tokens.
 text &lt;- c( &quot;Because I could not stop for Death -&quot;, &quot;He kindly stopped for me -&quot;, &quot;The Carriage held but just Ourselves -&quot;, &quot;and Immortality&quot; ) text ## [1] &quot;Because I could not stop for Death -&quot; ## [2] &quot;He kindly stopped for me -&quot; ## [3] &quot;The Carriage held but just Ourselves -&quot; ## [4] &quot;and Immortality&quot; library(dplyr) text_df &lt;- data_frame(line = 1:4, text = text) text_df ## # A tibble: 4 x 2 ## line text ## &lt;int&gt; &lt;chr&gt; ## 1 1 Because I could not stop for Death - ## 2 2 He kindly stopped for me - ## 3 3 The Carriage held but just Ourselves - ## 4 4 and Immortality library(tidytext) text_df %&gt;% unnest_tokens(word, text) ## # A tibble: 20 x 2 ## line word ## &lt;int&gt; &lt;chr&gt; ## 1 1 because ## 2 1 i ## 3 1 could ## 4 1 not ## 5 1 stop ## 6 1 for ## 7 1 death ## 8 2 he ## 9 2 kindly ## 10 2 stopped ## 11 2 for ## 12 2 me ## 13 3 the ## 14 3 carriage ## 15 3 held ## 16 3 but ## 17 3 just ## 18 3 ourselves ## 19 4 and ## 20 4 immortality For tidy text mining, the token that is stored in each row is most often a single word, but can also be an n-gram, sentence, or paragraph">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="NLP part04 word count use R">
    <meta property="og:url" content="/2018/09/nlp-part04-word-count-use-r/">
    <meta property="og:site_name" content="student zero ">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="student zero ">
    <meta name="twitter:description" content="What Is Clean Data Each variable is a column Each observation is a row Each type of observational unit is a table   A table with one-token-per-row.  A token is a meaningful unit of text, such as a word, that we are interested in using for analysis, and tokenization is the process of splitting text into tokens.
 text &lt;- c( &quot;Because I could not stop for Death -&quot;, &quot;He kindly stopped for me -&quot;, &quot;The Carriage held but just Ourselves -&quot;, &quot;and Immortality&quot; ) text ## [1] &quot;Because I could not stop for Death -&quot; ## [2] &quot;He kindly stopped for me -&quot; ## [3] &quot;The Carriage held but just Ourselves -&quot; ## [4] &quot;and Immortality&quot; library(dplyr) text_df &lt;- data_frame(line = 1:4, text = text) text_df ## # A tibble: 4 x 2 ## line text ## &lt;int&gt; &lt;chr&gt; ## 1 1 Because I could not stop for Death - ## 2 2 He kindly stopped for me - ## 3 3 The Carriage held but just Ourselves - ## 4 4 and Immortality library(tidytext) text_df %&gt;% unnest_tokens(word, text) ## # A tibble: 20 x 2 ## line word ## &lt;int&gt; &lt;chr&gt; ## 1 1 because ## 2 1 i ## 3 1 could ## 4 1 not ## 5 1 stop ## 6 1 for ## 7 1 death ## 8 2 he ## 9 2 kindly ## 10 2 stopped ## 11 2 for ## 12 2 me ## 13 3 the ## 14 3 carriage ## 15 3 held ## 16 3 but ## 17 3 just ## 18 3 ourselves ## 19 4 and ## 20 4 immortality For tidy text mining, the token that is stored in each row is most often a single word, but can also be an n-gram, sentence, or paragraph">
    
      <meta name="twitter:creator" content="@studentZero475">
    
    

    
    

    
      <meta property="og:image" content="https://i.loli.net/2018/02/26/5a937bb148b02.jpg">
    

    
      <meta property="og:image" content="https://i.loli.net/2018/08/13/5b70bd4dc9763.jpg">
    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-hbs5om8csx9a8yrv5hnhpi2qqdv4ykuslajwbramhqxvleqbfklxgek50hye.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <link rel="stylesheet" href="/css/monokai-sublime.css" rel="stylesheet" id="theme-stylesheet">
<script src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">student zero </a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <h1 class="sidebar-profile-title">NLP part04 word count use R</h1>
        <a href="/#about">
          <img class="sidebar-profile-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Jixing Liu</h4>
        
          <h5 class="sidebar-profile-bio">Reading And Writing</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives/">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories/">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags/">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://twitter.com/studentZero475">
    
      <i class="sidebar-button-icon fa fa-lg fa-twitter"></i>
      
      <span class="sidebar-button-desc">Twitter</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.r-bloggers.com/">
    
      <i class="sidebar-button-icon fa fa-lg fa-book"></i>
      
      <span class="sidebar-button-desc">R-bloggers</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      

    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaOut
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-center">
  
    <h1 class="post-title" itemprop="headline">
      NLP part04 word count use R
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-09-20T00:00:00Z">
        
  September 20, 2018

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/machine-learning">machine learning</a>
    
  


  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <!--more-->
<div id="what-is-clean-data" class="section level2">
<h2>What Is Clean Data</h2>
<ol style="list-style-type: decimal">
<li>Each variable is a column</li>
<li>Each observation is a row</li>
<li>Each type of observational unit is a table</li>
</ol>
</div>
<div id="a-table-with-one-token-per-row." class="section level2">
<h2>A table with one-token-per-row.</h2>
<blockquote>
<p>A <strong style="color: darkred;">token</strong> is a meaningful unit of text, such as a word, that we are interested in using for analysis, and tokenization is the process of splitting text into tokens.</p>
</blockquote>
<pre class="r"><code>text &lt;- c(
  &quot;Because I could not stop for Death -&quot;,
  &quot;He kindly stopped for me -&quot;,
  &quot;The Carriage held but just Ourselves -&quot;,
  &quot;and Immortality&quot;
)
text</code></pre>
<pre><code>## [1] &quot;Because I could not stop for Death -&quot;  
## [2] &quot;He kindly stopped for me -&quot;            
## [3] &quot;The Carriage held but just Ourselves -&quot;
## [4] &quot;and Immortality&quot;</code></pre>
<pre class="r"><code>library(dplyr)
text_df &lt;- data_frame(line = 1:4, text = text)
text_df</code></pre>
<pre><code>## # A tibble: 4 x 2
##    line text                                  
##   &lt;int&gt; &lt;chr&gt;                                 
## 1     1 Because I could not stop for Death -  
## 2     2 He kindly stopped for me -            
## 3     3 The Carriage held but just Ourselves -
## 4     4 and Immortality</code></pre>
<pre class="r"><code>library(tidytext)
text_df %&gt;%
  unnest_tokens(word, text)</code></pre>
<pre><code>## # A tibble: 20 x 2
##     line word       
##    &lt;int&gt; &lt;chr&gt;      
##  1     1 because    
##  2     1 i          
##  3     1 could      
##  4     1 not        
##  5     1 stop       
##  6     1 for        
##  7     1 death      
##  8     2 he         
##  9     2 kindly     
## 10     2 stopped    
## 11     2 for        
## 12     2 me         
## 13     3 the        
## 14     3 carriage   
## 15     3 held       
## 16     3 but        
## 17     3 just       
## 18     3 ourselves  
## 19     4 and        
## 20     4 immortality</code></pre>
<p>For tidy text mining, the token that is stored in each row is most often a single word, but can also be an n-gram, sentence, or paragraph</p>
<p>A workflow where importing, filtering, and processing is done using dplyr and other tidy tools, after which the data is converted into a document-term matrix for machine learning applications</p>
<p>This function uses the tokenizers package to separate each line of text in the original data frame into tokens. The default tokenizing is for words, but other options include characters, n-grams, sentences, lines, paragraphs, or separation around a regex pattern</p>
<div class="figure">
<img src="https://www.tidytextmining.com/images/tidyflow-ch-1.png" />

</div>
<pre class="r"><code>library(janeaustenr)
library(dplyr)
library(stringr)
original_books &lt;- austen_books() %&gt;%
  group_by(book) %&gt;%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(
           text, regex(&quot;^chapter [\\divxlc]&quot;,
                       ignore_case = TRUE)
         ))) %&gt;%
  ungroup()
original_books</code></pre>
<pre><code>## # A tibble: 73,422 x 4
##    text                  book                linenumber chapter
##    &lt;chr&gt;                 &lt;fct&gt;                    &lt;int&gt;   &lt;int&gt;
##  1 SENSE AND SENSIBILITY Sense &amp; Sensibility          1       0
##  2 &quot;&quot;                    Sense &amp; Sensibility          2       0
##  3 by Jane Austen        Sense &amp; Sensibility          3       0
##  4 &quot;&quot;                    Sense &amp; Sensibility          4       0
##  5 (1811)                Sense &amp; Sensibility          5       0
##  6 &quot;&quot;                    Sense &amp; Sensibility          6       0
##  7 &quot;&quot;                    Sense &amp; Sensibility          7       0
##  8 &quot;&quot;                    Sense &amp; Sensibility          8       0
##  9 &quot;&quot;                    Sense &amp; Sensibility          9       0
## 10 CHAPTER 1             Sense &amp; Sensibility         10       1
## # ... with 73,412 more rows</code></pre>
<pre class="r"><code>library(tidytext)
tidy_books &lt;- original_books %&gt;%
  unnest_tokens(word, text)
tidy_books</code></pre>
<pre><code>## # A tibble: 725,055 x 4
##    book                linenumber chapter word       
##    &lt;fct&gt;                    &lt;int&gt;   &lt;int&gt; &lt;chr&gt;      
##  1 Sense &amp; Sensibility          1       0 sense      
##  2 Sense &amp; Sensibility          1       0 and        
##  3 Sense &amp; Sensibility          1       0 sensibility
##  4 Sense &amp; Sensibility          3       0 by         
##  5 Sense &amp; Sensibility          3       0 jane       
##  6 Sense &amp; Sensibility          3       0 austen     
##  7 Sense &amp; Sensibility          5       0 1811       
##  8 Sense &amp; Sensibility         10       1 chapter    
##  9 Sense &amp; Sensibility         10       1 1          
## 10 Sense &amp; Sensibility         13       1 the        
## # ... with 725,045 more rows</code></pre>
<pre class="r"><code>data(stop_words)
tidy_books &lt;- tidy_books %&gt;%
  anti_join(stop_words)
tidy_books %&gt;%
  count(word, sort = TRUE)</code></pre>
<pre><code>## # A tibble: 13,914 x 2
##    word       n
##    &lt;chr&gt;  &lt;int&gt;
##  1 miss    1855
##  2 time    1337
##  3 fanny    862
##  4 dear     822
##  5 lady     817
##  6 sir      806
##  7 day      797
##  8 emma     787
##  9 sister   727
## 10 house    699
## # ... with 13,904 more rows</code></pre>
<ol style="list-style-type: decimal">
<li><strong style="color: darkred;">Corpus</strong> : These types of objects typically contain raw strings annotated with additional metadata and details.</li>
<li><strong style="color: darkred;">Document-term matrix</strong> : This is a sparse matrix describing a collection (i.e., a corpus) of documents with one row for each document and one column for each term. The value in the matrix is typically word count or tf-idf (see Chapter 3).</li>
<li>A <strong style="color: darkred;">tibble</strong> is a modern class of data frame within R, available in the dplyr and tibble packages, that has a convenient print method, will <strong style="color: darkred;">not convert strings to factors, and does not use row names</strong> . Tibbles are great for use with tidy tools.</li>
<li>A <strong style="color: darkred;">token</strong> is a meaningful unit of text, most often a word, that we are interested in using for further analysis, and tokenization is the process of splitting text into tokens 5.Stop words are words that are not useful for an analysis, typically extremely common words such as “the”, “of”, “to”, and so forth in English. We can remove stop words (kept in the tidytext dataset stop_words) with an anti_join(). <img src="https://www.tidytextmining.com/images/tidyflow-ch-1.png" /></li>
</ol>
<pre class="r"><code>library(ggplot2)
tidy_books %&gt;%
  count(word, sort = TRUE) %&gt;%
  filter(n &gt; 600) %&gt;%
  mutate(word = reorder(word, n)) %&gt;%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()</code></pre>
<p><img src="/post/2018-09-20-nlp-part04-word-count-use-r_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="gutenbergr" class="section level2">
<h2><strong style="color: darkred;">Gutenbergr</strong></h2>
<blockquote>
<p>The gutenbergr package provides access to the public domain works from the <a href="https://www.gutenberg.org/">Project Gutenberg</a> collection. The package includes tools both for downloading books (stripping out the unhelpful header/footer information), and a complete dataset of Project Gutenberg metadata that can be used to find works of interest. </p>
</blockquote>
<pre class="r"><code>library(&quot;gutenbergr&quot;)
hgwells &lt;- gutenberg_download(c(35, 36, 5230, 159))
tidy_hgwells &lt;- hgwells %&gt;%
  unnest_tokens(word, text) %&gt;%
  anti_join(stop_words)
tidy_hgwells %&gt;%
  count(word, sort = TRUE)</code></pre>
<pre><code>## # A tibble: 11,769 x 2
##    word       n
##    &lt;chr&gt;  &lt;int&gt;
##  1 time     454
##  2 people   302
##  3 door     260
##  4 heard    249
##  5 black    232
##  6 stood    229
##  7 white    222
##  8 hand     218
##  9 kemp     213
## 10 eyes     210
## # ... with 11,759 more rows</code></pre>
<pre class="r"><code>bronte &lt;- gutenberg_download(c(1260, 768, 969, 9182, 767))
tidy_bronte &lt;- bronte %&gt;%
  unnest_tokens(word, text) %&gt;%
  anti_join(stop_words)
tidy_bronte %&gt;%
  count(word, sort = TRUE)</code></pre>
<pre><code>## # A tibble: 23,050 x 2
##    word       n
##    &lt;chr&gt;  &lt;int&gt;
##  1 time    1065
##  2 miss     855
##  3 day      827
##  4 hand     768
##  5 eyes     713
##  6 night    647
##  7 heart    638
##  8 looked   601
##  9 door     592
## 10 half     586
## # ... with 23,040 more rows</code></pre>
<div id="frequence" class="section level3">
<h3>Frequence</h3>
<pre class="r"><code>library(tidyr)
frequency &lt;-
  bind_rows(
    mutate(tidy_bronte, author = &quot;Brontë Sisters&quot;),
    mutate(tidy_hgwells, author = &quot;H.G. Wells&quot;),
    mutate(tidy_books, author = &quot;Jane Austen&quot;)
  ) %&gt;%
  mutate(word = str_extract(word, &quot;[a-z&#39;]+&quot;)) %&gt;%
  count(author, word) %&gt;%
  group_by(author) %&gt;%
  mutate(proportion = n / sum(n)) %&gt;%
  select(-n) %&gt;%
  spread(author, proportion) %&gt;%
  gather(author, proportion, `Brontë Sisters`:`H.G. Wells`)</code></pre>
</div>
<div id="plot" class="section level3">
<h3>Plot</h3>
<pre class="r"><code>library(scales)

# expect a warning about rows with missing values being removed
ggplot(frequency, aes(x = proportion, y = `Jane Austen`, color = abs(`Jane Austen` - proportion))) +
  geom_abline(color = &quot;gray40&quot;, lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = &quot;darkslategray4&quot;, high = &quot;gray75&quot;) +
  facet_wrap(~author, ncol = 2) +
  theme(legend.position=&quot;none&quot;) +
  labs(y = &quot;Jane Austen&quot;, x = NULL)</code></pre>
<p><img src="/post/2018-09-20-nlp-part04-word-count-use-r_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>We explored <strong style="color: darkred;">what we mean by tidy data</strong> when it comes to text, and <strong style="color: darkred;">how tidy data principles </strong> can be applied to natural language processing. When text is organized in <strong style="color: darkred;">a format with one token per row, tasks</strong> like removing stop words or calculating word frequencies are natural applications of familiar operations within the tidy tool ecosystem. The one-token-per-row framework can be extended from single words to n-grams and other meaningful units of text, as well as to many other analysis priorities.</p>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="//tags/nlp/">NLP</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/10/pubchunks_extract_parts_of_scholarly_xml_articles/" data-tooltip="pubchunks：提取学术文章的某部分">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/09/nlp-part-03-sentiment-analysis/" data-tooltip="NLP part 03 sentiment analysis">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/09/nlp-part04-word-count-use-r/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/09/nlp-part04-word-count-use-r/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/09/nlp-part04-word-count-use-r/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2019 Jixing Liu. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/10/pubchunks_extract_parts_of_scholarly_xml_articles/" data-tooltip="pubchunks：提取学术文章的某部分">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/09/nlp-part-03-sentiment-analysis/" data-tooltip="NLP part 03 sentiment analysis">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/09/nlp-part04-word-count-use-r/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/09/nlp-part04-word-count-use-r/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/09/nlp-part04-word-count-use-r/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2018%2F09%2Fnlp-part04-word-count-use-r%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2018%2F09%2Fnlp-part04-word-count-use-r%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2F2018%2F09%2Fnlp-part04-word-count-use-r%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://i.loli.net/2018/02/26/5a937bb148b02.jpg" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Jixing Liu</h4>
    
      <div id="about-card-bio">Reading And Writing</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Data Scientist
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        China
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/06/deep-work/">
                <h3 class="media-heading">Deep Work</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">最近在读 卡尔.纽波特的 深度工作, 以下是阅读的一点感悟和笔记.
 深度工作是 21 世纪的超级力量
 作者介绍: 卡尔·纽波特，畅销书作家，人气博主，创办了在美国很受欢迎的博客“学习黑客”，破解工作和学习领域的成功模式。
 关于本书 这是一本自我管理类书籍，讲述了在碎片化时代，如何训练大脑排除干扰，提高大脑的深度思维能力，创造更多价值。这本书的英文原版2016年在美国出版，一发行就占据了亚马逊美国网站的职场励志书榜首。
几个问题:
在职场中，为什么有些人越忙碌越无法产出有价值的成果？ 又该如何通过训练大脑排除干扰，提高深度思维能力，创造更多价值？  这本书从2个方面解释了大部分人无法进行深度工作的原因，并给出了培养深度工作的4个步骤，分别是:
选择适合自己的深度工作模式 将工作内化成习惯 像经商一样去执行 适当减少整体工作时间遵循这几个步骤进行刻意练习   概念介绍 深度工作(Deep Work): 在没有干扰的情况下专注的进行职业活动, 使个人的认知能力达到极限, 这种努力能够创造新价值, 提升技能, 而且难以复制.
肤浅工作(shallow work): 对认知要求不高的任务, 在收到干扰的情况下也能进行, 此类工作创造的价值不高, 且容易复制.
 深度工作的重要性 作者前面花了大量篇幅说明深度工作的重要性, 其中关于注意的论断深以为然.
快速学习复杂的技能, 这能为我们带来价值, 这件事需要深度工作.
但是现实生活中, 网络工具使我们分心, 导致专注能力的下降. 不分心是很难的, 我们都有一种冲动就是, 把自己的注意力转移到肤浅的事物上.
比如, 工作累了或者遇到难题了就要刷刷社交网络, 但是这种行为其实还是在消耗着你的注意力和能量. 你的意志力是有限的, 它在使用的过程中是不断的被消耗的. 而进入深度工作状态是需要意志力能量, 如何使得这个转化过程变得容易使我们应该掌握的技巧. 简而言之, 我们增加深度工作的评率, 而减小转移到肤浅工作的冲动和频率. 我们都有过类似的经历, 打开 word 文档, 准备写论文和报告, 一瞬间脑袋空白, 这时候平时不相干的事情, 突然都变得可爱起来, 比如: 洗完, 扫地, 洗衣服, 收拾房间, 下楼买💊, 总之只要是不是写论文, 什么其他能拖延这件事情的事, 我们都愿意干.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/05/the-hello-world-of-neural-network/">
                <h3 class="media-heading">The Hello World Of Neural Network</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  May 5, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">简单来说神经网络和我们一般的编程区别在于: 一个是输入数据和函数规则, 然后得到结果. 而神经网络是输入数据和答案, 通过迭代学习, 神经网络能学习出函数规则.如下图:
举个简单的例子, 这里有两组数据:
X: -1, 0, 1, 2, 3, 4 Y: -3, -1, 1, 3, 5, 7
你可以把 x 看做是数据, y 看做是答案, 现在你要做的是找到其中的函数关系, 这个关系能够帮助我们, 用 x 去预测 Y 的值(假设你没有学过解方程组).
最常用的方法就是归纳法, 首先你根据第一对数据猜一个对应关系规则, 拿着这个规则计算答案值, 评估计算的答案和真实答案差多远, 然后在调整你的规则, 继续评估, 直到你的规则能够拟合所有的数据.
这就是神经网络的逻辑过程.
我们来看一个简单的神经网络的例子
1.Import: 加载所需模块 import tensorflow as tf ## /Users/zero/anaconda3/envs/tfdeeplearning/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module &#39;tensorflow.python.framework.fast_tensor_util&#39; does not match runtime version 3.5 ## return f(*args, **kwds) import numpy as np from tensorflow import keras  2.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/04/analyze-and-visualize-your-iphone-s-health-app-data-in-r/">
                <h3 class="media-heading">使用 R 分析可视化你的 iPhone 健康 APP 数据</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">介绍 iPhone 的 health APP 存储着我们的私人健康数据, 这里有一篇帖子是用 Python 分析 health APP 的数据Apple Health Data How to Export Analyze Visualize Guide - ryanpraski.com , 而我更喜欢 R 的版本.
让我们赶紧开始吧!!
 首先获取数据并读取 从你的 health APP 应用中导出数据 在 R 中读取数据  加载包并读入数据 library(XML) library(tidyverse) library(lubridate) library(scales) library(here) library(ggthemes) xml &lt;- xmlParse(here(&quot;data/apple_health_export/export.xml&quot;)) summary(xml) ## $nameCounts ## ## Record ExportDate HealthData Me Workout ## 90037 1 1 1 1 ## ## $numNodes ## [1] 90041 Record 是我的主要数据, 有 90,037 条</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/03/tao_wang_bei_shang_guang/">
                <h3 class="media-heading">逃往北上广</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">奋斗，应该是一种生活方式, 登山并不全是为了登顶的那一刻
 只有不停奋斗的人生，才有意义，才活的有劲儿，混吃等死的日子其实是很艰难的，无聊死了，一头扎进人堆儿里不停的扑棱才有意思啊！
逃往北京、上海、广州、深圳
在家乡，在那个你生长了二三十年的小城镇，如果你拒绝过上和所有人一样循规蹈矩的生活，拒绝结婚生子，拒绝稳定工作，拒绝放弃影响你赚钱升职的爱好，那么你就变成了一头和周围的一切格格不入的怪物。
于是大家要挽救你，要教育你，要让你学会认命，停止毫无意义的折腾，这样你才能和大家一样“踏踏实实过日子”。
许多人因此选择了对抗，在愤怒中慢慢变得绝望，在绝望中变得麻木，在麻木中逃往虚无</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/10/pubchunks_extract_parts_of_scholarly_xml_articles/">
                <h3 class="media-heading">pubchunks：提取学术文章的某部分</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">背景 pubchunks 的目的是从XML格式的学术文章中获取部分数据。我们不需要了解XML及其所有的格式原理。只需知道我们的文件或XML字符串在哪里以及我们想要每篇文章的哪些部分。然后用户可以组合这些部分并做我们希望下游的任何事情; 例如,分析文本结构
 pubchunks中的函数 两个主要功能是：
pub_chunks()：获取XML部分 pub_tabularize()：强制输出pub_chunks()到data.frame中 pub_guess_publisher()：从XML文件或字符串猜测发布者 pub_sections()：部分pubchunks知道如何处理 pub_providers()：提供者（即发布者）pubchunks知道如何明确处理   支持的出版商 elife plos elsevier hindawi pensoft peerj copernicus frontiers f1000research   支持提取的部分有: Front - 发布者，期刊和文章元数据元素 Body - 文章的正文 Back - 文章的背面，致谢，作者贡献，参考文献 Title - 文章标题 Doi - 文章doi Categories - 发布商的类别，如果有的话 Author - 作者 Aff - 隶属关系（包括作者姓名） Keyword - 关键字 Abstract - 文章摘要 Executive_summary - 文章执行摘要 Refs - 参考文献 Refs_dois - 参考dois - 如果有的话 Publisher - 发布者名称 Journal_meta - 期刊元数据 Article_meta - 文章元数据 Acknowledgments - 致谢 Permissions - 文章权限 History - 日期，收到，出版，接受等   安装 #install.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/09/nlp-part04-word-count-use-r/">
                <h3 class="media-heading">NLP part04 word count use R</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Sep 9, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">What Is Clean Data Each variable is a column Each observation is a row Each type of observational unit is a table   A table with one-token-per-row.  A token is a meaningful unit of text, such as a word, that we are interested in using for analysis, and tokenization is the process of splitting text into tokens.
 text &lt;- c( &quot;Because I could not stop for Death -&quot;, &quot;He kindly stopped for me -&quot;, &quot;The Carriage held but just Ourselves -&quot;, &quot;and Immortality&quot; ) text ## [1] &quot;Because I could not stop for Death -&quot; ## [2] &quot;He kindly stopped for me -&quot; ## [3] &quot;The Carriage held but just Ourselves -&quot; ## [4] &quot;and Immortality&quot; library(dplyr) text_df &lt;- data_frame(line = 1:4, text = text) text_df ## # A tibble: 4 x 2 ## line text ## &lt;int&gt; &lt;chr&gt; ## 1 1 Because I could not stop for Death - ## 2 2 He kindly stopped for me - ## 3 3 The Carriage held but just Ourselves - ## 4 4 and Immortality library(tidytext) text_df %&gt;% unnest_tokens(word, text) ## # A tibble: 20 x 2 ## line word ## &lt;int&gt; &lt;chr&gt; ## 1 1 because ## 2 1 i ## 3 1 could ## 4 1 not ## 5 1 stop ## 6 1 for ## 7 1 death ## 8 2 he ## 9 2 kindly ## 10 2 stopped ## 11 2 for ## 12 2 me ## 13 3 the ## 14 3 carriage ## 15 3 held ## 16 3 but ## 17 3 just ## 18 3 ourselves ## 19 4 and ## 20 4 immortality For tidy text mining, the token that is stored in each row is most often a single word, but can also be an n-gram, sentence, or paragraph</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/09/nlp-part-03-sentiment-analysis/">
                <h3 class="media-heading">NLP part 03 sentiment analysis</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Sep 9, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Case Study: Sentiment Analysis Data Prep import pandas as pd import numpy as np # Read in the data df = pd.read_csv(&#39;/Users/zero/Desktop/NLP/raw-data/Amazon_Unlocked_Mobile.csv&#39;) # 对数据进行采样以加快计算速度 # Comment out this line to match with lecture df = df.sample(frac=0.1, random_state=10) df.head()   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }   &lt;tr style=&quot;text-align: right;&quot;&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;Product Name&lt;/th&gt; &lt;th&gt;Brand Name&lt;/th&gt; &lt;th&gt;Price&lt;/th&gt; &lt;th&gt;Rating&lt;/th&gt; &lt;th&gt;Reviews&lt;/th&gt; &lt;th&gt;Review Votes&lt;/th&gt; &lt;/tr&gt;   &lt;tr&gt; &lt;th&gt;394349&lt;/th&gt; &lt;td&gt;Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/09/nlp-part-03-sentiment-analysis/">
                <h3 class="media-heading">NLP part 03 sentiment analysis</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Sep 9, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><p></p></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/09/npl-use-python-part-01/">
                <h3 class="media-heading">NLP use python part 01</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Sep 9, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><p></p></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/09/will_data_scientists_be_replaced_by_machines_2018-09-10/">
                <h3 class="media-heading">数据科学家会不会被机器取?</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Sep 9, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">数据科学自动化 曾今是一个热门话题, 大多数人都在讨论所谓的“自动化”工具, 人们声称他们的工具可以自动化数据科学过程。给人一种错觉, 只要将这些工具与大数据架构相结合就可以解决任何业务问题。
但是其实在实际的数据分析工作中, 自动化建模部分仅仅占到总工作量的10%, 大多数的时间和精力花在了 feature engineering 和 feature selection。 比起构建一个复杂的模型, 我们更应该关注的问题这些问题 例如: 定义要解决的问题，获取数据，探索数据，部署项目，调试和监视, 而这些问题往往都无法完全自动化。
这里 Berry 和 Linoff 从摄影的角度给了一个有趣的比喻:
 “The camera can relieve the photographer from having to set the shutter speed, aperture and other settings every time a picture is taken. This makes the process easier for expert photographers and makes better photography accessible to people who are not experts. But this is still automating only a small part of the process of producing a photograph.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         54 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('https://i.loli.net/2018/02/26/5a9416186c149.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js" integrity="sha256-IFHWFEbU2/+wNycDECKgjIRSirRNIDp2acEB5fvdVRU=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js" integrity="sha256-+mpyNVJsNt4rVXCw0F+pAOiB3YxmHgrbJsx4ecPuUaI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js" integrity="sha256-vMxgR/7FtLovVA+IPrR7+xTgIgARH7y9VZQnmmi0HDI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js" integrity="sha256-N0qFUh7/9vLvia87dDndewmsgsyYoNkdA212tPc+2NI=" crossorigin="anonymous"></script>


<script src="/js/script-kr8dyqj6rb6ortyib7whfo9x9p6td6zo8t1v4fdz4ecx5kwybsdlmk1slygn.min.js"></script>


<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>

  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2018\/09\/nlp-part04-word-count-use-r\/';
          
            this.page.identifier = '\/2018\/09\/nlp-part04-word-count-use-r\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'jixing';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>

