<feed xmlns="http://www.w3.org/2005/Atom">
  <title>student zero </title>
  <link href="/index.xml" rel="self"/>
  <link href="/"/>
  <updated>2018-05-09T00:00:00+00:00</updated>
  <id>/</id>
  <author>
    <name>Jixing Liu</name>
  </author>
  <generator>Hugo -- gohugo.io</generator>
  <entry>
    <title type="html"><![CDATA[LELTS speaking: constructing your answers]]></title>
    <link href="/2018/05/lelts-speaking-constructing-your-answers/"/>
    <id>/2018/05/lelts-speaking-constructing-your-answers/</id>
    <published>2018-05-09T00:00:00+00:00</published>
    <updated>2018-05-09T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p><center><h2>  <strong style="color: darkred;"> 四个要注意的问题</strong> </h2></center></p>

<ol>
<li>流畅性</li>
<li>丰富多变的词汇</li>
<li>语法和准确</li>
<li>发音</li>
</ol>

<p><center><h2>  <strong style="color: darkred;">答案的基本结构</strong> </h2></center></p>

<p>直接回答 + 连接词 + <strong style="color: darkred;">扩展句子</strong> ：</p>

<ol>
<li>原因</li>
<li>细节</li>
<li>例子</li>
<li>事情的两面性</li>
</ol>

<p><center><h2>  <strong style="color: darkred;">常见词语的替代</strong> </h2></center></p>

<ol>
<li><p>And</p>

<ul>
<li>in addition to what i have just mentioned earlier</li>
<li>on the top of that</li>
<li>as well as this</li>
<li>second to that</li>
<li>among other things</li>
<li>as a further matter
<br /></li>
</ul></li>

<li><p>So</p>

<ul>
<li>this is the reason why</li>
<li>this wxplains why</li>
<li>and the result of this is
<br /></li>
</ul></li>

<li><p>But</p>

<ul>
<li>however</li>
<li>meanwhile</li>
<li>on the other hand</li>
<li>in the meantime
<br /></li>
</ul></li>

<li><p>I think</p>

<ul>
<li>i believe</li>
<li>i reckon</li>
<li>i&rsquo;m convinced to say that</li>
<li>i&rsquo;m inclined to believe that</li>
<li>my view on this matter is
<br /></li>
</ul></li>

<li><p>In my opinion</p>

<ul>
<li>as far as i&rsquo;m concerned</li>
<li>from what i can see</li>
<li>come to think of it</li>
<li>the way i see it
<br /></li>
</ul></li>

<li><p>Because</p>

<ul>
<li>and this is probably because</li>
<li>i guess the reason for that is</li>
<li>the reason i feel this way is</li>
<li>it is mainly due to the fact that
<br /></li>
</ul></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[R vs python]]></title>
    <link href="/2018/05/r-vs-python-representing-data-in-r-python-equivalent/"/>
    <id>/2018/05/r-vs-python-representing-data-in-r-python-equivalent/</id>
    <published>2018-05-03T00:00:00+00:00</published>
    <updated>2018-05-03T00:00:00+00:00</updated>
    <content type="html"><![CDATA[

<h2 id="strong-style-color-darkred-representing-data-in-r-python-equivalent-strong"><strong style="color: darkred;">Representing Data in R &ndash; Python equivalent</strong></h2>

<pre><code class="language-python">import pandas as pd
import numpy as np
</code></pre>

<pre><code class="language-python"># 'characters' is equivalent to string
firstName = 'jeff'
print((type(firstName), firstName))
</code></pre>

<pre><code>&lt;type 'str'&gt; jeff
</code></pre>

<pre><code class="language-python"># 'numeric' is equivalent to float
heightCM = 188.2
print((type(heightCM), heightCM))
</code></pre>

<pre><code>&lt;type 'float'&gt; 188.2
</code></pre>

<pre><code class="language-python"># integer is equivalent to integer
numberSons = 1
print((type(numberSons), numberSons))
</code></pre>

<pre><code>&lt;type 'int'&gt; 1
</code></pre>

<pre><code class="language-python"># 'logical' is equivalent to Boolean
teachingCoursera = True
print((type(teachingCoursera), teachingCoursera))
</code></pre>

<pre><code>&lt;type 'bool'&gt; True
</code></pre>

<pre><code class="language-python"># 'vectors' is equivalent to numpy array or Python list (I will use array everywhere for consistency)
heights = np.array([188.2, 181.3, 193.4])
print(heights)

firstNames = np.array(['jeff', 'roger', 'andrew', 'brian'])
print(firstNames)
</code></pre>

<pre><code>[ 188.2  181.3  193.4]
['jeff' 'roger' 'andrew' 'brian']
</code></pre>

<pre><code class="language-python"># 'list' is equivalent to dictionary in Python
vector1 = np.array([188.2, 181.3, 193.4])
vector2 = np.array(['jeff', 'roger', 'andrew', 'brian'])
myList = dict(heights = vector1, firstNames = vector2)
print(myList)

print((myList['heights']))
print((myList['firstNames']))
</code></pre>

<pre><code>{'firstNames': array(['jeff', 'roger', 'andrew', 'brian'], 
      dtype='|S6'), 'heights': array([ 188.2,  181.3,  193.4])}
[ 188.2  181.3  193.4]
['jeff' 'roger' 'andrew' 'brian']
</code></pre>

<pre><code class="language-python"># 'matrices' is equivalent to two-dimensional numpy array
myMatrix = np.array([[1, 2], [3, 4]])
print(myMatrix)
</code></pre>

<pre><code>[[1 2]
 [3 4]]
</code></pre>

<pre><code class="language-python"># data frame is equivalent to Pandas DataFrame
# this example doesn't work because the input array lengths are not the same
vector1 = np.array([188.2, 181.3, 193.4])
vector2 = np.array(['jeff', 'roger', 'andrew', 'brian'])

# ValueError: arrays must all be same length
# 
myDataFrame = pd.DataFrame(dict(heights = vector1, firstNames = vector2))
</code></pre>

<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)

&lt;ipython-input-10-58e1535d1fac&gt; in &lt;module&gt;()
      6 # ValueError: arrays must all be same length
      7 #
----&gt; 8 myDataFrame = pd.DataFrame(dict(heights = vector1, firstNames = vector2))


/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/frame.pyc in __init__(self, data, index, columns, dtype, copy)
    383             mgr = self._init_mgr(data, index, columns, dtype=dtype, copy=copy)
    384         elif isinstance(data, dict):
--&gt; 385             mgr = self._init_dict(data, index, columns, dtype=dtype)
    386         elif isinstance(data, ma.MaskedArray):
    387             mask = ma.getmaskarray(data)


/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/frame.pyc in _init_dict(self, data, index, columns, dtype)
    515 
    516         return _arrays_to_mgr(arrays, data_names, index, columns,
--&gt; 517                               dtype=dtype)
    518 
    519     def _init_ndarray(self, values, index, columns, dtype=None,


/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/frame.pyc in _arrays_to_mgr(arrays, arr_names, index, columns, dtype)
   5343     # figure out the index, if necessary
   5344     if index is None:
-&gt; 5345         index = extract_index(arrays)
   5346     else:
   5347         index = _ensure_index(index)


/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/frame.pyc in extract_index(data)
   5395             lengths = list(set(raw_lengths))
   5396             if len(lengths) &gt; 1:
-&gt; 5397                 raise ValueError('arrays must all be same length')
   5398 
   5399             if have_dicts:


ValueError: arrays must all be same length
</code></pre>

<pre><code class="language-python"># data frame -- fixed
vector1 = np.array([188.2, 181.3, 193.4, 192.3])
vector2 = np.array(['jeff', 'roger', 'andrew', 'brian'])

myDataFrame = pd.DataFrame(dict(heights = vector1, firstNames = vector2))
myDataFrame
</code></pre>

<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>firstNames</th>
      <th>heights</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>   jeff</td>
      <td> 188.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>  roger</td>
      <td> 181.3</td>
    </tr>
    <tr>
      <th>2</th>
      <td> andrew</td>
      <td> 193.4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>  brian</td>
      <td> 192.3</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="language-python"># factors is equivalent to pandas Categorical
smoker = np.array(['yes', 'no', 'yes', 'yes'])
smokerFactor = pd.Categorical.from_array(smoker)
smokerFactor
</code></pre>

<pre><code>Categorical: 
array(['yes', 'no', 'yes', 'yes'], dtype=object)
Levels (2): Index(['no', 'yes'], dtype=object)
</code></pre>

<pre><code class="language-python"># R's NA missing values is equivalent to NaN
vector1 = np.array([188.2, 181.3, 193.4, NaN])
print(vector1)
print((isnan(vector1)))
</code></pre>

<pre><code>[ 188.2  181.3  193.4    nan]
[False False False  True]
</code></pre>

<pre><code class="language-python"># subsetting
vector1 = np.array([188.2, 181.3, 193.4, 192.3])
vector2 = np.array(['jeff', 'roger', 'andrew', 'brian'])

myDataFrame = pd.DataFrame(dict(heights = vector1, firstNames = vector2))

print('------------------')
print((vector1[0]))
print('------------------')
print((vector1[[0, 1, 3]]))
print('------------------')
print((myDataFrame.ix[0, 0:2])) # appears transposed as compared to R
print('------------------')
print((myDataFrame['firstNames'])) # there's no 'Levels' as in R
print('------------------')
print((myDataFrame[myDataFrame['firstNames'] == 'jeff']))
print('------------------')
print((myDataFrame[myDataFrame['heights'] &lt; 190]))
</code></pre>

<pre><code>------------------
188.2
------------------
[ 188.2  181.3  192.3]
------------------
firstNames     jeff
heights       188.2
Name: 0
------------------
0      jeff
1     roger
2    andrew
3     brian
Name: firstNames
------------------
  firstNames  heights
0       jeff    188.2
------------------
  firstNames  heights
0       jeff    188.2
1      roger    181.3
</code></pre>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[How To Get Genomewide Position-Specific Scores]]></title>
    <link href="/2018/04/how-to-get-genomewide-position-specific-scores/"/>
    <id>/2018/04/how-to-get-genomewide-position-specific-scores/</id>
    <published>2018-04-27T00:00:00+00:00</published>
    <updated>2018-04-27T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div id="load-packages" class="section level2">
<h2>load packages</h2>
<pre class="r"><code>#source(&quot;http://bioconductor.org/biocLite.R&quot;)
#biocLite(&quot;GenomicScores&quot;)
library(GenomicScores)</code></pre>
</div>
<div id="retrieval-of-genomic-scores-through-annotation-packages" class="section level2">
<h2>Retrieval of genomic scores through annotation packages</h2>
<p>There are currently four different annotation packages that store genomic scores and can be accessed using the <em><a href="http://bioconductor.org/packages/GenomicScores">GenomicScores</a></em> package</p>
<p><strong style="color: darkred;">Annotation packages </strong> <strong style="color: darkred;">Description</strong> 1. <em><a href="http://bioconductor.org/packages/phastCons100way.UCSC.hg19">phastCons100way.UCSC.hg19</a></em> phastCons scores derived from the alignment of the human genome (hg19) to other 99 vertebrate species. 2. <em><a href="http://bioconductor.org/packages/phastCons100way.UCSC.hg38">phastCons100way.UCSC.hg38</a></em> phastCons scores derived from the alignment of the human genome (hg38) to other 99 vertebrate species. 3. <em><a href="http://bioconductor.org/packages/phastCons7way.UCSC.hg38">phastCons7way.UCSC.hg38</a></em> phastCons scores derived from the alignment of the human genome (hg38) to other 6 mammal species. 4. <em><a href="http://bioconductor.org/packages/fitCons.UCSC.hg19">fitCons.UCSC.hg19</a></em> fitCons scores: fitness consequences of functional annotation for the human genome (hg19).</p>
<div id="to-retrieve-genomic-scores-for-specific-positions-we-should-use-the-function-scores" class="section level3">
<h3><strong style="color: darkred;">To retrieve genomic scores for specific positions we should use the function scores()</strong></h3>
<pre class="r"><code>library(phastCons100way.UCSC.hg19)
gsco &lt;- phastCons100way.UCSC.hg19
class(gsco)</code></pre>
<pre><code>## [1] &quot;GScores&quot;
## attr(,&quot;package&quot;)
## [1] &quot;GenomicScores&quot;</code></pre>
<pre class="r"><code>scores(gsco, GRanges(seqnames=&quot;chr22&quot;,
                     IRanges(start=50967020:50967021, width=1)))</code></pre>
<pre><code>## GRanges object with 2 ranges and 1 metadata column:
##       seqnames               ranges strand |    scores
##          &lt;Rle&gt;            &lt;IRanges&gt;  &lt;Rle&gt; | &lt;numeric&gt;
##   [1]    chr22 [50967020, 50967020]      * |         1
##   [2]    chr22 [50967021, 50967021]      * |         1
##   -------
##   seqinfo: 1 sequence from an unspecified genome; no seqlengths</code></pre>
<pre class="r"><code>gsco</code></pre>
<pre><code>## GScores object 
## # organism: Homo sapiens (UCSC)
## # provider: UCSC
## # provider version: 09Feb2014
## # download date: Mar 17, 2017
## # loaded sequences: chr19_gl000208_random, chr22
## # maximum abs. error: 0.05</code></pre>
<pre class="r"><code>#citation(gsco) now cann&#39;t run
provider(gsco)</code></pre>
<pre><code>## [1] &quot;UCSC&quot;</code></pre>
<pre class="r"><code>providerVersion(gsco)</code></pre>
<pre><code>## [1] &quot;09Feb2014&quot;</code></pre>
<pre class="r"><code>organism(gsco)</code></pre>
<pre><code>## [1] &quot;Homo sapiens&quot;</code></pre>
<pre class="r"><code>seqlevelsStyle(gsco)</code></pre>
<pre><code>## [1] &quot;UCSC&quot;</code></pre>
</div>
</div>
<div id="retrieval-of-genomic-scores-through-annotationhub-resources" class="section level2">
<h2>Retrieval of genomic scores through <strong style="color: darkred;">AnnotationHub resources</strong></h2>
<p>Another way to retrieve genomic scores is by using the <em><a href="http://bioconductor.org/packages/AnnotationHub">AnnotationHub</a></em>, which is a web resource that provides a central location where genomic files (e.g., VCF, bed, wig) and other resources from standard (e.g., UCSC, Ensembl) and distributed sites, can be found. A Bioconductor <em><a href="http://bioconductor.org/packages/AnnotationHub">AnnotationHub</a></em> web resource creates and manages a local cache of files retrieved by the user, helping with quick and reproducible access.</p>
<p><img src="/post/2018-04-27-how-to-get-genomewide-position-specific-scores_files/Screen Shot 2018-04-27 at 15.35.21.png" width="30%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>gsco &lt;- getGScores(&quot;phastCons7way.UCSC.hg38&quot;)
scores(gsco, GRanges(seqnames=&quot;chr22&quot;,IRanges(start=20967020:20967025, width=1)))</code></pre>
</div>
<div id="retrieval-of-multiple-scores-per-genomic-position" class="section level2">
<h2>Retrieval of <strong style="color: darkred;">multiple scores</strong> per genomic position</h2>
</div>
<div id="summarization-of-genomic-scores" class="section level2">
<h2>Summarization of genomic scores</h2>
<pre class="r"><code>library(dplyr)
gsco &lt;- phastCons100way.UCSC.hg19
gr &lt;- GRanges(seqnames=&quot;chr22&quot;, IRanges(start=50967020:50967025, width=1))

#mean
scores(gsco, gr) %&gt;% 
  .$scores %&gt;% 
  mean()</code></pre>
<pre><code>## [1] 0.8</code></pre>
<pre class="r"><code>#median
scores(gsco, gr) %&gt;% 
  .$scores %&gt;% 
  median()</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>#min
scores(gsco, gr) %&gt;% 
  .$scores %&gt;% 
  min()</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>scores(gsco, gr) %&gt;% 
  .$scores %&gt;% 
  hist()</code></pre>
<p><img src="/post/2018-04-27-how-to-get-genomewide-position-specific-scores_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="annotating-variants-with-genomic-scores" class="section level2">
<h2><strong style="color: darkred;">Annotating variants with genomic scores</strong></h2>
<p>A typical use case of the <em><a href="http://bioconductor.org/packages/GenomicScores">GenomicScores</a></em> package is in the context of annotating variants with genomic scores, such as phastCons conservation scores. For this purpose, we load the <em><a href="http://bioconductor.org/packages/VariantAnnotaiton">VariantAnnotaiton</a></em> and <em><a href="http://bioconductor.org/packages/TxDb.Hsapiens.UCSC.hg19.knownGene">TxDb.Hsapiens.UCSC.hg19.knownGene</a></em> packages. The former will allow us to read a VCF file and annotate it, and the latter contains the gene annotations from UCSC that will be used in this process.</p>
<p>Let’s load one of the sample VCF files that form part of the <em><a href="http://bioconductor.org/packages/VariantAnnotation">VariantAnnotation</a></em> package.</p>
<pre class="r"><code>library(VariantAnnotation)
library(TxDb.Hsapiens.UCSC.hg19.knownGene)
fl &lt;- system.file(&quot;extdata&quot;, &quot;chr22.vcf.gz&quot;, package=&quot;VariantAnnotation&quot;)
vcf &lt;- readVcf(fl, &quot;hg19&quot;)
seqlevelsStyle(vcf)</code></pre>
<pre><code>## [1] &quot;NCBI&quot;    &quot;Ensembl&quot;</code></pre>
<pre class="r"><code>txdb &lt;- TxDb.Hsapiens.UCSC.hg19.knownGene
seqlevelsStyle(txdb)</code></pre>
<pre><code>## [1] &quot;UCSC&quot;</code></pre>
<p>Because the chromosome nomenclature from the VCF file (NCBI) is different from the one with the gene annotations (UCSC) we use the <strong style="color: darkred;">seqlevelsStyle()</strong> function to force our variants having the chromosome nomenclature of the gene annotations.</p>
<pre class="r"><code>seqlevelsStyle(vcf) &lt;- seqlevelsStyle(txdb)</code></pre>
<p>We <strong style="color: darkred;">annotate the location of variants</strong> using the function <strong style="color: darkred;">locateVariants()</strong> from the VariantAnnotation package.</p>
<pre class="r"><code>loc &lt;- locateVariants(vcf, txdb, AllVariants())
loc[1:3]</code></pre>
<pre><code>## GRanges object with 3 ranges and 9 metadata columns:
##    seqnames               ranges strand | LOCATION  LOCSTART    LOCEND
##       &lt;Rle&gt;            &lt;IRanges&gt;  &lt;Rle&gt; | &lt;factor&gt; &lt;integer&gt; &lt;integer&gt;
##       chr22 [50300078, 50300078]      - |   intron     10763     10763
##       chr22 [50300086, 50300086]      - |   intron     10755     10755
##       chr22 [50300101, 50300101]      - |   intron     10740     10740
##      QUERYID        TXID         CDSID      GENEID       PRECEDEID
##    &lt;integer&gt; &lt;character&gt; &lt;IntegerList&gt; &lt;character&gt; &lt;CharacterList&gt;
##            1       75253                     79087                
##            2       75253                     79087                
##            3       75253                     79087                
##           FOLLOWID
##    &lt;CharacterList&gt;
##                   
##                   
##                   
##   -------
##   seqinfo: 1 sequence from hg19 genome; no seqlengths</code></pre>
<pre class="r"><code>table(loc$LOCATION)</code></pre>
<pre><code>## 
## spliceSite     intron    fiveUTR   threeUTR     coding intergenic 
##         11      22572        309       1368       2822       2867 
##   promoter 
##       2864</code></pre>
</div>
<div id="annotate-phastcons-conservation-scores" class="section level2">
<h2><strong style="color: darkred;">Annotate phastCons conservation scores</strong></h2>
<p>on the variants and store those annotations as an additional metadata column of the GRanges object. For this specific purpose we should the argument scores.only=TRUE that makes the scores() method to return the genomic scores as a numeric vector instead as a metadata column in the input ranges object.</p>
<pre class="r"><code>loc$PHASTCONS &lt;- scores(gsco, loc, scores.only=TRUE)
loc[1:3]</code></pre>
<pre><code>## GRanges object with 3 ranges and 10 metadata columns:
##    seqnames               ranges strand | LOCATION  LOCSTART    LOCEND
##       &lt;Rle&gt;            &lt;IRanges&gt;  &lt;Rle&gt; | &lt;factor&gt; &lt;integer&gt; &lt;integer&gt;
##       chr22 [50300078, 50300078]      - |   intron     10763     10763
##       chr22 [50300086, 50300086]      - |   intron     10755     10755
##       chr22 [50300101, 50300101]      - |   intron     10740     10740
##      QUERYID        TXID         CDSID      GENEID       PRECEDEID
##    &lt;integer&gt; &lt;character&gt; &lt;IntegerList&gt; &lt;character&gt; &lt;CharacterList&gt;
##            1       75253                     79087                
##            2       75253                     79087                
##            3       75253                     79087                
##           FOLLOWID PHASTCONS
##    &lt;CharacterList&gt; &lt;numeric&gt;
##                          0.0
##                          0.1
##                          0.0
##   -------
##   seqinfo: 1 sequence from hg19 genome; no seqlengths</code></pre>
<p>Using the following code we can examine <strong style="color: darkred;">the distribution of phastCons conservation scores</strong> of variants across the different annotated regions</p>
<pre class="r"><code>x &lt;- split(loc$PHASTCONS, loc$LOCATION)
mask &lt;- elementNROWS(x) &gt; 0
boxplot(x[mask], ylab=&quot;phastCons score&quot;, las=1, cex.axis=1.2, cex.lab=1.5, col=&quot;gray&quot;)
points(1:length(x[mask])+0.25, 
       sapply(x[mask], mean, na.rm=TRUE),
       pch=23, bg=&quot;red&quot;)</code></pre>
<p><img src="/post/2018-04-27-how-to-get-genomewide-position-specific-scores_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div id="links" class="section level2">
<h2><strong>Links</strong></h2>
<ul>
<li><a href="http://bioconductor.org/packages/release/bioc/vignettes/GenomicScores/inst/doc/GenomicScores.html">An introduction to the GenomicScores package</a></li>
</ul>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[purrr: adverb]]></title>
    <link href="/2018/04/purrr-adverb/"/>
    <id>/2018/04/purrr-adverb/</id>
    <published>2018-04-20T00:00:00+00:00</published>
    <updated>2018-04-20T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div id="what-is-an-adverb" class="section level2">
<h2><strong style="color: darkred;">What is an adverb</strong></h2>
<p>Read carefully the <a href="http://purrr.tidyverse.org/reference/index.html#section-adverbs">purrr documentation</a></p>
<p><img src="https://media.giphy.com/media/8UGoKT4boBkF9MGUb3/giphy.gif" width="30%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Adverbs <strong style="color: darkred;">modify the action of a function</strong> ; taking a function as input and <strong style="color: darkred;">returning a function with modified action as output.</strong></p>
</blockquote>
<p>In other words, adverbs take a function, and return this function modified. Yes, just an adverb modifies a verb.</p>
<pre class="r"><code>library(purrr)
safe_log &lt;- safely(log)#high-order functions
safe_log(&quot;a&quot;)</code></pre>
<pre><code>## $result
## NULL
## 
## $error
## &lt;simpleError in log(x = x, base = base): non-numeric argument to mathematical function&gt;</code></pre>
<pre class="r"><code># have a result and error</code></pre>
</div>
<div id="how-to-write-your-own" class="section level1">
<h1><strong style="color: darkred;">how to write your own?</strong></h1>
<pre class="r"><code>library(attempt)

# Silently only return the errors, and nothing if the function succeeds
silent_log &lt;- silently(log)
silent_log(1)
# Surely make a function always work, without stopping the process
sure_log &lt;- surely(log)
sure_log(1)</code></pre>
<pre><code>## [1] 0</code></pre>
<div id="with_message-and-with_warning" class="section level2">
<h2><strong style="color: darkred;">with_message and with_warning</strong></h2>
<pre class="r"><code>as_num_msg &lt;- with_message(as.numeric, msg = &quot;We&#39;re performing a numeric conversion&quot;)
as_num_warn &lt;- with_warning(as.numeric, msg = &quot;We&#39;re performing a numeric conversion&quot;)
as_num_msg(&quot;1&quot;)</code></pre>
<pre><code>## [1] 1</code></pre>
</div>
</div>
<div id="how-to-implement-this-kind-of-behavior" class="section level1">
<h1>how to implement this kind of behavior?</h1>
<p>Let’s take a simple example with sleepy:</p>
<pre class="r"><code>sleepy &lt;- function(fun, sleep){
  function(...){
    Sys.sleep(sleep)
    fun(...)
  }
}

sleep_print &lt;- sleepy(Sys.time, 5)
class(sleep_print)</code></pre>
<pre><code>## [1] &quot;function&quot;</code></pre>
<pre class="r"><code>sleep_print()</code></pre>
<pre><code>## [1] &quot;2018-04-20 09:15:36 CST&quot;</code></pre>
</div>
<div id="how" class="section level1">
<h1><strong style="color: darkred;">how?</strong></h1>
<p>First of all, the adverb functon should return another function, so we need to start with?</p>
<pre class="r"><code>talky &lt;- function(fun){
  function(...){
    fun(...)
  }
}</code></pre>
<p>secondly, with R referential transparency, you can <strong style="color: darkred;">create a variable that is a function:</strong></p>
<pre class="r"><code>plop &lt;- mean
plop(1:10)</code></pre>
<pre><code>## [1] 5.5</code></pre>
<pre class="r"><code>sys_time &lt;- talky(Sys.time)
sys_time()</code></pre>
<pre><code>## [1] &quot;2018-04-20 09:15:36 CST&quot;</code></pre>
<div id="the-template" class="section level2">
<h2><strong style="color: darkred;">the template</strong></h2>
<pre class="r"><code>talky &lt;- function(fun, mess){
  function(...){
    #add some command
    message(mess)#这里可以添加参数
    print(Sys.time())
    
    print(&quot;you can add anything&quot;)
    
    
    fun(...)#the function you want modify
  }
}

talky_sqrt&lt;- talky(fun = sqrt, mess = &quot;Hey there! You Rock!&quot;)#创建被修饰函数
talky_sqrt(4)#4 是传递给被修饰的函数的</code></pre>
<pre><code>## [1] &quot;2018-04-20 09:15:36 CST&quot;
## [1] &quot;you can add anything&quot;</code></pre>
<pre><code>## [1] 2</code></pre>
<div id="run-it-or-not" class="section level3">
<h3>Run it or not ?</h3>
<pre class="r"><code>maybe &lt;- function(fun){
  function(...){
    num &lt;- sample(1:100, 1)
    if (num &gt; 50) {
      fun(...)
    }
  }
}
maybe_sqrt &lt;- maybe(fun = sqrt)
maybe_sqrt(1)</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>maybe_sqrt(1)</code></pre>
</div>
<div id="create-a-log-file-of-a-function" class="section level3">
<h3>Create a log file of a function</h3>
<pre class="r"><code>log_calls &lt;- function(fun, file){
  function(...){
    write(as.character(Sys.time()), file, append = TRUE, sep = &quot;\n&quot;)
    fun(...)
  }
}
log_sqrt &lt;- log_calls(sqrt, file = &quot;logs&quot;)
log_sqrt(10)</code></pre>
<pre><code>## [1] 3.162278</code></pre>
<p><strong>refrence</strong> - <a href="https://colinfay.me/purrr-adverb-tidyverse/">colin Fay</a></p>
</div>
</div>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[为什么我的锻炼又失败了]]></title>
    <link href="/2018/04/why-did-my-plan-fail-again-2018-04-20/"/>
    <id>/2018/04/why-did-my-plan-fail-again-2018-04-20/</id>
    <published>2018-04-20T00:00:00+00:00</published>
    <updated>2018-04-20T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<center>
<h2>
<strong style="color: darkred;"> 妈蛋！</strong>
</h2>
</center>
<p><strong style="color: darkred;">健康饮食</strong></p>
<p><strong style="color: darkred;">坚持锻炼 </strong></p>
<p><strong style="color: darkred;">好处多多</strong></p>
<p><strong style="color: darkred;">人尽皆知</strong></p>
<p>但要真正做到这两点 真心不容易</p>
<p>今天就好好反思一下 我为什么不能坚持锻炼</p>
<div class="section level2">
<h2><strong style="color: darkred;">放弃的原因:</strong></h2>
<pre><code>. 指定的计划难度太高
. 短期没看到效果就是去了动力
. 被各种琐事干扰，无法正常执行
. 只要中途断了几次，就会放弃锻炼的习惯</code></pre>
<blockquote>
<p><strong style="color: darkred;">能让人在短期内取得显著成效的计划，你都要特别小心。因为往往这种计划太过激烈，没人能长期坚持，很快你就会放弃，取得的成效也会随它而去，甚至还有反弹效果</strong></p>
</blockquote>
</div>
<div id="-" class="section level2">
<h2><strong style="color: darkred;">解决办法:</strong> 把锻炼变成像刷牙一样的常规活动，集中精力想尽一切办法把它边做常规活动</h2>
<pre><code>. 从小的运动开始, 尽量从小的开始直到你学会了坚持。可以慢慢增加运动量，哪怕你一开始能够多做一些，也一定要忍住，
. 安排固定的锻炼时间，这段时间最好能不受到其他事情的干扰
. 养成习惯中最重要的一点就是坚持不懈，只要错过几次，你就会开始犯懒。多少次都是因为这个败下阵来，😔
. 最好找个搭档，和别人约定一起，会帮助你自律</code></pre>
<p><img src="https://media.giphy.com/media/8UGoKT4boBkF9MGUb3/giphy.gif" width="30%" style="display: block; margin: auto;" /></p>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[algorithms: quick sort]]></title>
    <link href="/2018/04/algorithms-quick-sort/"/>
    <id>/2018/04/algorithms-quick-sort/</id>
    <published>2018-04-18T00:00:00+00:00</published>
    <updated>2018-04-18T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div id="--dcdivde-and-conquer" class="section level1">
<h1>快速排序 和 分而治之（D&amp;C）divde and conquer</h1>
<ul>
<li>D&amp;C 将问题逐步分解，找到最基本的情况为止</li>
<li>快速排序，随机的选择基准值，平均运行时间为**O(n*logn)**</li>
</ul>
<p><img src="https://i.loli.net/2018/04/18/5ad680ee22950.jpg" width="30%" style="display: block; margin: auto;" /></p>
<pre class="python"><code>def quicksort(array):
  if len(array) &lt; 2:# base case, arrays with 0 or 1 element are already &quot;sorted&quot;
    return array
  else:# recursive case
    pivot = array[0]# sub-array of all the elements less than the pivot
    less = [i for i in array[1:] if i &lt;= pivot]# sub-array of all the elements greater than the pivot
    greater = [i for i in array[1:] if i &gt; pivot]
    return quicksort(less) + [pivot] + quicksort(greater)
print(quicksort([10, 5, 2, 3]))
    </code></pre>
<pre><code>## [2, 3, 5, 10]</code></pre>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[algorithms: recursive]]></title>
    <link href="/2018/04/algorithms-recursive/"/>
    <id>/2018/04/algorithms-recursive/</id>
    <published>2018-04-18T00:00:00+00:00</published>
    <updated>2018-04-18T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div class="section level1">
<h1>递归</h1>
<ul>
<li><strong style="color: darkred;">递归指的是调用自己的函数</strong></li>
<li>每个递归都有两个条件
<ul>
<li><strong style="color: darkred;">base case</strong> : 终止条件</li>
<li><strong style="color: darkred;">recursive case</strong> : 递归条件</li>
</ul></li>
<li>所有的函数的调用都遵循 call stack</li>
<li>递归语法的清晰是以内存为代价的</li>
</ul>
<p><img src="https://i.loli.net/2018/04/18/5ad6782dbd45a.jpg" width="30%" style="display: block; margin: auto;" /></p>
</div>
<div class="section level1">
<h1>通过递归求阶乘</h1>
<pre class="python"><code>def fact(n):
  if n == 1: #base case(终止条件)
    return 1
  else:
    return n * fact(n-1)#recursive case
    
print(fact(5))</code></pre>
<pre><code>## 120</code></pre>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[workflow: Organising projects for reproducibility]]></title>
    <link href="/2018/04/workflow-organising-projects-for-reproducibility/"/>
    <id>/2018/04/workflow-organising-projects-for-reproducibility/</id>
    <published>2018-04-18T00:00:00+00:00</published>
    <updated>2018-04-18T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div id="why-reproducible" class="section level1">
<h1><strong style="color: darkred;">why reproducible</strong></h1>
<blockquote>
<p>The fundamental idea behind a <strong style="color: darkred;"><strong>robust, reproducible analysis</strong></strong> is a clean, repeatable script-based workflow (i.e. the sequence of tasks from the start to the end of a project) that links <strong>raw data</strong> through to <strong>clean data</strong> and to <strong>final analysis outputs</strong>.</p>
</blockquote>
<div id="principles-of-a-good-analysis-workflow" class="section level2">
<h2><strong style="color: darkred;">principles of a good analysis workflow</strong></h2>
<ol style="list-style-type: decimal">
<li>Any cleaning, merging, transforming, etc. of data <strong>should be done in scripts</strong>, not manually.</li>
<li><strong>Split your workflow (scripts) into logical thematic units</strong>. For example, you might separate your code into scripts that
<ul>
<li><ol style="list-style-type: lower-roman">
<li>load, merge and clean data</li>
</ol></li>
<li><ol start="2" style="list-style-type: lower-roman">
<li>analyse data</li>
</ol></li>
<li><ol start="3" style="list-style-type: lower-roman">
<li>produce outputs like figures and tables</li>
</ol></li>
</ul></li>
<li><p>Eliminate code duplication by <strong>packaging up useful code into custom functions</strong> (Programming: write a function). Make sure to comment your functions thoroughly, explaining their expected inputs and outputs, and what they are doing and why.</p></li>
<li><p><strong>Document your code and data as comments in your scripts</strong> or by producing separate documentation (see Programming and Reproducible reports).</p></li>
<li><p>Any intermediary outputs generated by your workflow should be kept separate from raw data. <strong>结果输出应该和原始数据分开</strong></p></li>
</ol>
</div>
</div>
<div id="file-system-structure" class="section level1">
<h1><strong style="color: darkred;">file system structure</strong></h1>
<ol style="list-style-type: decimal">
<li>The <code>data</code> folder contains all input data (and metadata) used in the analysis.</li>
<li>The <code>docs</code> folder contains the manuscript.</li>
<li>The <code>figs</code> directory contains figures generated by the analysis.</li>
<li>The <code>output_data</code> folder contains any type of intermediate or output files (e.g. simulation outputs, models, processed datasets, etc.). You might separate this and also have a cleaned-data folder.</li>
<li>The <code>scripts</code> contains R scripts with function definitions.</li>
<li>The <code>rmd</code> folder contains RMarkdown and reports files that document the analysis or report on results.</li>
</ol>
</div>
<div id="good-name-principle" class="section level1">
<h1><strong style="color: darkred;">good name principle</strong></h1>
<ol style="list-style-type: decimal">
<li>machine readable</li>
</ol>
<ul>
<li>Use delimiters to separate and make important metadata information</li>
<li>Avoid spaces, punctuation, accented characters and case sensitivity.</li>
<li>“_” to separate metadata to be extracted as strings later on</li>
<li>“-” instead of spaces or vice versa but do not mix</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>human readable</li>
</ol>
<ul>
<li>Ensure file names also include informative description of file contents</li>
<li>Adapt the concept of the slug to <strong>link outputs</strong> with <strong>the scripts in which they are generated</strong></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>easy to order by default</li>
<li><strong>Starting file names with a number</strong> helps.</li>
<li>For data, this might be a date allowing chronological ordering.</li>
<li>Make sure to use ISO 8601 format <strong>(YYYY-MM-DD)</strong> to avoid confusion between differing local dating conventions.</li>
<li>For scripts, you could use <strong>a number indicating the position of the scripts</strong> <strong>in the analysis sequence</strong> e.g. 01_download-data.R</li>
</ol>
<p><img src="https://media.giphy.com/media/QLuMqcnfCVTDIcOwG8/giphy.gif" width="30%" style="display: block; margin: auto;" /></p>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[algorithms: selection sort]]></title>
    <link href="/2018/04/algorithms-selection-sort/"/>
    <id>/2018/04/algorithms-selection-sort/</id>
    <published>2018-04-17T00:00:00+00:00</published>
    <updated>2018-04-17T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div class="section level2">
<h2>选择排序</h2>
<ul>
<li>计算机内存就像一大堆的抽屉， 每个抽屉都有地址</li>
<li>存储多个元素可以使用：数组和链表</li>
<li>数组的元素都在一起</li>
<li>链表的元素是分开的，每个元素都存着下一个元素的地址</li>
<li>数组的读取速度很快</li>
<li>链表的插入和删除速度很快</li>
<li>在同一个数组中，所有的元素类型必须一致 <img src="/Users/zero/Documents/_14_tmp/jixingBlogdown/public/post/2018-04-17-algorithms-selection-sort_files/%E5%86%85%E5%AD%98.png" width="30%" style="display: block; margin: auto;" /></li>
</ul>
<p><img src="/Users/zero/Documents/_14_tmp/jixingBlogdown/public/post/2018-04-17-algorithms-selection-sort_files/Screen%20Shot%202018-04-17%20at%2007.29.00.png" width="30%" style="display: block; margin: auto;" /></p>
<pre class="python"><code>def findSmallest(arr):
    smallest = arr[0] #初始化：存储最小的值
    smallest_index=0 #初始化: 存储最小值的索引
    for i in range(1, len(arr)):
        if arr[i] &lt; smallest:
            smallest=arr[i]
            smallest_index=i
    return smallest_index
def selectionSort(arr): #对数据进行排序
    newArr=[]
    for i in range(len(arr)):
        smallest=findSmallest(arr)#找出数据中最小的元素，并将其加到新的数组中去
        newArr.append(arr.pop(smallest))
    return newArr
print(selectionSort([5,3,6,2]))</code></pre>
<pre><code>## [2, 3, 5, 6]</code></pre>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Hierarchical Clustering]]></title>
    <link href="/2018/04/hierarchical-clustering/"/>
    <id>/2018/04/hierarchical-clustering/</id>
    <published>2018-04-16T00:00:00+00:00</published>
    <updated>2018-04-16T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div id="what-is-clustering" class="section level1">
<h1>What Is Clustering</h1>
<blockquote>
<p><strong>Clustering</strong> refers to a very broad set of techniques for finding subgroups, or clusters, in a data set. When we cluster the observations of a data set, we seek to partition them into distinct groups so that the observations within each group are quite similar to each other, while observations in different groups are quite different from each other. Of course, to make this concrete, we must define what it means for two or more observations to be similar or different. Indeed, this is often a domain-specific consideration that must be made based on knowledge of the data being studied.</p>
</blockquote>
</div>
<div id="why-hierarachical-clustering" class="section level1">
<h1>Why Hierarachical Clustering</h1>
<blockquote>
<p>For instance, suppose that we have a set of n observations, each with p features. The n observations could correspond to tissue samples for patients with breast cancer, and the p features could correspond to measurements collected for each tissue sample; these could be clinical measurements, such as tumor stage or grade, or they could be gene expression measurements. We may have a reason to believe that there is some heterogeneity among the n tissue samples; for instance, perhaps there are a few different unknown subtypes of breast cancer. Clustering could be used to find these subgroups. This is an unsupervised problem because we are trying to discover structure in this case, distinct clusters on the basis of a data set. The goal in supervised problems, on the other hand, is to try to predict some outcome vector such as survival time or response to drug treatment</p>
</blockquote>
</div>
<div id="how-do-hierarachical-clustering-bottom-up" class="section level1">
<h1>How do hierarachical clustering: bottom-up</h1>
<div id="key-operation-repeatedly-combine-two-nearest-clusters" class="section level2">
<h2>Key operation: repeatedly combine two <strong>nearest clusters</strong></h2>
</div>
<div id="three-important-question" class="section level2">
<h2>three important question</h2>
<div id="how-do-you-represent-a-cluster-of-more-than-one-point" class="section level3">
<h3>1. how do you represent a cluster of more than one point?</h3>
<ul>
<li>how do you represent the location of each cluster, to tell which pair of cluster is closest?</li>
<li>represent each cluster by its centroid=average of its point</li>
</ul>
</div>
<div id="how-do-you-determine-the-nearness-of-clusters" class="section level3">
<h3>2. how do you determine the “nearness” of clusters?</h3>
<ul>
<li>measure cluster distances by distances of centroids</li>
</ul>
</div>
<div id="when-to-stop-combining-clusters" class="section level3">
<h3>3. when to stop combining clusters?</h3>
<ul>
<li>pick a number k upfront, and stop when have k clusters</li>
<li>stop when the next merge would creat a cluster with low “cohesion”</li>
</ul>
</div>
</div>
</div>
<div id="eg-stat-question" class="section level1">
<h1>Eg: stat question</h1>
</div>
<div id="resuilt" class="section level1">
<h1>resuilt</h1>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Row Combine Many Table In R ]]></title>
    <link href="/2018/04/row-combine-many-table-in-r/"/>
    <id>/2018/04/row-combine-many-table-in-r/</id>
    <published>2018-04-11T00:00:00+00:00</published>
    <updated>2018-04-11T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p><strong>Q: I has many separate tables that need to be combined into a single file?</strong></p>
<p>google search “R read many datasets or tables”</p>
<div id="three-steps" class="section level1">
<h1><strong>Three steps</strong>:</h1>
<ol style="list-style-type: decimal">
<li>Getting a list of files path to read</li>
<li>Write a function to read a file</li>
<li>Then loop it <br></li>
</ol>
<div id="step01-list-all-files-path" class="section level2">
<h2>step01: list all files path</h2>
<pre class="r"><code>library(here) 
allfiles = list.files(path = here(&quot;data&quot;), #Use the ⭐here package to indicate the directory the files are in relative to the root directory
                        pattern = &quot;AB.csv|ab.csv&quot;,#tell R which file paths should be listed
                        full.names = TRUE,
                        recursive = TRUE) #indicate whether or not child folders in the parent directory should be searched for files to list or not</code></pre>
</div>
<div id="step02-write-a-function-to-read-a-single-file" class="section level2">
<h2>step02: write a function to read a single file</h2>
<pre class="r"><code>library(stringr)

#eg_path: data/Block1/Siteone/SIT1_17_12_21_5.2_AB.csv
read_fun = function(path) {
     test = read.csv(path, 
                skip = 6,
                header = FALSE,
                col.names = c(&quot;date&quot;, &quot;temperature&quot;) )
     allnames = str_split( path, pattern = &quot;/&quot;, simplify = TRUE)
     test$block = allnames[, ncol(allnames) - 2] 
     test$site = allnames[, ncol(allnames) - 1] #The information on the physical units of the study, “Blocks” and “Sites”
     test$plot = str_extract(allnames[, ncol(allnames)], pattern = &quot;[0-9](?=\\.)&quot;)
     test$logloc = toupper( str_sub(allnames[, ncol(allnames)], start = -6, end = -5) )
     test
}</code></pre>
<p>step03: read all files</p>
<p>If using either of for or lapply, the final concatenation step can be done via rbind in do.call</p>
<p><code>map_dfr</code> looks like, looping through each element of allfiles to read and modify the datasets with the read_fun function and then stacking everything together into a final combined dataset</p>
<pre class="r"><code>library(furrr)
library(future)
plan(multiprocess)
library(tictoc)
tic()
( combined_dat = future_map_dfr(allfiles, read_fun, .progress = TRUE) )</code></pre>
<pre><code>##    date temperature  block    site plot logloc
## 1    15           9 Block1 Siteone    5     AB
## 2    16           8 Block1 Siteone    5     AB
## 3    17          15 Block1 Siteone    5     AB
## 4    18           9 Block1 Siteone    5     AB
## 5    19          10 Block1 Siteone    5     AB
## 6     1          12 Block1 Siteone    2     AB
## 7     2          15 Block1 Siteone    2     AB
## 8     3          21 Block1 Siteone    2     AB
## 9     4          20 Block1 Siteone    2     AB
## 10    5          20 Block1 Siteone    2     AB
## 11    6          13 Block1 Siteone    2     AB
## 12    1          10 Block1 Siteone    5     AB
## 13    2          19 Block1 Siteone    5     AB
## 14    3          17 Block1 Siteone    5     AB
## 15    4           6 Block1 Siteone    5     AB
## 16    5           5 Block1 Siteone    5     AB
## 17    6          10 Block1 Siteone    5     AB
## 18    7          15 Block1 Siteone    5     AB
## 19    8          16 Block1 Siteone    5     AB
## 20    9          10 Block1 Siteone    5     AB
## 21    1           9 Block2 Sitenew    3     AB
## 22    2           8 Block2 Sitenew    3     AB
## 23    3          15 Block2 Sitenew    3     AB
## 24    5          10 Block2 Sitenew    3     AB
## 25    6           9 Block2 Sitenew    3     AB
## 26    7          10 Block2 Sitenew    3     AB
## 27    8           8 Block2 Sitenew    3     AB
## 28    1          11 Block2 Sitenew    5     AB
## 29    2          12 Block2 Sitenew    5     AB
## 30    3          13 Block2 Sitenew    5     AB
## 31    4          18 Block2 Sitenew    5     AB
## 32    5          19 Block2 Sitenew    5     AB
## 33    6          18 Block2 Sitenew    5     AB
## 34    8          19 Block2 Sitenew    5     AB
## 35    7          18 Block2 Sitenew    5     AB
## 36    9          19 Block2 Sitenew    5     AB
## 37   10          10 Block2 Sitenew    5     AB</code></pre>
<pre class="r"><code>toc() </code></pre>
<pre><code>## 2.921 sec elapsed</code></pre>
</div>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Build Webapp In R Using Shiny]]></title>
    <link href="/2018/04/build-webapp-in-r-using-shiny/"/>
    <id>/2018/04/build-webapp-in-r-using-shiny/</id>
    <published>2018-04-09T00:00:00+00:00</published>
    <updated>2018-04-09T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p><strong>How to build shiny app from scratch in R</strong>?</p>
<p>You can build web page (online reporting tool) without knowing any web programming languages such as Javascript / PHP / CSS.</p>
<p>The best part about shiny package is that you can easily integrate R with webpage.</p>
<p>Suppose you want your web page run machine learning algorithms like random forest, SVM etc and display summary of the model with the flexibility of selecting inputs from user.</p>
<p>Shiny can do it?</p>
<div id="shinys-prominent-features" class="section level2">
<h2><strong>Shiny’s prominent features</strong></h2>
<ol style="list-style-type: decimal">
<li>Customizable widgets like sliders, drop down lists, numeric inputs and many more.</li>
<li><strong>Downloading</strong> datasets, graphs and tables in various formats.</li>
<li><strong>Uploading</strong> files.</li>
<li>Provides utility to <strong>create brilliant plots</strong>.</li>
<li>In-built functions for viewing data or printing the text or summaries.</li>
<li>Reactive programs which makes data handling easier.</li>
<li>Conditional Panels for only when a particular condition is present.</li>
<li>Works in any R environment (Console R, RGUI for Windows or Mac,  RStudio, etc)</li>
<li>No need to learn another software for online dashboarding</li>
<li><strong>Can style your app with CSS</strong> / HTML (Optional)</li>
</ol>
<p>Two must things in shiny 1. UI: user interface which is controlled by ui script 2. Sever: It contains the instructions that your computer needs when the user interacts with the app</p>
</div>
<div id="basic-layout-of-ui" class="section level2">
<h2><strong>Basic layout of UI</strong></h2>
<p><code>User Interface: </code>A simple shiny UI consists of a <strong>fluidpage </strong>which contains various panels. We can divide the display in two parts named <strong>sidebdarPanel( ) </strong> and <strong>mainPanel( ).</strong> Both of the panels can be accessed using <strong>sidebarLayout( ).</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Title panel </strong>is a place where the title of the app is displayed.</li>
<li><strong>Sidebar panel</strong> is where special instructions or widgets (drop down / slider/ checkbox) are displayed to the app user. The sidebar panel appears on the left side of your app by default. You can move it to the right side by changing the position argument in the sidebar layout.</li>
<li><strong>Main panel</strong> is the area where all the outputs are generally placed.</li>
</ol>
<p><img src="https://i.loli.net/2018/04/09/5acac07887856.jpg" width="30%" style="display: block; margin: auto;" /></p>
</div>
<div id="the-first-simple-shiny-app-with-basic-layout" class="section level2">
<h2><strong>The first simple shiny app with basic layout</strong></h2>
<pre class="r"><code>library(shiny)
ui = fluidPage(sidebarLayout(sidebarPanel(&quot;Welcome to Shiny App&quot;),
                             mainPanel(&quot;This is main Panel&quot;)))
server = function(input, output) {  }
shinyApp(ui, server)</code></pre>
</div>
<div id="guidelines-for-beginners-to-run-a-shiny-app" class="section level2">
<h2><strong>Guidelines for beginners to run a shiny app</strong></h2>
<p><strong>Step 1 : shinyApp(ui,server)</strong> <strong>: </strong>It is an in-built function in shiny package to run the app with ui and server as the arguments. Select the code and run it. Once you do it successfully, you would find the text **Listening on <a href="http://127.0.0.1:4692**" class="uri">http://127.0.0.1:4692**</a> on console.</p>
<p><strong>Step 2 : </strong>To create your app you need to save the code as an <strong>app.R</strong> file and a <strong>RunApp </strong>icon will get displayed on your screen. Click on it and a new prompt window as your app will appear.</p>
</div>
<div id="using-html-tags-in-shiny" class="section level2">
<h2><strong>Using HTML tags in Shiny</strong></h2>
<p>Content can be added in various panels. To change the <strong>appearance of the text by bolds, italics, images, changing the fonts and colors, adding heading</strong> etc. we can use various HTML functions in shiny. Some of them being the same in both of them are:</p>
<p><img src="https://i.loli.net/2018/04/09/5acac1e2659cd.jpg" width="30%" style="display: block; margin: auto;" /></p>
</div>
<div id="creating-a-hyperlink" class="section level2">
<h2><strong>Creating a hyperlink</strong></h2>
<p>A hyperlink can be created using <strong>a( ) </strong>where the first argument is the text with which the link is attached. <strong>href</strong> contains the link for our website which we want to attach.</p>
<div id="modifying-the-text-presentation-using-html-tags." class="section level3">
<h3><strong>Modifying the text presentation using HTML tags.</strong></h3>
<p>We create an app containing the list of the favorite novels . You can refer to the above mentioned table of HTML and shiny functions.</p>
<p><img src="https://i.loli.net/2018/04/09/5acac3fc6bb2b.jpg" width="30%" style="display: block; margin: auto;" /></p>
</div>
<div id="introducing-widgets" class="section level3">
<h3><strong>Introducing widgets</strong></h3>
<p>Various widgets are used in shiny to select various outputs. These widgets can be inserted in the ui function (anywhere in the main panel and sidebar panel).<br />
The most commonly used widgets are:</p>
<p><img src="https://i.loli.net/2018/04/09/5acac49acf925.jpg" width="30%" style="display: block; margin: auto;" /><img src="https://i.loli.net/2018/04/09/5acac4b608308.jpg" width="30%" style="display: block; margin: auto;" /></p>
<ul>
<li>‘Buttons’ can be created using an <strong>actionButton </strong>and <strong>submitButton </strong>widgets</li>
<li>Single check box, multiple check box and date inputs are created using <strong>checkboxInput</strong>, <strong>checkboxGroupInput </strong>and <strong>dateInput </strong>respectively.</li>
<li>Date range is created using <strong>dateRangeInput</strong>.</li>
</ul>
<p>More detail see: <a href="https://www.listendata.com/2018/02/shiny-tutorial-r.html">Most commonly used widgets</a></p>
</div>
<div id="sharing-the-app-with-others" class="section level3">
<h3><strong>Sharing the app with others</strong></h3>
<p><strong>Share your app as a web page:</strong> You need to create an account on<a href="http://shinyapps.io/"><strong>shinyapps.io</strong></a> and follow the instructions below to share your app.R file.</p>
</div>
<div id="deploying-shiny-app-on-shinyapps.io" class="section level3">
<h3><strong>Deploying shiny app on shinyapps.io</strong></h3>
<p>First you need to have an account on shinyapps.io.</p>
<p>Import library <strong>rsconnect </strong>by using</p>
<blockquote>
<p><code>library(rsconnect)</code> </p>
</blockquote>
<p>Then you need to configure the <strong>rsconnect </strong>package to your account using the code below -</p>
<blockquote>
<p><code>rsconnect::setAccountInfo(name=&quot;&lt;ACCOUNT&gt;&quot;, token=&quot;&lt;TOKEN&gt;&quot;, secret=&quot;&lt;SECRET&gt;&quot;)</code></p>
</blockquote>
<p>To deploy the app you can write: </p>
<blockquote>
<p><code>rsconnect::deployApp(' Folder path in which your app.R file is saved') </code></p>
</blockquote>
<p> As a result a new web page of your app link will be opened. </p>
</div>
</div>
<div id="links" class="section level2">
<h2><strong>Links</strong></h2>
<ul>
<li><a href="https://www.listendata.com/2018/02/shiny-tutorial-r.html">shiny</a></li>
</ul>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Run Python From R]]></title>
    <link href="/2018/04/run-python-from-r/"/>
    <id>/2018/04/run-python-from-r/</id>
    <published>2018-04-03T00:00:00+00:00</published>
    <updated>2018-04-03T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p><strong>R</strong> is mainly known for data analysis, statistical modeling and visualization. While <strong>python</strong> is popular for deep learning and natural language processing.</p>
<p>Python and R were ranked top 2 tools for data science and machine learning. If you really want to boost your career in data science world, these are the languages you need to focus on.</p>
<div id="how-to-call-or-run-python-from-r" class="section level1">
<h1><strong>How To Call Or Run Python From R?</strong></h1>
<p>RStudio developed a package called <strong>reticulate</strong> which provides a medium to run Python packages and functions from R.</p>
<pre class="r"><code># Load reticulate package
if (!require(&quot;reticulate&quot;)) install.packages(&quot;reticulate&quot;)</code></pre>
<pre><code>## Loading required package: reticulate</code></pre>
</div>
<div id="python-version-configuration" class="section level1">
<h1><a href="https://rstudio.github.io/reticulate/articles/versions.html">Python Version Configuration</a></h1>
<p>If the version of Python you want to use is located on the system PATH then it will be automatically discovered (via Sys.which) and used.</p>
<p>Alternatively, you can use one of the following functions to specify alternate versions of Python:</p>
<p>Function Description</p>
<ul>
<li><p><a href="https://rstudio.github.io/reticulate/reference/use_python.html">use_python</a> Specify the path a specific Python binary.</p></li>
<li><p><a href="https://rstudio.github.io/reticulate/reference/use_python.html">use_virtualenv</a> Specify the directory containing a Python virtualenv.</p></li>
<li><p><a href="https://rstudio.github.io/reticulate/reference/use_python.html">use_condaenv</a> Specify the name of a Conda environment.</p></li>
</ul>
</div>
<div id="import-a-python-module-within-r" class="section level1">
<h1>🔥 import a python module within R</h1>
<pre class="r"><code>os &lt;- import(&quot;os&quot;)
pd &lt;- import(&quot;pandas&quot;)
numpy &lt;- import(&quot;numpy&quot;)
py_module_available(&quot;pandas&quot;)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>os$getcwd()</code></pre>
<pre><code>## [1] &quot;/Users/zero/myrepo/jixingBlogdown/content/post&quot;</code></pre>
<p><strong style="color: darkred;">Install Python package with conda in terminal</strong></p>
<div id="working-with-numpy" class="section level2">
<h2>working with <strong>numpy</strong></h2>
<pre class="r"><code>y &lt;- array(1:4, c(2, 2)) # create a matrix with R
x &lt;- numpy$array(y) # edit it with python
numpy$transpose(y) # transpose the above array</code></pre>
<pre><code>##      [,1] [,2]
## [1,]    1    2
## [2,]    3    4</code></pre>
<pre class="r"><code>numpy$linalg$eig(y) # Eigenvalues and eigen vectors</code></pre>
<pre><code>## [[1]]
## [1] -0.3722813  5.3722813
## 
## [[2]]
##            [,1]       [,2]
## [1,] -0.9093767 -0.5657675
## [2,]  0.4159736 -0.8245648</code></pre>
<pre class="r"><code>numpy$sqrt(x)</code></pre>
<pre><code>##          [,1]     [,2]
## [1,] 1.000000 1.732051
## [2,] 1.414214 2.000000</code></pre>
<pre class="r"><code>numpy$exp(x)</code></pre>
<pre><code>##          [,1]     [,2]
## [1,] 2.718282 20.08554
## [2,] 7.389056 54.59815</code></pre>
</div>
</div>
<div id="sourcing-python-scripts" class="section level1">
<h1>🔥 <strong style="color: darkred;">Sourcing Python scripts</strong></h1>
<div id="call-the-python-fuction-in-r" class="section level2">
<h2><a href="%5B*Access%20objects%20created%20in%20python%20from%20R***:%5D(%5B*Access%20objects%20created%20in%20python%20from%20R**%5D(https://rviews.rstudio.com/2018/04/17/reticulated-shiny/))"><strong>Call the python fuction in R:</strong></a></h2>
<p>You can source any Python script just as you would source an R script using the source_python() function, then call the fuction in R.</p>
<pre class="r"><code>#use Python functions
source_python(&quot;../../scripts/add.py&quot;)# minus in action
add(1,1)</code></pre>
<pre><code>## [1] 0</code></pre>
</div>
<div id="access-objects-created-in-python-from-r" class="section level2">
<h2><a href="%5B*Access%20objects%20created%20in%20python%20from%20R**%5D(https://rviews.rstudio.com/2018/04/17/reticulated-shiny/)"><em>Access objects created in python from R</em>:</a></h2>
<p>If your Python file doesn’t contain functions, but also creates objects, use <strong style="color: darkred;">py_run_file</strong> instead of <strong style="color: darkred;">source_python</strong></p>
</div>
</div>
<div id="access-objects-created-in-python-from-r-1" class="section level1">
<h1>⭐<strong>Access objects created in python from R</strong></h1>
<p>with <strong style="color: darkred;">repl_python()</strong> <strong>note: Don’t work with Rmd</strong></p>
<pre class="r"><code>repl_python()
#===== python console====

# Load Pandas package
import pandas as pd

# Importing Dataset
travel = pd.read_excel(&quot;data/AIR.xlsx&quot;)

# Number of rows and columns
travel.shape

# Select random no. of rows 
travel.sample(n = 10)

# Group By
travel.groupby(&quot;Year&quot;).AIR.mean()

# Filter
t = travel.loc[(travel.Month &gt;= 6) &amp; (travel.Year &gt;= 1955),:]

# Return to R
exit

#==== R console====
# Access objects created in python from R
summary(py$t)

# Line chart using ggplot2
library(ggplot2)
ggplot(py$t, aes(AIR, Year)) + geom_line()</code></pre>
</div>
<div id="access-objects-created-in-r-from-python" class="section level1">
<h1>⭐<strong>Access objects created in R from Python</strong></h1>
<pre class="r"><code># Let&#39;s create a object in R
#===== R console====
mydata = head(cars, n=15)

#Use the R created object within Python REPL
repl_python()
#===== python console====
import pandas as pd
#Access objects created in R from Python: r.mydata
r.mydata.describe()
pd.isnull(r.mydata.speed)

exit</code></pre>
</div>
<div id="building-logistic-regression-model-using-sklearn-package" class="section level1">
<h1>⭐Building Logistic Regression Model using sklearn package</h1>
<pre class="r"><code>repl_python()

# Load libraries
from sklearn import datasets
from sklearn.linear_model import LogisticRegression

# load the iris datasets
iris = datasets.load_iris()

# Developing logit model
model = LogisticRegression()
model.fit(iris.data, iris.target)

# Scoring
actual = iris.target
predicted = model.predict(iris.data)

# Performance Metrics
print(metrics.classification_report(actual, predicted))
print(metrics.confusion_matrix(actual, predicted))</code></pre>
<div id="links" class="section level2">
<h2><strong>Links</strong></h2>
<ul>
<li><p><a href="https://www.diycode.cc/projects/rstudio/reticulate">R Interface to Python</a></p></li>
<li><p><a href="https://blog.rstudio.com/2018/03/26/reticulate-r-interface-to-python/">reticulate: R interface to Python</a></p></li>
<li><p><a href="https://rviews.rstudio.com/2018/04/17/reticulated-shiny/"><strong style="color: darkred;">Reticulated Shiny</strong></a></p></li>
</ul>
</div>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[9 Ensembling The Predictions]]></title>
    <link href="/2018/04/9-ensembling-the-predictions/"/>
    <id>/2018/04/9-ensembling-the-predictions/</id>
    <published>2018-04-01T00:00:00+00:00</published>
    <updated>2018-04-01T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div id="load-package-and-data" class="section level1">
<h1>Load Package And Data</h1>
<pre class="r"><code>load(&quot;../../data/craet_8.Rdata&quot;)
library(tidyverse)
library(caret)
#Set Parallel Processing - Decrease computation time
if (!require(&quot;doMC&quot;)) install.packages(&quot;doMC&quot;)
library(doMC)
registerDoMC(cores = 4)</code></pre>
</div>
<div id="train-multiple-models" class="section level1">
<h1>Train Multiple Models</h1>
<p>So now we have predictions from multiple individual models.To do this we had to run the train() function once for each model, store the models and pass it to the res</p>
<pre class="r"><code>library(caretEnsemble)

# Stacking Algorithms - Run multiple algos in one call.
trainControl &lt;- trainControl(method=&quot;repeatedcv&quot;, 
                             number=10, 
                             repeats=3,
                             savePredictions=TRUE, 
                             classProbs=TRUE)

algorithmList &lt;- c(&#39;rf&#39;, &#39;adaboost&#39;, &#39;earth&#39;, &#39;svmRadial&#39;)

set.seed(100)
models &lt;- caretList(Purchase ~ ., data=trainData, trControl=trainControl, methodList=algorithmList) 

results &lt;- resamples(models)
summary(results)</code></pre>
<pre><code>## 
## Call:
## summary.resamples(object = results)
## 
## Models: rf, adaboost, earth, svmRadial 
## Number of resamples: 30 
## 
## Accuracy 
##                Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## rf        0.7011494 0.7764706 0.7965116 0.8033148 0.8250684 0.9058824    0
## adaboost  0.6823529 0.7674419 0.7906977 0.7966532 0.8328659 0.8941176    0
## earth     0.7209302 0.7906977 0.8187415 0.8164175 0.8367305 0.8604651    0
## svmRadial 0.7558140 0.7948276 0.8304378 0.8261842 0.8588235 0.9058824    0
## 
## Kappa 
##                Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## rf        0.3518625 0.5184810 0.5504351 0.5737290 0.6253768 0.8040346    0
## adaboost  0.3349754 0.5046620 0.5686668 0.5711983 0.6423870 0.7831018    0
## earth     0.4102857 0.5609657 0.6148850 0.6095470 0.6580869 0.7147595    0
## svmRadial 0.4685109 0.5645744 0.6326120 0.6285652 0.6993397 0.7996464    0</code></pre>
<pre class="r"><code># Box plots to compare models
scales &lt;- list(x=list(relation=&quot;free&quot;), y=list(relation=&quot;free&quot;))
bwplot(results, scales=scales)</code></pre>
<p><img src="/post/2018-04-01-9-ensembling-the-predictions_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="combine-the-predictions-of-multiple-models-to-form-a-final-prediction" class="section level1">
<h1>Combine The Predictions Of Multiple Models To Form A Final Prediction</h1>
<ul>
<li>One thought: Is it possible to combine these predicted values from multiple models somehow and make a new ensemble that predicts better?</li>
<li>another thought: using the caretStack(). <strong>You just need to make sure you don’t use the same trainControl you used to build the models</strong></li>
</ul>
<pre class="r"><code># Create the trainControl
set.seed(101)
stackControl &lt;- trainControl(method=&quot;repeatedcv&quot;, 
                             number=10, 
                             repeats=3,
                             savePredictions=TRUE, 
                             classProbs=TRUE)

# Ensemble the predictions of `models` to form a new combined prediction based on glm
# 在原有模型的基础上叠加 一般线性模型 作为预测
stack.glm &lt;- caretStack(models, method=&quot;glm&quot;, metric=&quot;Accuracy&quot;, trControl=stackControl)
print(stack.glm)</code></pre>
<pre><code>## A glm ensemble of 2 base models: rf, adaboost, earth, svmRadial
## 
## Ensemble results:
## Generalized Linear Model 
## 
## 2571 samples
##    4 predictor
##    2 classes: &#39;CH&#39;, &#39;MM&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 2314, 2314, 2314, 2314, 2313, 2313, ... 
## Resampling results:
## 
##   Accuracy   Kappa    
##   0.8321128  0.6419638</code></pre>
<pre class="r"><code># Predict on testData
stack_predicteds &lt;- predict(stack.glm, newdata=testData4)
head(stack_predicteds)</code></pre>
<pre><code>## [1] CH CH CH CH CH MM
## Levels: CH MM</code></pre>
<pre class="r"><code>save.image(&quot;../../data/craet_9.Rdata&quot;)</code></pre>
<p><strong>A point to consider: The ensembles tend to perform better if the predictions are less correlated with each other.</strong></p>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[8 How To Evaluate Performance Of Multiple Machine Learning Algorithms?]]></title>
    <link href="/2018/03/8-how-to-evaluate-performance-of-multiple-machine-learning-algorithms/"/>
    <id>/2018/03/8-how-to-evaluate-performance-of-multiple-machine-learning-algorithms/</id>
    <published>2018-03-31T00:00:00+00:00</published>
    <updated>2018-03-31T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div id="load-package-and-data" class="section level1">
<h1>Load Package And Data</h1>
<pre class="r"><code>load(&quot;../../data/craet_7.Rdata&quot;)
library(tidyverse)
library(caret)
#Set Parallel Processing - Decrease computation time
if (!require(&quot;doMC&quot;)) install.packages(&quot;doMC&quot;)
library(doMC)
registerDoMC(cores = 4)</code></pre>
</div>
<div id="caret-provides-the-resamples-function-where-you-can-provide-multiple-machine-learning-models-and-collectively-evaluate-them" class="section level1">
<h1>Caret provides the resamples() function where you can provide multiple machine learning models and collectively evaluate them</h1>
<div id="define-the-training-control" class="section level2">
<h2>Define the training control</h2>
<pre class="r"><code>fitControl &lt;- trainControl(
    method = &#39;cv&#39;,                   # k-fold cross validation
    number = 5,                      # number of folds
    savePredictions = &#39;final&#39;,       # saves predictions for optimal tuning parameter
    classProbs = T,                  # should class probabilities be returned
    summaryFunction=twoClassSummary  # results summary function
) </code></pre>
</div>
<div id="train-models" class="section level2">
<h2>train models</h2>
<pre class="r"><code>set.seed(100)

# Training Adaboost using adaboost
model_adaboost = train(Purchase ~ ., data=trainData, method=&#39;adaboost&#39;, tuneLength=2, trControl = fitControl)

# Training Random Forest model using rf
model_rf = train(Purchase ~ ., data=trainData, method=&#39;rf&#39;, tuneLength=5, trControl = fitControl)

# Training xgBoost Dart
#model_xgbDART = train(Purchase ~ ., data=trainData, method=&#39;xgbDART&#39;, tuneLength=5, trControl = fitControl, verbose=F)

# Train SVM using MARS
model_svmRadial = train(Purchase ~ ., data=trainData, method=&#39;svmRadial&#39;, tuneLength=15, trControl = fitControl)</code></pre>
</div>
</div>
<div id="run-resamples-to-compare-the-models" class="section level1">
<h1>Run resamples() to compare the models</h1>
<pre class="r"><code># Compare model performances using resample()
models_compare &lt;- resamples(list(ADABOOST=model_adaboost, RF=model_rf, MARS=model_mars3, SVM=model_svmRadial))

# Summary of the models performances
summary(models_compare)</code></pre>
<pre><code>## 
## Call:
## summary.resamples(object = models_compare)
## 
## Models: ADABOOST, RF, MARS, SVM 
## Number of resamples: 5 
## 
## ROC 
##               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## ADABOOST 0.8126510 0.8462687 0.8682549 0.8657598 0.8868515 0.9147727    0
## RF       0.8635394 0.8647908 0.8748565 0.8841388 0.9046198 0.9128875    0
## MARS     0.8520967 0.8660981 0.9091561 0.8953757 0.9118590 0.9376688    0
## SVM      0.8769723 0.8839375 0.8902597 0.8895479 0.8948048 0.9017652    0
## 
## Sens 
##               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## ADABOOST 0.7619048 0.7904762 0.7904762 0.8070330 0.8076923 0.8846154    0
## RF       0.7809524 0.8000000 0.8461538 0.8451832 0.8750000 0.9238095    0
## MARS     0.8190476 0.8476190 0.8857143 0.8739377 0.8942308 0.9230769    0
## SVM      0.8750000 0.8761905 0.8761905 0.8891209 0.9047619 0.9134615    0
## 
## Spec 
##               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## ADABOOST 0.7014925 0.7462687 0.7727273 0.7635007 0.7761194 0.8208955    0
## RF       0.6119403 0.6363636 0.7462687 0.7332429 0.8208955 0.8507463    0
## MARS     0.6567164 0.7164179 0.7313433 0.7454998 0.7424242 0.8805970    0
## SVM      0.6969697 0.7164179 0.7313433 0.7364089 0.7611940 0.7761194    0</code></pre>
<pre class="r"><code># Draw box plots to compare models
scales &lt;- list(x=list(relation=&quot;free&quot;), y=list(relation=&quot;free&quot;))
bwplot(models_compare, scales=scales)</code></pre>
<p><img src="/post/2018-03-31-8-how-to-evaluate-performance-of-multiple-machine-learning-algorithms_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>save.image(&quot;../../data/craet_8.Rdata&quot;)</code></pre>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[7 How To Do Hyperparameter Tuning ]]></title>
    <link href="/2018/03/7-how-to-do-hyperparameter-tuning/"/>
    <id>/2018/03/7-how-to-do-hyperparameter-tuning/</id>
    <published>2018-03-30T00:00:00+00:00</published>
    <updated>2018-03-30T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div id="load-package-and-data" class="section level1">
<h1>Load Package And Data</h1>
<pre class="r"><code>load(&quot;../../data/craet_6.Rdata&quot;)
library(tidyverse)
library(caret)
# Set Parallel Processing - Decrease computation time
if (!require(&quot;doMC&quot;)) install.packages(&quot;doMC&quot;)
library(doMC)
registerDoMC(cores = 4)</code></pre>
<div id="hyper-parameter-tuning-using-tunegrid" class="section level2">
<h2>Hyper parameter tuning using tuneGrid</h2>
<ol style="list-style-type: decimal">
<li><p>Model Tuning Parameter Set</p></li>
<li><p>Cross Validation Set</p>
<strong>Cross validation <code>method</code> can be one amongst</strong>:
<ul>
<li>‘boot’: Bootstrap sampling</li>
<li>‘boot632’: Bootstrap sampling with 63.2% bias correction applied</li>
<li>‘optimism_boot’: The optimism bootstrap estimator</li>
<li>‘boot_all’: All boot methods.</li>
<li>‘cv’: k-Fold cross validation</li>
<li>‘repeatedcv’: Repeated k-Fold cross validation</li>
<li>‘oob’: Out of Bag cross validation</li>
<li>‘LOOCV’: Leave one out cross validation</li>
<li>‘LGOCV’: Leave group out cross validation</li>
</ul></li>
<li><p>Training And Tuning</p></li>
<li><p>Predict</p></li>
<li><p>Confusion Matrix</p></li>
</ol>
<pre class="r"><code># Step 1: Define the tuneGrid
marsGrid &lt;-  expand.grid(nprune = c(2, 4, 6, 8, 10), 
                        degree = c(1, 2, 3))

# Step 2: Define the training control
fitControl &lt;- trainControl(
    method = &#39;cv&#39;,                   # k-fold cross validation
    number = 5,                      # number of folds
    savePredictions = &#39;final&#39;,       # saves predictions for optimal tuning parameter
    classProbs = T,                  # should class probabilities be returned
    summaryFunction=twoClassSummary  # results summary function
) 

# Step 3: Training and Tuning hyper parameters by setting tuneGrid
set.seed(100)
model_mars3 = train(Purchase ~ ., data=trainData, method=&#39;earth&#39;, metric=&#39;ROC&#39;, tuneGrid = marsGrid, trControl = fitControl)
model_mars3</code></pre>
<pre><code>## Multivariate Adaptive Regression Spline 
## 
## 857 samples
##  18 predictor
##   2 classes: &#39;CH&#39;, &#39;MM&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 685, 685, 687, 686, 685 
## Resampling results across tuning parameters:
## 
##   degree  nprune  ROC        Sens       Spec     
##   1        2      0.8745398  0.8700916  0.7006784
##   1        4      0.8924657  0.8662454  0.7394844
##   1        6      0.8912361  0.8719414  0.7334238
##   1        8      0.8886974  0.8661722  0.7334238
##   1       10      0.8879988  0.8623626  0.7423790
##   2        2      0.8745398  0.8700916  0.7006784
##   2        4      0.8953757  0.8739377  0.7454998
##   2        6      0.8917824  0.8681868  0.7515152
##   2        8      0.8904559  0.8624359  0.7574401
##   2       10      0.8932377  0.8547436  0.7784261
##   3        2      0.8582783  0.8777106  0.6618725
##   3        4      0.8914544  0.8662454  0.7544550
##   3        6      0.8910605  0.8586264  0.7665310
##   3        8      0.8838647  0.8452015  0.7456355
##   3       10      0.8827056  0.8471062  0.7426504
## 
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were nprune = 4 and degree = 2.</code></pre>
<pre class="r"><code># Step 4: Predict on testData 
predicted3 &lt;- predict(model_mars3, testData4)

# Step 5: Compute the confusion matrix
confusionMatrix(reference = testData$Purchase, data = predicted3, mode=&#39;everything&#39;, positive=&#39;MM&#39;)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  CH  MM
##         CH 117  21
##         MM  13  62
##                                           
##                Accuracy : 0.8404          
##                  95% CI : (0.7841, 0.8869)
##     No Information Rate : 0.6103          
##     P-Value [Acc &gt; NIR] : 2.164e-13       
##                                           
##                   Kappa : 0.6585          
##  Mcnemar&#39;s Test P-Value : 0.2299          
##                                           
##             Sensitivity : 0.7470          
##             Specificity : 0.9000          
##          Pos Pred Value : 0.8267          
##          Neg Pred Value : 0.8478          
##               Precision : 0.8267          
##                  Recall : 0.7470          
##                      F1 : 0.7848          
##              Prevalence : 0.3897          
##          Detection Rate : 0.2911          
##    Detection Prevalence : 0.3521          
##       Balanced Accuracy : 0.8235          
##                                           
##        &#39;Positive&#39; Class : MM              
## </code></pre>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.4.3 (2017-11-30)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Sierra 10.12.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] parallel  methods   stats     graphics  grDevices utils     datasets 
## [8] base     
## 
## other attached packages:
##  [1] earth_4.6.1        plotmo_3.3.5       TeachingDemos_2.10
##  [4] plotrix_3.7        doMC_1.3.5         iterators_1.0.9   
##  [7] foreach_1.4.4      caret_6.0-78       lattice_0.20-35   
## [10] forcats_0.3.0      stringr_1.3.0      dplyr_0.7.4       
## [13] purrr_0.2.4        readr_1.1.1        tidyr_0.8.0       
## [16] tibble_1.4.2       ggplot2_2.2.1      tidyverse_1.2.1   
## 
## loaded via a namespace (and not attached):
##  [1] nlme_3.1-131.1     lubridate_1.7.3    dimRed_0.1.0      
##  [4] httr_1.3.1         rprojroot_1.3-2    tools_3.4.3       
##  [7] backports_1.1.2    R6_2.2.2           rpart_4.1-13      
## [10] lazyeval_0.2.1     colorspace_1.3-2   nnet_7.3-12       
## [13] withr_2.1.1.9000   tidyselect_0.2.4   mnormt_1.5-5      
## [16] compiler_3.4.3     cli_1.0.0          rvest_0.3.2       
## [19] xml2_1.2.0         bookdown_0.7       scales_0.5.0.9000 
## [22] sfsmisc_1.1-2      DEoptimR_1.0-8     psych_1.7.8       
## [25] robustbase_0.92-8  digest_0.6.15      foreign_0.8-69    
## [28] rmarkdown_1.9      pkgconfig_2.0.1    htmltools_0.3.6   
## [31] rlang_0.2.0.9000   readxl_1.0.0       ddalpha_1.3.1.1   
## [34] bindr_0.1.1        jsonlite_1.5       ModelMetrics_1.1.0
## [37] magrittr_1.5       Matrix_1.2-12      Rcpp_0.12.16      
## [40] munsell_0.4.3      stringi_1.1.7      yaml_2.1.18       
## [43] MASS_7.3-49        plyr_1.8.4         recipes_0.1.2     
## [46] grid_3.4.3         crayon_1.3.4       haven_1.1.1       
## [49] splines_3.4.3      hms_0.4.2          knitr_1.20        
## [52] pillar_1.2.1       reshape2_1.4.3     codetools_0.2-15  
## [55] stats4_3.4.3       CVST_0.2-1         glue_1.2.0        
## [58] evaluate_0.10.1    blogdown_0.5       modelr_0.1.1      
## [61] cellranger_1.1.0   gtable_0.2.0       kernlab_0.9-25    
## [64] assertthat_0.2.0   DRR_0.0.3          xfun_0.1          
## [67] gower_0.1.2        prodlim_1.6.1      broom_0.4.3       
## [70] e1071_1.6-8        class_7.3-14       survival_2.41-3   
## [73] timeDate_3043.102  RcppRoll_0.2.2     bindrcpp_0.2      
## [76] lava_1.6           ipred_0.9-6</code></pre>
<pre class="r"><code>save.image(file = &quot;../../data/craet_7.Rdata&quot;)</code></pre>
</div>
<div id="links" class="section level2">
<h2><strong>Links</strong></h2>
<ul>
<li><a href="https://www.machinelearningplus.com/caret-package/#7howtodohyperparametertuningtooptimizethemodelforbetterperformance?">How to do hyperparameter tuning to optimize the model for better performance?</a></li>
</ul>
</div>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[6 Training and Tuning the model]]></title>
    <link href="/2018/03/6-training-and-tuning-the-model/"/>
    <id>/2018/03/6-training-and-tuning-the-model/</id>
    <published>2018-03-29T00:00:00+00:00</published>
    <updated>2018-03-29T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div id="load-package-and-data" class="section level1">
<h1>Load Package And Data</h1>
</div>
<div id="training" class="section level1">
<h1>Training</h1>
<div id="how-to-train-the-model-and-interpret-the-results" class="section level2">
<h2>1. How to train the model and interpret the results?</h2>
<p>Once you have chosen an algorithm, building the model is fairly easy using the train() function</p>
<p><code>train()</code> does multiple other things like:</p>
<ol style="list-style-type: decimal">
<li><em>Cross validating the model</em></li>
<li><em>Tune the hyper parameters for optimal model performance</em></li>
<li><em>Choose the optimal model based on a given evaluation metric</em></li>
<li><em>Preprocess the predictors (what we did so far using preProcess())</em></li>
</ol>
</div>
<div id="how-to-compute-variable-importance" class="section level2">
<h2>2. How to compute variable importance?</h2>
<p>Which variables came out to be useful?</p>
</div>
</div>
<div id="tuning" class="section level1">
<h1>Tuning</h1>
<div id="preprocess-the-test-dataset-and-predict" class="section level2">
<h2>1. Preprocess the test dataset and predict</h2>
<p>The pre-processing in the following sequence:</p>
<p><strong>Missing Value imputation –&gt; One-Hot Encoding –&gt; Range Normalization</strong></p>
<p><strong>All the information required for pre-processing is stored in the respective preProcess model and dummyVar model.</strong></p>
<p>pass the testData through these models in the same sequence:</p>
<p><strong>preProcess_missingdata_model –&gt; dummies_model –&gt; preProcess_range_model</strong></p>
</div>
<div id="predict-on-testdata-and-confusion-matrix" class="section level2">
<h2>2. Predict on testData and Confusion Matrix</h2>
</div>
<div id="reference" class="section level2">
<h2><strong>Reference</strong></h2>
<p><a href="https://www.machinelearningplus.com/caret-package/">Traing and Tuning model</a></p>
</div>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[5 How to do feature selection using recursive feature elimination]]></title>
    <link href="/2018/03/5-how-to-do-feature-selection-using-recursive-feature-elimination/"/>
    <id>/2018/03/5-how-to-do-feature-selection-using-recursive-feature-elimination/</id>
    <published>2018-03-28T00:00:00+00:00</published>
    <updated>2018-03-28T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p>You might need <em>a rigorous way to determine the important variables</em> first before feeding them to the ML algorithm. This is important.</p>
<p>A good choice of selecting the important features is the <em>recursive feature elimination (RFE)</em></p>
<p>RFE works in 3 broad steps:</p>
<p>Step 1: Build a ML model on a training dataset and estimate the feature importances on the test dataset.（在确定自由度的情况下，评价变量在测试数据集中的重要性）</p>
<p>Step 2: Keeping priority to the most important variables, iterate through by building models of given sizes. Ranking of the predictors is recalculated in each iteration.（把刚才的过程在不同的自由度下迭代执行）</p>
<p>Step 3: The model performances are compared across different subset sizes to arrive at the optimal number and list of final predictors.（比较不同自由度的测试错误率，给出最佳自由度模型选择）</p>
<div id="load-package-and-data" class="section level1">
<h1>Load Package And Data</h1>
<pre class="r"><code># Load Package And Data
load(&quot;../../data/craet_4.Rdata&quot;)
library(tidyverse)
library(caret)
#Set Parallel Processing - Decrease computation time
if (!require(&quot;doMC&quot;)) install.packages(&quot;doMC&quot;)
library(doMC)
registerDoMC(cores = 4)</code></pre>
</div>
<div id="feature-select" class="section level1">
<h1>Feature select</h1>
<pre class="r"><code>set.seed(100)
options(warn=-1)

subsets &lt;- c(1:5, 10, 15, 18)

#Step 1: Build a ML model on a training dataset and estimate the feature importances on the test dataset.（在确定自由度的情况下，评价变量在测试数据集中的重要性）
ctrl &lt;- rfeControl(functions = rfFuncs,
                   method = &quot;repeatedcv&quot;,#repeated K-fold cross-validation
                   number = 10,#10-fold cross-validations
                   repeats = 5, #five separate 10-fold cross-validations are used
                   verbose = FALSE)
#Step 2: Keeping priority to the most important variables, iterate through by building models of given sizes. Ranking of the predictors is recalculated in each iteration.（把刚才的过程在不同的自由度下迭代执行
lmProfile &lt;- rfe(x=trainData[, 1:18], y=trainData$Purchase,
                 sizes = subsets,
                 rfeControl = ctrl)

#Step 3: The model performances are compared across different subset sizes to arrive at the optimal number and list of final predictors.（比较不同自由度的测试错误率，给出最佳自由度模型选择
lmProfile</code></pre>
<pre><code>## 
## Recursive feature selection
## 
## Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 
## 
## Resampling performance over subset size:
## 
##  Variables Accuracy  Kappa AccuracySD KappaSD Selected
##          1   0.7442 0.4569    0.04125 0.08753         
##          2   0.8124 0.6031    0.04002 0.08505         
##          3   0.8182 0.6136    0.04170 0.08790        *
##          4   0.8047 0.5879    0.04314 0.08993         
##          5   0.8000 0.5770    0.04215 0.08861         
##         10   0.8035 0.5826    0.04112 0.08815         
##         15   0.8089 0.5918    0.04209 0.09076         
##         18   0.8084 0.5918    0.04118 0.08894         
## 
## The top 3 variables (out of 3):
##    LoyalCH, PriceDiff, StoreID</code></pre>
<div id="input" class="section level2">
<h2>input</h2>
<ul>
<li><p>Size: sizes determines what all model sizes (the number of most important features) the rfe should consider</p></li>
<li>rfeControl():
<ul>
<li>functions: what type of algorithm should be used <strong>rfFuncs:: random forest based</strong>
<ul>
<li>methods: repeated K-fold cross-validation</li>
<li>number: 10-fold cross-validations</li>
<li>repeats: five separate 10-fold cross-validations are used</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="output" class="section level2">
<h2>output</h2>
<p>The Output Shows: - accuracy<br />
- kappa (and their standard deviation) for the different model sizes we provided - The final selected model subset size is marked with a * in the rightmost Selected column.</p>
<pre class="r"><code>save.image(&quot;../../data/craet_5.Rdata&quot;)
sessionInfo()</code></pre>
<pre><code>## R version 3.4.3 (2017-11-30)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Sierra 10.12.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] parallel  methods   stats     graphics  grDevices utils     datasets 
## [8] base     
## 
## other attached packages:
##  [1] doMC_1.3.5      iterators_1.0.9 foreach_1.4.4   caret_6.0-78   
##  [5] lattice_0.20-35 forcats_0.3.0   stringr_1.3.0   dplyr_0.7.4    
##  [9] purrr_0.2.4     readr_1.1.1     tidyr_0.8.0     tibble_1.4.2   
## [13] ggplot2_2.2.1   tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##  [1] httr_1.3.1          ddalpha_1.3.1.1     sfsmisc_1.1-2      
##  [4] jsonlite_1.5        splines_3.4.3       prodlim_1.6.1      
##  [7] modelr_0.1.1        assertthat_0.2.0    stats4_3.4.3       
## [10] DRR_0.0.3           cellranger_1.1.0    yaml_2.1.18        
## [13] robustbase_0.92-8   ipred_0.9-6         pillar_1.2.1       
## [16] backports_1.1.2     glue_1.2.0          digest_0.6.15      
## [19] randomForest_4.6-12 rvest_0.3.2         colorspace_1.3-2   
## [22] recipes_0.1.2       htmltools_0.3.6     Matrix_1.2-12      
## [25] plyr_1.8.4          psych_1.7.8         timeDate_3043.102  
## [28] pkgconfig_2.0.1     CVST_0.2-1          broom_0.4.3        
## [31] haven_1.1.1         bookdown_0.7        scales_0.5.0.9000  
## [34] gower_0.1.2         lava_1.6            withr_2.1.1.9000   
## [37] nnet_7.3-12         lazyeval_0.2.1      cli_1.0.0          
## [40] mnormt_1.5-5        survival_2.41-3     magrittr_1.5       
## [43] crayon_1.3.4        readxl_1.0.0        evaluate_0.10.1    
## [46] nlme_3.1-131.1      MASS_7.3-49         xml2_1.2.0         
## [49] dimRed_0.1.0        foreign_0.8-69      class_7.3-14       
## [52] blogdown_0.5        tools_3.4.3         hms_0.4.2          
## [55] kernlab_0.9-25      munsell_0.4.3       bindrcpp_0.2       
## [58] e1071_1.6-8         compiler_3.4.3      RcppRoll_0.2.2     
## [61] rlang_0.2.0.9000    grid_3.4.3          rmarkdown_1.9      
## [64] gtable_0.2.0        ModelMetrics_1.1.0  codetools_0.2-15   
## [67] reshape2_1.4.3      R6_2.2.2            lubridate_1.7.3    
## [70] knitr_1.20          bindr_0.1.1         rprojroot_1.3-2    
## [73] stringi_1.1.7       Rcpp_0.12.16        rpart_4.1-13       
## [76] tidyselect_0.2.4    DEoptimR_1.0-8      xfun_0.1</code></pre>
</div>
<div id="reference" class="section level2">
<h2><strong>Reference</strong></h2>
<ul>
<li><a href="https://www.machinelearningplus.com/caret-package/">How to do feature selection using recursive feature elimination (rfe)?</a></li>
</ul>
</div>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[4 How To Visualize The Importance Of Variables Using featurePlot]]></title>
    <link href="/2018/03/4-how-to-visualize-the-importance-of-variables-using-featureplot/"/>
    <id>/2018/03/4-how-to-visualize-the-importance-of-variables-using-featureplot/</id>
    <published>2018-03-27T00:00:00+00:00</published>
    <updated>2018-03-27T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div id="load-package-and-data" class="section level1">
<h1>Load Package And Data</h1>
<pre class="r"><code>load(&quot;../../data/craet_3-3.Rdata&quot;)
library(tidyverse)
library(caret)</code></pre>
</div>
<div id="q-how-the-predictors-influence-the-y" class="section level1">
<h1>Q: How The Predictors Influence The Y</h1>
<p>选择重要的变量: 通过观察在Y的分组下各个变量的分布情况</p>
<p>一般有 箱线图 和 密度图</p>
</div>
<div id="box-plot" class="section level1">
<h1>box-plot</h1>
<pre class="r"><code>featurePlot(x = trainData[, 1:18], 
            y = trainData$Purchase, 
            plot = &quot;box&quot;,#&quot;density&quot;
            strip=strip.custom(par.strip.text=list(cex=.7)),
            scales = list(x = list(relation=&quot;free&quot;), 
                          y = list(relation=&quot;free&quot;)))</code></pre>
<p><img src="/post/2018-03-27-4-how-to-visualize-the-importance-of-variables-using-featureplot_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="density" class="section level1">
<h1>Density</h1>
<pre class="r"><code>featurePlot(x = trainData[, 1:18], 
            y = trainData$Purchase, 
            plot = &quot;density&quot;,
            strip=strip.custom(par.strip.text=list(cex=.7)),
            scales = list(x = list(relation=&quot;free&quot;), 
                          y = list(relation=&quot;free&quot;)))</code></pre>
<p><img src="/post/2018-03-27-4-how-to-visualize-the-importance-of-variables-using-featureplot_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>save.image(&quot;../../data/craet_4.Rdata&quot;)</code></pre>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Scraping and Wranging Tables from Research Articles]]></title>
    <link href="/2018/03/scraping-and-wranging-tables-from-research-articles/"/>
    <id>/2018/03/scraping-and-wranging-tables-from-research-articles/</id>
    <published>2018-03-27T00:00:00+00:00</published>
    <updated>2018-03-27T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p>What do you do when you want to use results from the literature to anchor your own analysis? we’ll go through a practical scenario on scraping an html table from a Nature Genetics article into R and wrangling the data into a useful format.</p>
<div id="scraping-a-html-table-from-a-webpage" class="section level1">
<h1>01. Scraping a html table from a webpage</h1>
<pre class="r"><code>#load packages
library(&quot;rvest&quot;)
library(&quot;knitr&quot;)
library(tidyverse)
#scraping web page
url &lt;- &quot;https://www.nature.com/articles/ng.2802/tables/2&quot;

#====🔥find where is the table lives on this webpage====
table_path=&#39;//*[@id=&quot;content&quot;]/div/div/figure/div[1]/div/div[1]/table&#39;
#get the table
nature_genetics_table2 &lt;- url %&gt;%
  read_html() %&gt;%
  html_nodes(xpath=table_path) %&gt;%
  html_table(fill=T) %&gt;% .[[1]]
#the first few lines of table
kable(nature_genetics_table2[1:4,])</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">SNPa</th>
<th align="left">Chr.</th>
<th align="left">Positionb</th>
<th align="left">Closest genec</th>
<th align="left">Major/minor alleles</th>
<th align="left">MAFd</th>
<th align="left">Stage 1</th>
<th align="left">Stage 1</th>
<th align="left">Stage 2</th>
<th align="left">Stage 2</th>
<th align="left">Overall</th>
<th align="left">Overall</th>
<th align="left">Overall</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">SNPa</td>
<td align="left">Chr.</td>
<td align="left">Positionb</td>
<td align="left">Closest genec</td>
<td align="left">Major/minor alleles</td>
<td align="left">MAFd</td>
<td align="left">OR (95% CI)e</td>
<td align="left">Meta P value</td>
<td align="left">OR (95% CI)e</td>
<td align="left">Meta P value</td>
<td align="left">OR (95% CI)e</td>
<td align="left">Meta P value</td>
<td align="left">I2 (%), P valuef</td>
</tr>
<tr class="even">
<td align="left">Known GWAS-defined associated genes</td>
<td align="left">Known GWAS-defined associated genes</td>
<td align="left">Known GWAS-defined associated genes</td>
<td align="left">Known GWAS-defined associated genes</td>
<td align="left">Known GWAS-defined associated genes</td>
<td align="left">Known GWAS-defined associated genes</td>
<td align="left">Known GWAS-defined associated genes</td>
<td align="left">Known GWAS-defined associated genes</td>
<td align="left">Known GWAS-defined associated genes</td>
<td align="left">Known GWAS-defined associated genes</td>
<td align="left">Known GWAS-defined associated genes</td>
<td align="left">Known GWAS-defined associated genes</td>
<td align="left">Known GWAS-defined associated genes</td>
</tr>
<tr class="odd">
<td align="left">rs6656401</td>
<td align="left">1</td>
<td align="left">207692049</td>
<td align="left">CR1</td>
<td align="left">G/A</td>
<td align="left">0.197</td>
<td align="left">1.17 (1.12–1.22)</td>
<td align="left">7.7 × 10−15</td>
<td align="left">1.21 (1.14–1.28)</td>
<td align="left">7.9 × 10−11</td>
<td align="left">1.18 (1.14–1.22)</td>
<td align="left">5.7 × 10−24</td>
<td align="left">0, 7.8 × 10−1</td>
</tr>
<tr class="even">
<td align="left">rs6733839</td>
<td align="left">2</td>
<td align="left">127892810</td>
<td align="left">BIN1</td>
<td align="left">C/T</td>
<td align="left">0.409</td>
<td align="left">1.21 (1.17–1.25)</td>
<td align="left">1.7 × 10−26</td>
<td align="left">1.24 (1.18–1.29)</td>
<td align="left">3.4 × 10−19</td>
<td align="left">1.22 (1.18–1.25)</td>
<td align="left">6.9 × 10−44</td>
<td align="left">28, 6.1 × 10−2</td>
</tr>
</tbody>
</table>
</div>
<div id="making-messy-data-useful" class="section level1">
<h1>02 Making messy data useful</h1>
<div id="cleaning-up-the-rows" class="section level2">
<h2>Cleaning up the rows</h2>
<p>All The Elements Of These Rows Contain The Exact Same Text</p>
<pre class="r"><code>v=which(apply(nature_genetics_table2,1, function(x) length(unique(unlist(x))) )==1)
v</code></pre>
<pre><code>## [1]  2 12 18</code></pre>
</div>
<div id="split-table" class="section level2">
<h2>split table</h2>
<pre class="r"><code>nature_genetics_table2_list = split(nature_genetics_table2, cumsum(1:nrow(nature_genetics_table2) %in% v))
nature_genetics_table2_list = lapply(nature_genetics_table2_list[2:4], function(y) {
y$Description = unique(as.character(y[1, ]))
y[-1, ]
})

#rbind three table
nature_genetics_table2_clean = do.call(&quot;rbind&quot;, nature_genetics_table2_list)

kable(nature_genetics_table2_clean[1:3,])</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">SNPa</th>
<th align="left">Chr.</th>
<th align="left">Positionb</th>
<th align="left">Closest genec</th>
<th align="left">Major/minor alleles</th>
<th align="left">MAFd</th>
<th align="left">Stage 1</th>
<th align="left">Stage 1</th>
<th align="left">Stage 2</th>
<th align="left">Stage 2</th>
<th align="left">Overall</th>
<th align="left">Overall</th>
<th align="left">Overall</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1.3</td>
<td align="left">rs6656401</td>
<td align="left">1</td>
<td align="left">207692049</td>
<td align="left">CR1</td>
<td align="left">G/A</td>
<td align="left">0.197</td>
<td align="left">1.17 (1.12–1.22)</td>
<td align="left">7.7 × 10−15</td>
<td align="left">1.21 (1.14–1.28)</td>
<td align="left">7.9 × 10−11</td>
<td align="left">1.18 (1.14–1.22)</td>
<td align="left">5.7 × 10−24</td>
<td align="left">0, 7.8 × 10−1</td>
<td align="left">Known GWAS-defined associated genes</td>
</tr>
<tr class="even">
<td>1.4</td>
<td align="left">rs6733839</td>
<td align="left">2</td>
<td align="left">127892810</td>
<td align="left">BIN1</td>
<td align="left">C/T</td>
<td align="left">0.409</td>
<td align="left">1.21 (1.17–1.25)</td>
<td align="left">1.7 × 10−26</td>
<td align="left">1.24 (1.18–1.29)</td>
<td align="left">3.4 × 10−19</td>
<td align="left">1.22 (1.18–1.25)</td>
<td align="left">6.9 × 10−44</td>
<td align="left">28, 6.1 × 10−2</td>
<td align="left">Known GWAS-defined associated genes</td>
</tr>
<tr class="odd">
<td>1.5</td>
<td align="left">rs10948363</td>
<td align="left">6</td>
<td align="left">47487762</td>
<td align="left">CD2AP</td>
<td align="left">A/G</td>
<td align="left">0.266</td>
<td align="left">1.10 (1.07–1.14)</td>
<td align="left">3.1 × 10−8</td>
<td align="left">1.09 (1.04–1.15)</td>
<td align="left">4.1 × 10−4</td>
<td align="left">1.10 (1.07–1.13)</td>
<td align="left">5.2 × 10−11</td>
<td align="left">0, 9 × 10−1</td>
<td align="left">Known GWAS-defined associated genes</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="fixing-column-names" class="section level1">
<h1>03. Fixing column names</h1>
<pre class="r"><code>colnames(nature_genetics_table2_clean) &lt;- c(&quot;SNP&quot;, &quot;Chr&quot;, &quot;Position&quot;, &quot;Closest gene&quot;, &quot;Major/minor alleles&quot;, &quot;MAF&quot;, &quot;Stage1_OR&quot;, &quot;Stage1_MetaP&quot;, &quot;Stage2_OR&quot;,&quot;Stage2_MetaP&quot;,    &quot;Overall_OR&quot;, &quot;Overall_MetaP&quot;, &quot;I2_Percent/P&quot;,&quot;Description&quot;)
colnames(nature_genetics_table2_clean)</code></pre>
<pre><code>##  [1] &quot;SNP&quot;                 &quot;Chr&quot;                 &quot;Position&quot;           
##  [4] &quot;Closest gene&quot;        &quot;Major/minor alleles&quot; &quot;MAF&quot;                
##  [7] &quot;Stage1_OR&quot;           &quot;Stage1_MetaP&quot;        &quot;Stage2_OR&quot;          
## [10] &quot;Stage2_MetaP&quot;        &quot;Overall_OR&quot;          &quot;Overall_MetaP&quot;      
## [13] &quot;I2_Percent/P&quot;        &quot;Description&quot;</code></pre>
</div>
<div id="making-a-character-variable-into-a-numeric-variable" class="section level1">
<h1>04. Making a character variable into a numeric variable</h1>
<pre class="r"><code># &quot; × 10-&quot; -&gt; &quot;e-&quot;
nature_genetics_table2_clean$Stage1_MetaP &lt;- 
str_replace(nature_genetics_table2_clean$Stage1_MetaP,&quot; × 10−&quot;,&quot;e-&quot;) %&gt;% as.numeric()
kable(nature_genetics_table2_clean[1:3,])</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">SNP</th>
<th align="left">Chr</th>
<th align="left">Position</th>
<th align="left">Closest gene</th>
<th align="left">Major/minor alleles</th>
<th align="left">MAF</th>
<th align="left">Stage1_OR</th>
<th align="right">Stage1_MetaP</th>
<th align="left">Stage2_OR</th>
<th align="left">Stage2_MetaP</th>
<th align="left">Overall_OR</th>
<th align="left">Overall_MetaP</th>
<th align="left">I2_Percent/P</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1.3</td>
<td align="left">rs6656401</td>
<td align="left">1</td>
<td align="left">207692049</td>
<td align="left">CR1</td>
<td align="left">G/A</td>
<td align="left">0.197</td>
<td align="left">1.17 (1.12–1.22)</td>
<td align="right">0</td>
<td align="left">1.21 (1.14–1.28)</td>
<td align="left">7.9 × 10−11</td>
<td align="left">1.18 (1.14–1.22)</td>
<td align="left">5.7 × 10−24</td>
<td align="left">0, 7.8 × 10−1</td>
<td align="left">Known GWAS-defined associated genes</td>
</tr>
<tr class="even">
<td>1.4</td>
<td align="left">rs6733839</td>
<td align="left">2</td>
<td align="left">127892810</td>
<td align="left">BIN1</td>
<td align="left">C/T</td>
<td align="left">0.409</td>
<td align="left">1.21 (1.17–1.25)</td>
<td align="right">0</td>
<td align="left">1.24 (1.18–1.29)</td>
<td align="left">3.4 × 10−19</td>
<td align="left">1.22 (1.18–1.25)</td>
<td align="left">6.9 × 10−44</td>
<td align="left">28, 6.1 × 10−2</td>
<td align="left">Known GWAS-defined associated genes</td>
</tr>
<tr class="odd">
<td>1.5</td>
<td align="left">rs10948363</td>
<td align="left">6</td>
<td align="left">47487762</td>
<td align="left">CD2AP</td>
<td align="left">A/G</td>
<td align="left">0.266</td>
<td align="left">1.10 (1.07–1.14)</td>
<td align="right">0</td>
<td align="left">1.09 (1.04–1.15)</td>
<td align="left">4.1 × 10−4</td>
<td align="left">1.10 (1.07–1.13)</td>
<td align="left">5.2 × 10−11</td>
<td align="left">0, 9 × 10−1</td>
<td align="left">Known GWAS-defined associated genes</td>
</tr>
</tbody>
</table>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.4.3 (2017-11-30)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Sierra 10.12.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] methods   stats     graphics  grDevices utils     datasets  base     
## 
## other attached packages:
##  [1] forcats_0.3.0   stringr_1.3.0   dplyr_0.7.4     purrr_0.2.4    
##  [5] readr_1.1.1     tidyr_0.8.0     tibble_1.4.2    ggplot2_2.2.1  
##  [9] tidyverse_1.2.1 knitr_1.20      rvest_0.3.2     xml2_1.2.0     
## 
## loaded via a namespace (and not attached):
##  [1] xfun_0.1          reshape2_1.4.3    haven_1.1.1      
##  [4] lattice_0.20-35   colorspace_1.3-2  htmltools_0.3.6  
##  [7] yaml_2.1.18       rlang_0.2.0.9000  pillar_1.2.1     
## [10] foreign_0.8-69    glue_1.2.0        selectr_0.3-2    
## [13] modelr_0.1.1      readxl_1.0.0      bindrcpp_0.2     
## [16] bindr_0.1.1       plyr_1.8.4        munsell_0.4.3    
## [19] blogdown_0.5      gtable_0.2.0      cellranger_1.1.0 
## [22] psych_1.7.8       evaluate_0.10.1   parallel_3.4.3   
## [25] curl_3.1          highr_0.6         broom_0.4.3      
## [28] Rcpp_0.12.16      backports_1.1.2   scales_0.5.0.9000
## [31] jsonlite_1.5      mnormt_1.5-5      hms_0.4.2        
## [34] digest_0.6.15     stringi_1.1.7     bookdown_0.7     
## [37] grid_3.4.3        rprojroot_1.3-2   cli_1.0.0        
## [40] tools_3.4.3       magrittr_1.5      lazyeval_0.2.1   
## [43] crayon_1.3.4      pkgconfig_2.0.1   lubridate_1.7.3  
## [46] assertthat_0.2.0  rmarkdown_1.9     httr_1.3.1       
## [49] R6_2.2.2          nlme_3.1-131.1    compiler_3.4.3</code></pre>
</div>
<div id="reference" class="section level1">
<h1><strong>Reference</strong></h1>
<ul>
<li><a href="http://research.libd.org/rstatsclub/2018/03/19/introduction-to-scraping-and-wranging-tables-from-research-articles/">Introduction to Scraping and Wranging Tables from Research Articles</a></li>
</ul>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[3.3 How To Create Dummy Variables And Normalization]]></title>
    <link href="/2018/03/how-to-create-dummy-variables-and-normalization/"/>
    <id>/2018/03/how-to-create-dummy-variables-and-normalization/</id>
    <published>2018-03-26T00:00:00+00:00</published>
    <updated>2018-03-26T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div id="load-package-and-data" class="section level1">
<h1>Load Package And Data</h1>
<pre class="r"><code>load(&quot;../../data/craet_3-2.Rdata&quot;)
library(tidyverse)
library(caret)</code></pre>
</div>
<div id="why-dummy-variables" class="section level1">
<h1>Why Dummy Variables</h1>
<p>对于字符型的因子变量，我们需要把它转变为有序的数值，一般转为 0，1 的二变量， 这样0 就代表基础水平， 1代表比较组</p>
<p><img src="https://i.loli.net/2018/03/26/5ab847e351487.jpg" width="30%" style="display: block; margin: auto;" /></p>
</div>
<div id="how" class="section level1">
<h1>How</h1>
<pre class="r"><code># One-Hot Encoding
# Creating dummy variables is converting a categorical variable to as many binary variables as here are categories.
dummies_model &lt;- dummyVars(Purchase ~ ., data=trainData)

# Create the dummy variables using predict. The Y variable (Purchase) will not be present in trainData_mat.
trainData_mat &lt;- predict(dummies_model, newdata = trainData)

# # Convert to dataframe
trainData &lt;- data.frame(trainData_mat)

# # See the structure of the new dataset
str(trainData)</code></pre>
<pre><code>## &#39;data.frame&#39;:    857 obs. of  18 variables:
##  $ WeekofPurchase: num  -1.1 -1.74 -1.68 -1.29 -1.04 ...
##  $ StoreID       : num  -1.29 -1.29 1.33 1.33 1.33 ...
##  $ PriceCH       : num  -1.14 -1.73 -1.73 -1.14 -1.14 ...
##  $ PriceMM       : num  -0.688 -2.898 -2.898 -0.688 -0.688 ...
##  $ DiscCH        : num  -0.452 -0.452 -0.452 -0.452 -0.452 ...
##  $ DiscMM        : num  -0.582 -0.582 -0.582 1.341 1.341 ...
##  $ SpecialCH     : num  -0.429 -0.429 -0.429 2.329 -0.429 ...
##  $ SpecialMM     : num  -0.42 -0.42 -0.42 -0.42 -0.42 ...
##  $ LoyalCH       : num  -0.205 -0.525 1.256 1.324 1.35 ...
##  $ SalePriceMM   : num  0.113 -1.101 -1.101 -1.506 -1.506 ...
##  $ SalePriceCH   : num  -0.431 -0.844 -0.844 -0.431 -0.431 ...
##  $ PriceDiff     : num  0.341 -0.563 -0.563 -1.165 -1.165 ...
##  $ Store7.No     : num  1 1 0 0 0 0 0 0 0 1 ...
##  $ Store7.Yes    : num  0 0 1 1 1 1 1 1 1 0 ...
##  $ PctDiscMM     : num  -0.588 -0.588 -0.588 1.447 1.447 ...
##  $ PctDiscCH     : num  -0.448 -0.448 -0.448 -0.448 -0.448 ...
##  $ ListPriceDiff : num  0.211 -1.988 -1.988 0.211 0.211 ...
##  $ STORE         : num  -0.457 -0.457 -1.15 -1.15 -1.15 ...</code></pre>
</div>
<div id="why-normalization" class="section level1">
<h1>Why Normalization</h1>
<p>为了消除不同变量由于单位造成的权重影响，我们对数据进行数据标准化</p>
</div>
<div id="how-1" class="section level1">
<h1>How</h1>
<ol style="list-style-type: decimal">
<li><strong>range:</strong> Normalize values so it ranges between 0 and 1</li>
<li><strong>center:</strong> Subtract Mean</li>
<li><strong>scale:</strong> Divide by standard deviation</li>
<li><strong>BoxCox:</strong> Remove skewness leading to normality. Values must be &gt; 0</li>
<li><strong>YeoJohnson:</strong> Like BoxCox, but works for negative values.</li>
<li><strong>expoTrans:</strong> Exponential transformation, works for negative values.</li>
<li><strong>pca:</strong> Replace with principal components</li>
<li><strong>ica:</strong> Replace with independent components</li>
<li><strong>spatialSign:</strong> Project the data to a unit circle</li>
</ol>
<pre class="r"><code>preProcess_range_model &lt;- preProcess(trainData, method=&#39;range&#39;)
trainData &lt;- predict(preProcess_range_model, newdata = trainData)

# Append the Y variable
trainData$Purchase &lt;- y

apply(trainData[, 1:10], 2, FUN=function(x){c(&#39;min&#39;=min(x), &#39;max&#39;=max(x))})</code></pre>
<pre><code>##     WeekofPurchase StoreID PriceCH PriceMM DiscCH DiscMM SpecialCH
## min              0       0       0       0      0      0         0
## max              1       1       1       1      1      1         1
##     SpecialMM LoyalCH SalePriceMM
## min         0       0           0
## max         1       1           1</code></pre>
<pre class="r"><code>save.image(file = &quot;../../data/craet_3-3.Rdata&quot;)</code></pre>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Why should I trust you 🤖?]]></title>
    <link href="/2018/03/why-should-i-trust-you/"/>
    <id>/2018/03/why-should-i-trust-you/</id>
    <published>2018-03-26T00:00:00+00:00</published>
    <updated>2018-03-26T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p>传统的机器学习工作流程主要集中在模型训练和优化上; 最好的模型通常是通过像精度或者错误这样的性能度量来选择的，而且如果它通过了这些性能标准的某些阈值，我们倾向于假设一个模型是足够好的。在机器学习的许多应用中，用户会使用一个模型来帮助做决定， 例如：一位医生不会对病人进行手术，仅仅因为这个模型说不应该进行手术？</p>
<p>由于复杂的机器学习模型本质上是黑盒子，而且太复杂，机器学习模型做出的分类决定通常很难被人类的大脑所理解，但是能够理解和解释这些模型对于提高模型质量，提高信任度和透明度以及减少偏见非常重要，因为人类往往具有良好的直觉和因果推理，这些都是难以在数据评估指标中捕获。</p>
<p>因此，我们希望能够形象的理解它们的工作原理：为什么一个模型将具有特定标签的案例进行准确分类。eg: 为什么一个乳腺肿块样本被归类为“恶性”而不是“良性，仅仅因为它长得丑吗？</p>
<blockquote>
<p><a href="https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime">Local Interpretable Model-Agnostic Explanations (LIME)</a> is an attempt to make these complex models at least partly understandable. The method has been published in <a href="https://arxiv.org/pdf/1602.04938.pdf">“Why Should I Trust You?”</a> Explaining the Predictions of Any Classifier. By Marco Tulio Ribeiro, Sameer Singh and Carlos Guestrin from the University of Washington in Seattle</p>
</blockquote>
<div id="how-lime-works" class="section level2">
<h2><strong>How LIME works</strong></h2>
<blockquote>
<p>lime is able to explain all models for which we can obtain prediction probabilities (in R, that is every model that works with predict(type = “prob”)). It makes use of the fact that linear models are easy to explain because they are based on linear relationships between features and class labels: The complex model function is approximated by locally fitting linear models to permutations of the original training set.On each permutation, a linear model is being fit and weights are given so that incorrect classification of instances that are more similar to the original data are penalized (positive weights support a decision, negative weights contradict them). This will give an approximation of how much (and in which way) each feature contributed to a decision made by the model</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7fa56fd7333.jpg" width="30%" /></p>
<blockquote>
<p>We take the image on the left and divide it into interpretable components</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7faba0d302a.jpg" width="30%" /></p>
<blockquote>
<p>we then generate a data set of perturbed instances by turning some of the interpretable components “oﬀ”. For each perturbed instance, we get the probability that a tree frog is in the image according to the model.</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7fac3ca8787.jpg" width="30%" /></p>
<blockquote>
<p>We then learn a simple (linear) model on this data set, which is locally weighted—that is, we care more about making mistakes in perturbed instances that are more similar to the original image</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7fac8382a86.jpg" width="30%" /></p>
<blockquote>
<p>the end, we present the superpixels with highest positive weights as an explanation, graying out everything else</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7faf16f0320.jpg" width="30%" /></p>
<p>🤖预测这张图是个树蛙是因为这个部分,所以🤖预测结果是比较可信的。 <img src="https://i.loli.net/2018/02/11/5a7faebabe34e.jpg" style="display: block; margin: auto;" /></p>
<p>🤖预测这张图是台球是根据这些部分，所以🤖预测结果是不可信的。 <img src="https://i.loli.net/2018/02/11/5a7fb61ecb060.jpg" style="display: block; margin: auto;" /></p>
</div>
<div id="example-in-r" class="section level2">
<h2><strong>Example in R</strong></h2>
<div id="prepare-the-breast-cancer-data" class="section level3">
<h3>01.Prepare the breast cancer data</h3>
<p>This <strong>data</strong> of example comes from the book of <strong>R in action</strong></p>
<pre class="r"><code>loc &lt;- &quot;http://archive.ics.uci.edu/ml/machine-learning-databases/&quot;
ds  &lt;- &quot;breast-cancer-wisconsin/breast-cancer-wisconsin.data&quot;
url &lt;- paste(loc, ds, sep=&quot;&quot;)

breast &lt;- read.table(url, sep=&quot;,&quot;, header=FALSE, na.strings=&quot;?&quot;)
names(breast) &lt;- c(&quot;ID&quot;, &quot;clumpThickness&quot;, &quot;sizeUniformity&quot;,
                   &quot;shapeUniformity&quot;, &quot;maginalAdhesion&quot;, 
                   &quot;singleEpithelialCellSize&quot;, &quot;bareNuclei&quot;, 
                   &quot;blandChromatin&quot;, &quot;normalNucleoli&quot;, &quot;mitosis&quot;, &quot;class&quot;)

df &lt;- breast[-1]
df$class &lt;- factor(df$class, levels=c(2,4), 
                   labels=c(&quot;benign&quot;, &quot;malignant&quot;))

set.seed(1234)
train &lt;- sample(nrow(df), 0.7*nrow(df))
df.train &lt;- df[train,]
df.validate &lt;- df[-train,]
table(df.train$class)</code></pre>
<pre><code>## 
##    benign malignant 
##       329       160</code></pre>
<pre class="r"><code>table(df.validate$class)</code></pre>
<pre><code>## 
##    benign malignant 
##       129        81</code></pre>
</div>
<div id="create-decision-tree-model" class="section level3">
<h3>02 Create decision tree model</h3>
<pre class="r"><code>library(rpart)
set.seed(1234)
dtree &lt;- rpart(class ~ ., data=df.train, method=&quot;class&quot;,      
               parms=list(split=&quot;information&quot;))
dtree$cptable</code></pre>
<pre><code>##         CP nsplit rel error  xerror       xstd
## 1 0.800000      0   1.00000 1.00000 0.06484605
## 2 0.046875      1   0.20000 0.30625 0.04150018
## 3 0.012500      3   0.10625 0.20625 0.03467089
## 4 0.010000      4   0.09375 0.18125 0.03264401</code></pre>
<pre class="r"><code>plotcp(dtree)</code></pre>
<p><img src="/post/2018-02-11-why-should-i-trust-you_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>dtree.pruned &lt;- prune(dtree, cp=.0125)</code></pre>
</div>
<div id="predict" class="section level3">
<h3>03 predict</h3>
<pre class="r"><code>dtree.pred &lt;- predict(dtree.pruned, df.validate, type=&quot;class&quot;)
(dtree.perf &lt;- table(df.validate$class, dtree.pred, 
                    dnn=c(&quot;Actual&quot;, &quot;Predicted&quot;)))</code></pre>
<pre><code>##            Predicted
## Actual      benign malignant
##   benign       122         7
##   malignant      2        79</code></pre>
</div>
<div id="plot-decision-tree" class="section level3">
<h3>04 plot decision tree</h3>
<pre class="r"><code>#plot01
library(rpart.plot)
prp(dtree.pruned, type = 2, extra = 104,  
    fallen.leaves = TRUE, main=&quot;Decision Tree&quot;)
#plot02
library(partykit)</code></pre>
<p><img src="/post/2018-02-11-why-should-i-trust-you_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>library(dplyr)
dtree.pruned %&gt;% as.party() %&gt;% plot()</code></pre>
<p><img src="/post/2018-02-11-why-should-i-trust-you_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
</div>
<div id="lime-why-should-i-trust-you" class="section level3">
<h3>LIME: why should I trust you 🤖?</h3>
<pre class="r"><code>library(lime)
explainer &lt;- lime(df.train, model = dtree.pruned)

# Explain new observation
#[model_type](https://github.com/thomasp85/lime/blob/master/R/models.R)
model_type.rpart &lt;- function(x, ...) &#39;classification&#39;#defined model_type method
test.data &lt;- 
  df.validate %&gt;% 
  dplyr::select(-class) %&gt;% 
  head(3)
explanation &lt;- lime::explain(test.data, explainer, n_labels = 1, n_features = 2)

# The output is provided in a consistent tabular format and includes the
# output from the model.
head(explanation)</code></pre>
<pre><code>##       model_type case     label label_prob  model_r2 model_intercept
## 1 classification    3    benign  0.9933993 0.1809444      0.05042991
## 2 classification    3    benign  0.9933993 0.1809444      0.05042991
## 3 classification    4 malignant  0.9507042 0.1918642      0.54743276
## 4 classification    4 malignant  0.9507042 0.1918642      0.54743276
## 5 classification    5    benign  0.9933993 0.1924691      0.05378321
## 6 classification    5    benign  0.9933993 0.1924691      0.05378321
##   model_prediction                  feature feature_value feature_weight
## 1        0.4637659           blandChromatin             3   -0.001977357
## 2        0.4637659           sizeUniformity             1    0.415313316
## 3        0.9524157 singleEpithelialCellSize             3    0.002885248
## 4        0.9524157           sizeUniformity             8    0.402097681
## 5        0.4712710          maginalAdhesion             3   -0.004533032
## 6        0.4712710           sizeUniformity             1    0.422020822
##                        feature_desc                      data
## 1           2 &lt; blandChromatin &lt;= 3 3, 1, 1, 1, 2, 2, 3, 1, 1
## 2               sizeUniformity &lt;= 4 3, 1, 1, 1, 2, 2, 3, 1, 1
## 3 2 &lt; singleEpithelialCellSize &lt;= 4 6, 8, 8, 1, 3, 4, 3, 7, 1
## 4                4 &lt; sizeUniformity 6, 8, 8, 1, 3, 4, 3, 7, 1
## 5              maginalAdhesion &lt;= 3 4, 1, 1, 3, 2, 1, 3, 1, 1
## 6               sizeUniformity &lt;= 4 4, 1, 1, 3, 2, 1, 3, 1, 1
##               prediction
## 1 0.99339934, 0.00660066
## 2 0.99339934, 0.00660066
## 3 0.04929577, 0.95070423
## 4 0.04929577, 0.95070423
## 5 0.99339934, 0.00660066
## 6 0.99339934, 0.00660066</code></pre>
<pre class="r"><code># And can be visualised directly
plot_features(explanation)</code></pre>
<p><img src="/post/2018-02-11-why-should-i-trust-you_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
</div>
<div id="links" class="section level2">
<h2><strong>Links</strong></h2>
<ul>
<li><a href="http://archive.ics.uci.edu/ml/datasets/Chronic_Kidney_Disease">CKD data set</a></li>
<li><a href="https://github.com/marcotcr/lime">open-source Python code for LIME</a></li>
<li><a href="https://github.com/thomasp85/lime">R package for LIME</a></li>
</ul>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[3.2 statistic description and impute missing value]]></title>
    <link href="/2018/03/3-2-statistic-description-and-impute-missing-value/"/>
    <id>/2018/03/3-2-statistic-description-and-impute-missing-value/</id>
    <published>2018-03-24T00:00:00+00:00</published>
    <updated>2018-03-24T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div class="section level1">
<h1>加载数据和包</h1>
<pre class="r"><code>load(&quot;../../data/caret.Rdata&quot;)
library(tidyverse)
library(caret)</code></pre>
<p>在进行数据整理之前 我们先看看训练数据的统计描述</p>
<p><code>skimr</code>包对列的统计提供了方便的函数</p>
<p><code>skimr::skim_to_wide()</code> 输出一个包含列统计描述的数据框</p>
<pre class="r"><code>library(skimr)
skimmed &lt;- skim_to_wide(trainData)
skimmed[, c(1:5, 9:11, 13, 15:16)]</code></pre>
<pre><code>## # A tibble: 18 x 11
##    type   variable  missing complete n     mean   sd    p0    median p100 
##    &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;
##  1 factor Purchase  0       857      857   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; 
##  2 factor Store7    0       857      857   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; 
##  3 integ… SpecialCH 2       855      857   &quot;  0.… &quot; 0.… 0     0      1    
##  4 integ… SpecialMM 4       853      857   &quot;  0.… &quot; 0.… 0     0      1    
##  5 integ… STORE     2       855      857   &quot;  1.… &quot; 1.… 0     2      4    
##  6 integ… StoreID   1       856      857   &quot;  3.… &quot; 2.… 1     3      7    
##  7 integ… WeekofPu… 0       857      857   254.17 15.59 227   257    278  
##  8 numer… DiscCH    2       855      857   0.054  &quot;0.1… &quot; 0 … &quot;0   &quot; &quot;0.5…
##  9 numer… DiscMM    3       854      857   &quot;0.12… &quot;0.2… &quot; 0 … &quot;0   &quot; &quot;0.8…
## 10 numer… ListPric… 0       857      857   &quot;0.22… &quot;0.1… &quot; 0 … 0.24   0.44 
## 11 numer… LoyalCH   5       852      857   &quot;0.56… &quot;0.3… &quot; 1.… &quot;0.6 &quot; &quot;1  …
## 12 numer… PctDiscCH 2       855      857   0.028  0.063 &quot; 0 … &quot;0   &quot; 0.25 
## 13 numer… PctDiscMM 2       855      857   0.058  0.099 &quot; 0 … &quot;0   &quot; &quot;0.4…
## 14 numer… PriceCH   1       856      857   &quot;1.87… &quot;0.1… &quot; 1.… 1.86   2.09 
## 15 numer… PriceDiff 1       856      857   &quot;0.15… &quot;0.2… &quot;-0.… 0.23   0.64 
## 16 numer… PriceMM   1       856      857   &quot;2.08… &quot;0.1… &quot; 1.… 2.09   2.29 
## 17 numer… SalePric… 1       856      857   &quot;1.81… &quot;0.1… &quot; 1.… 1.86   2.09 
## 18 numer… SalePric… 3       854      857   &quot;1.96… &quot;0.2… &quot; 1.… 2.09   2.29 
## # ... with 1 more variable: hist &lt;chr&gt;</code></pre>
</div>
<div class="section level1">
<h1>插入数据</h1>
<p>Caret 提供了一个很方便的函数 <code>preProcess()</code></p>
<ul>
<li>设置 <code>method=knnImpute</code> 生成一个模型</li>
<li>使用 <code>predict()</code> 对数据进行插入</li>
</ul>
<pre class="r"><code># Create the knn imputation model on the training data
preProcess_missingdata_model &lt;- preProcess(trainData, method=&#39;knnImpute&#39;)
preProcess_missingdata_model</code></pre>
<pre><code>## Created from 828 samples and 18 variables
## 
## Pre-processing:
##   - centered (16)
##   - ignored (2)
##   - 5 nearest neighbor imputation (16)
##   - scaled (16)</code></pre>
<pre class="r"><code># Use the imputation model to predict the values of missing data points
library(RANN)  # required for knnInpute
trainData &lt;- predict(preProcess_missingdata_model, newdata = trainData)
anyNA(trainData)</code></pre>
<pre><code>## [1] FALSE</code></pre>
<pre class="r"><code>save.image(file = &quot;../../data/craet_3-2.Rdata&quot;)</code></pre>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[3.1 How to split the dataset into training and validation?]]></title>
    <link href="/2018/03/3-1-how-to-split-the-dataset-into-training-and-validation/"/>
    <id>/2018/03/3-1-how-to-split-the-dataset-into-training-and-validation/</id>
    <published>2018-03-23T00:00:00+00:00</published>
    <updated>2018-03-23T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p>数据准备好了之后的第一步就是拆分数据集为训练数据和测试数据，一般是 8:2 的比例。</p>
<p>为什么拆分数据呢？</p>
<p>当我们在构建一个机器学习模型上时，真正的目的是为了预测真是世界的数据，而机器学习模型是依靠算法学习训练数据学习Y 与 X 的关系，这种的关系的学习好坏的评判是要依靠没有参与学习模型的数据与预测数据之间的差距来评判的。</p>
<pre class="r"><code># Load the caret package
library(caret)

# Import dataset
orange &lt;- read.csv(&#39;../../data/orange_juice_withmissing.csv&#39;)
# Create the training and test datasets
set.seed(100)

# Step 1: Get row numbers for the training data
trainRowNumbers &lt;- createDataPartition(orange$Purchase, p=0.8, list=FALSE)

# Step 2: Create the training  dataset
trainData &lt;- orange[trainRowNumbers,]

# Step 3: Create the test dataset
testData &lt;- orange[-trainRowNumbers,]

# Store X and Y for later use.
x = trainData[, 2:18]
y = trainData$Purchase</code></pre>
<p><code>createDataPartition</code>：输入 Y 和 P 比率（训练数据的比率） 输出 训练数据的行索引。</p>
<div id="save-the-image-for-next-blog" class="section level1">
<h1>save the image for next blog</h1>
<pre class="r"><code>save.image(file = &quot;../../data/caret.Rdata&quot;)</code></pre>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[2 machine learning: load dataset]]></title>
    <link href="/2018/03/machine-learning-2-load-dataset/"/>
    <id>/2018/03/machine-learning-2-load-dataset/</id>
    <published>2018-03-22T00:00:00+00:00</published>
    <updated>2018-03-22T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<div id="load-the-package-and-dataset" class="section level1">
<h1>Load the package and dataset</h1>
<p>我们将使用 ISLR 包中的 <a href="&#39;https://raw.githubusercontent.com/selva86/datasets/master/orange_juice_withmissing.csv&#39;">Orange Juice Data</a>.</p>
<p>目标： 预测顾客会购买哪两种🍊汁</p>
<p>数据集不是很大，我们的重点是构建模型的过程，而非真正搭建一个有用的模型。</p>
<p>👌，let’go.</p>
<pre class="r"><code># Load the caret package
library(caret)

# Import dataset
orange &lt;- read.csv(&#39;../../data/orange_juice_withmissing.csv&#39;)

# Structure of the dataframe
str(orange)</code></pre>
<pre><code>## &#39;data.frame&#39;:    1070 obs. of  18 variables:
##  $ Purchase      : Factor w/ 2 levels &quot;CH&quot;,&quot;MM&quot;: 1 1 1 2 1 1 1 1 1 1 ...
##  $ WeekofPurchase: int  237 239 245 227 228 230 232 234 235 238 ...
##  $ StoreID       : int  1 1 1 1 7 7 7 7 7 7 ...
##  $ PriceCH       : num  1.75 1.75 1.86 1.69 1.69 1.69 1.69 1.75 1.75 1.75 ...
##  $ PriceMM       : num  1.99 1.99 2.09 1.69 1.69 1.99 1.99 1.99 1.99 1.99 ...
##  $ DiscCH        : num  0 0 0.17 0 0 0 0 0 0 0 ...
##  $ DiscMM        : num  0 0.3 0 0 0 0 0.4 0.4 0.4 0.4 ...
##  $ SpecialCH     : int  0 0 0 0 0 0 1 1 0 0 ...
##  $ SpecialMM     : int  0 1 0 0 0 1 1 0 0 0 ...
##  $ LoyalCH       : num  0.5 0.6 0.68 0.4 0.957 ...
##  $ SalePriceMM   : num  1.99 1.69 2.09 1.69 1.69 1.99 1.59 1.59 1.59 1.59 ...
##  $ SalePriceCH   : num  1.75 1.75 1.69 1.69 1.69 1.69 1.69 1.75 1.75 1.75 ...
##  $ PriceDiff     : num  0.24 -0.06 0.4 0 0 0.3 -0.1 -0.16 -0.16 -0.16 ...
##  $ Store7        : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 1 2 2 2 2 2 2 ...
##  $ PctDiscMM     : num  0 0.151 0 0 0 ...
##  $ PctDiscCH     : num  0 0 0.0914 0 0 ...
##  $ ListPriceDiff : num  0.24 0.24 0.23 0 0 0.3 0.3 0.24 0.24 0.24 ...
##  $ STORE         : int  1 1 1 1 0 0 0 0 0 0 ...</code></pre>
<pre class="r"><code># See top 6 rows and 10 columns
head(orange[, 1:10])</code></pre>
<pre><code>##   Purchase WeekofPurchase StoreID PriceCH PriceMM DiscCH DiscMM SpecialCH
## 1       CH            237       1    1.75    1.99   0.00    0.0         0
## 2       CH            239       1    1.75    1.99   0.00    0.3         0
## 3       CH            245       1    1.86    2.09   0.17    0.0         0
## 4       MM            227       1    1.69    1.69   0.00    0.0         0
## 5       CH            228       7    1.69    1.69   0.00    0.0         0
## 6       CH            230       7    1.69    1.99   0.00    0.0         0
##   SpecialMM  LoyalCH
## 1         0 0.500000
## 2         1 0.600000
## 3         0 0.680000
## 4         0 0.400000
## 5         0 0.956535
## 6         1 0.965228</code></pre>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Machine Learning in R 1：introdution]]></title>
    <link href="/2018/03/machine-learning-in-r-introdution/"/>
    <id>/2018/03/machine-learning-in-r-introdution/</id>
    <published>2018-03-21T00:00:00+00:00</published>
    <updated>2018-03-21T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p>Caret Package是一个用于在R中构建机器学习模型的综合框架。在此博文中，我会解释 caret 包的几乎所有核心功能，并引导完成构建预测模型的分步过程。</p>
<p>Caret 是 Classification And REgression Training 的简称。</p>
<p>Caret 包很好地让所有与机器学习模型开发相关的步骤集成到一个简化的工作流程中，几乎每个主流的ML算法都可以在R中实现。</p>
<p>由于R具有如此多的机器学习算法实现包，因此选则在哪个包中实现某种算法是非常头疼的问题。多数时候，实现算法的语法和方法在不同包中有所不同。 结合数据预处理，查阅超参数的帮助页面（定义算法如何学习的参数）并努力寻找最佳模型，可以使构建预测模型成为一项相关任务。</p>
<p>在本教程后面的部分，我将介绍如何查看所有caret 支持的ML算法（这是一个很长的列表）以及可以调整哪些超参数。</p>
<p>此外，我们不会止步于 caret 包，我们将看看如何巧妙地集成来自多个最佳模型的预测，并可能使用 <code>caretEnsemble</code> 来产生更好的预测。</p>
<p>这个教程总共包括5部分，分别是： 1. 数据准备和清理 2. 可视化重要变量 3. 特征选择 4. 训练模型和调节模型 5. 预测</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[HOW TO USE THE NCBI&#39;S NEW API KEYS]]></title>
    <link href="/2018/03/how-to-use-the-ncbis-new-api-keys/"/>
    <id>/2018/03/how-to-use-the-ncbis-new-api-keys/</id>
    <published>2018-03-19T00:00:00+00:00</published>
    <updated>2018-03-19T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p><a href="https://www.ncbi.nlm.nih.gov/">The NCBI</a> is one of the most important sources of biological data. The centre provides access to information on 28 million scholarly articles through PubMed and 250 million DNA sequences through GenBank. More importantly, records in the [50 public databases] (<a href="https://www.ncbi.nlm.nih.gov/guide/all/#databases" class="uri">https://www.ncbi.nlm.nih.gov/guide/all/#databases</a>) maintained by the NCBI are strongly cross-referenced. As a result, it is possible to pinpoint searches using almost 2 million taxonomic names or a <a href="https://www.nlm.nih.gov/mesh/">controlled vocabulary with 270,000 terms</a>.</p>
<p><strong>Rentrez has been designed to make it easy to search for and download NCBI records and download them from within an R session.</strong></p>
<p>I though it might be fun to use this post to find out where papers describing R packages are published these days</p>
<p>Here we use the <code>entrez_search</code> and <code>entrez_summary</code> functions to get some information on all of the papers published in 2017 with the term ‘R package’ in their title:</p>
<pre class="r"><code>if (!require(&quot;rentrez&quot;)) install.packages(&quot;rentrez&quot;)
library(rentrez)

pkg_search &lt;- entrez_search(db=&quot;pubmed&quot;, 
                            term=&quot;(R Package[TITLE]) AND (2018[PDAT])&quot;, 
                            use_history=TRUE)
pkg_summs &lt;- entrez_summary(db=&quot;pubmed&quot;, web_history=pkg_search$web_history)
pkg_summs</code></pre>
<pre><code>## List of  31 esummary records. First record:
## 
##  $`29554216`
## esummary result with 42 items:
##  [1] uid               pubdate           epubdate         
##  [4] source            authors           lastauthor       
##  [7] title             sorttitle         volume           
## [10] issue             pages             lang             
## [13] nlmuniqueid       issn              essn             
## [16] pubtype           recordstatus      pubstatus        
## [19] articleids        history           references       
## [22] attributes        pmcrefcount       fulljournalname  
## [25] elocationid       doctype           srccontriblist   
## [28] booktitle         medium            edition          
## [31] publisherlocation publishername     srcdate          
## [34] reportnumber      availablefromurl  locationlabel    
## [37] doccontriblist    docdate           bookname         
## [40] chapter           sortpubdate       sortfirstauthor</code></pre>
<p>we are interested in the journals in which these papers appear. We can use the helper function <code>extract_from_esummary</code> to isolate the <em>source</em> of each paper, then use <code>table</code> to count up the frequency of each journal.</p>
<pre class="r"><code>library(ggplot2)
library(ggpomological)
#scales::show_col(ggpomological:::pomological_palette)

journals &lt;- extract_from_esummary(pkg_summs, &quot;source&quot;)
journal_freq &lt;- as.data.frame(table(journals, dnn=&quot;journal&quot;), responseName=&quot;n.papers&quot;)
pkg_journal &lt;- ggplot(journal_freq, aes(reorder(journal, n.papers), n.papers)) + 
    geom_point(size=2) + 
    coord_flip() + 
    scale_y_continuous(&quot;Number of papers&quot;) +
    scale_x_discrete(&quot;Journal&quot;) +
    theme_bw() +
    ggtitle(&quot;Venues for papers describing R Packages in 2018&quot;)

pkg_journal + ggpomological::theme_pomological()</code></pre>
<p><img src="/post/2018-03-19-how_to_use_NCBI_API_keys_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>So, it looks like <em>Bioinformatics</em>, <em>Plos One</em> and <em>Comput Methods Progams Biomed</em> Resources are popular destinations for papers describing R packages, but these appear in journals all the way across the biological sciences.</p>
<p>The NCBI now gives users the opportunity to <a href="https://ncbiinsights.ncbi.nlm.nih.gov/2017/11/02/new-api-keys-for-the-e-utilities/">register for an access key</a> that will allow them to make up to 10 requests per second (non-registered users are limited to 3 requests per second per IP address).For one-off cases, this is as simple as adding the api_key argument to a given function call.</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[A function for ggplot2: input strings for aes()]]></title>
    <link href="/2018/03/a-function-for-ggplot2-input-strings-for-aes/"/>
    <id>/2018/03/a-function-for-ggplot2-input-strings-for-aes/</id>
    <published>2018-03-18T00:00:00+00:00</published>
    <updated>2018-03-18T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p>在我写文章画图时经常遇到的一个问题是：ggplot2 坐标轴的输入不支持输入数据框的变量名，通常会报错找不到对象</p>
<div class="section level1">
<h1>🌰：问题描述</h1>
<p>data: <a href="https://github.com/fivethirtyeight/data/tree/master/early-senate-polls">early senate poll</a></p>
<pre class="r"><code>library(tidyverse) # general tasks
library(broom) # tidy model output
library(ggthemes) # style the plots

poll_data &lt;- read_csv(&quot;https://raw.githubusercontent.com/fivethirtyeight/data/master/early-senate-polls/early-senate-polls.csv&quot;)

glimpse(poll_data)</code></pre>
<pre><code>## Observations: 107
## Variables: 4
## $ year                  &lt;int&gt; 2006, 2006, 2006, 2006, 2006, 2006, 2006...
## $ election_result       &lt;int&gt; -39, -10, -9, -16, 40, 10, -2, -41, -31,...
## $ presidential_approval &lt;int&gt; 46, 33, 32, 33, 53, 44, 37, 39, 42, 33, ...
## $ poll_average          &lt;int&gt; -28, -10, -1, -15, 39, 14, 2, -22, -27, ...</code></pre>
<p>background: <strong>there is a strong correlation between polling numbers and the ultimate result of an election</strong></p>
<div id="-" class="section level2">
<h2>构建模型： 线性模型</h2>
<pre class="r"><code>poll_lm &lt;- lm(election_result ~ poll_average, data = poll_data)

summary(poll_lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = election_result ~ poll_average, data = poll_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -29.4281  -5.0197   0.5601   6.1364  17.9357 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -0.89110    0.76969  -1.158     0.25    
## poll_average  1.04460    0.03777  27.659   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.93 on 105 degrees of freedom
## Multiple R-squared:  0.8793, Adjusted R-squared:  0.8782 
## F-statistic:   765 on 1 and 105 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div class="section level2">
<h2>写个函数画出因变量和自变量的关系</h2>
<p>结果出现了一个令我费解的报错</p>
<blockquote>
<p><strong>Error in FUN(X[[i]], …) : object ‘poll_average’ not found</strong></p>
</blockquote>
<p>我不断地检查我的拼写，直到我开始怀疑人生</p>
</div>
</div>
<div id="define-aesthetic-mappings-programatically" class="section level1">
<h1>解决办法：<a href="http://ggplot2.tidyverse.org/reference/aes_.html"><strong>Define aesthetic mappings programatically</strong></a></h1>
<pre class="r"><code>plot_model &lt;- function(mod, explanatory, response, .fitted = &quot;.fitted&quot;) {
  augment(mod) %&gt;%
  ggplot() +
    geom_point(aes_string(x = explanatory, y = response), color = &quot;#2CA58D&quot;) +
    geom_line(aes_string(x = explanatory, y = .fitted), color = &quot;#033F63&quot;) +
    theme_solarized() +
    theme(axis.title = element_text()) +
    labs(x = &quot;Poll average&quot;, y = &quot;Election results&quot;)
}

plot_model(poll_lm, &quot;poll_average&quot;, &quot;election_result&quot;)</code></pre>
<p><img src="/post/2018-03-18-a-function-for-ggplot2-input-strings-for-aes_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Hello world]]></title>
    <link href="/2018/03/hello-world/"/>
    <id>/2018/03/hello-world/</id>
    <published>2018-03-15T00:00:00+00:00</published>
    <updated>2018-03-15T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p>Just say hello world!</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Conferences, webinars, podcasts and the likes]]></title>
    <link href="/page/conferences_podcasts_webinars/"/>
    <id>/page/conferences_podcasts_webinars/</id>
    <published>2018-02-01T16:06:06+02:00</published>
    <updated>2018-02-01T16:06:06+02:00</updated>
    <content type="html"><![CDATA[

<p>Here, you can find a list of all the talks I gave at conferences, webinars, podcasts, workshops, and all the other places you can and could hear me talk. :-)</p>

<h2 id="workshops-i-am-giving">Workshops I am giving</h2>

<ul>
<li><a href="https://shirinsplayground.netlify.com/2017/11/deep_learning_keras_tensorflow/">Workshop on Deep Learning with Keras and TensorFlow in R</a></li>
</ul>

<blockquote>
<p>I offer a workshop on deep learning with Keras and TensorFlow using R.
Date and place depend on who and how many people are interested, so please contact me either directly or via the workshop page: <a href="https://www.codecentric.de/schulung/deep-learning-mit-keras-und-tensorflow/">https://www.codecentric.de/schulung/deep-learning-mit-keras-und-tensorflow/</a> (the description is in German but I also offer to give the workshop in English).</p>
</blockquote>

<h2 id="upcoming-talks-webinars-podcasts-etc">Upcoming talks, webinars, podcasts, etc.</h2>

<ul>
<li><a href="https://shirinsplayground.netlify.com/2018/02/m3_2018/">Announcing my talk about explainability of machine learning models at Minds Mastering Machines Conference</a></li>
</ul>

<blockquote>
<p>On Wednesday, April 25th 2018 I am going to talk about explainability of machine learning models at the Minds Mastering Machines conference in Cologne.</p>
</blockquote>

<ul>
<li><a href="JAX 2018 talk announcement: Deep Learning - a Primer">JAX 2018 talk announcement: Deep Learning - a Primer</a></li>
</ul>

<blockquote>
<p>Deep Learning is one of the &ldquo;hot&rdquo; topics in the AI area – a lot of hype, a lot of inflated expectation, but also quite some impressive success stories. As some AI experts already predict that Deep Learning will become &ldquo;Software 2.0&rdquo;, it might be a good time to have a closer look at the topic. In this session I will try to give a comprehensive overview of Deep Learning. We will start with a bit of history and some theoretical foundations that we will use to create a little Deep Learning taxonomy. Then we will have a look at current and upcoming application areas: Where can we apply Deep Learning successfully and what does it differentiate from other approaches? Afterwards we will examine the ecosystem: Which tools and libraries are available? What are their strengths and weaknesses? And to complete the session, we will look into some practical code examples and the typical pitfalls of Deep Learning. After this session you will have a much better idea of the why, what and how of Deep Learning, including if and how you might want to apply it to your own work. <a href="https://jax.de/big-data-machine-learning/deep-learning-a-primer/">https://jax.de/big-data-machine-learning/deep-learning-a-primer/</a></p>
</blockquote>

<h2 id="past-talks-webinars-podcasts-etc">Past talks, webinars, podcasts, etc.</h2>

<ul>
<li><a href="https://shirinsplayground.netlify.com/2018/02/herr_mies_wills_wissen/">I talk about machine learning with Daniel Mies (Podcast in German, though)</a></li>
</ul>

<blockquote>
<p>In January 2018 I was interviewed for a tech podcast where I talked about machine learning, neural nets, why I love R and Rstudio and how I became a Data Scientist.</p>
</blockquote>

<ul>
<li><a href="https://shirinsplayground.netlify.com/2017/12/lime_sketchnotes/">Explaining Predictions of Machine Learning Models with LIME - Münster Data Science Meetup</a></li>
</ul>

<blockquote>
<p>In December 2017 I talked about Explaining Predictions of Machine Learning Models with LIME at the Münster Data Science Meetup.</p>
</blockquote>

<ul>
<li><a href="https://shiring.github.io/blogging/2017/09/20/webinar_biology_to_data_science">From Biology to Industry. A Blogger’s Journey to Data Science</a></li>
</ul>

<blockquote>
<p>In September 2017 I gave a webinar for the Applied Epidemiology Didactic of the University of Wisconsin - Madison titled “From Biology to Industry. A Blogger’s Journey to Data Science.”
I talked about how blogging about R and Data Science helped me become a Data Scientist. I also gave a short introduction to Machine Learning, Big Data and Neural Networks.</p>
</blockquote>

<ul>
<li><a href="https://shiring.github.io/machine_learning/2017/03/31/webinar_code">Building meaningful machine learning models for disease prediction</a></li>
</ul>

<blockquote>
<p>In March 2017 I gave a webinar for the ISDS R Group about my work on building machine-learning models to predict the course of different diseases. I went over building a model, evaluating its performance, and answering or addressing different disease related questions using machine learning. My talk covered the theory of machine learning as it is applied using R.</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Welcome to my page!]]></title>
    <link href="/page/about/"/>
    <id>/page/about/</id>
    <published>2017-09-12T16:06:06+02:00</published>
    <updated>2017-09-12T16:06:06+02:00</updated>
    <content type="html"><![CDATA[

<p><img src="/img/Bewerbungsfoto_klein.jpg" alt="" /></p>

<p>I&rsquo;m Shirin, a biologist turned bioinformatician turned data scientist.</p>

<p>I&rsquo;m especially interested in machine learning and data visualization. While I am using R most every day at work, I wanted to have an incentive to regularly explore other types of analyses and other types of data that I don&rsquo;t normally work with. I have also very often benefited from other people&rsquo;s published code in that it gave me ideas for my own work; and I hope that sharing my own analyses will inspire others as much as I often am by what can be be done with data.  It&rsquo;s amazing to me what can be learned from analyzing and visualizing data!</p>

<p>My tool of choice for data analysis so far has been R. I also organize the <a href="https://shiring.github.io/r_users_group/2017/05/20/muenster_r_user_group">MünsteR R-users group on meetup.com</a>.</p>

<p><img src="http://res.cloudinary.com/shiring/image/upload/v1511852499/my_story_wml3zm.png" alt="My journey to Data Science" /></p>

<p>I love dancing and used to do competitive ballroom and latin dancing. Even though I don&rsquo;t have time for that anymore, I still enjoy teaching &ldquo;social dances&rdquo; once a week with the Hochschulsport (university sports courses).</p>

<p>I created the R package <a href="https://github.com/ShirinG/exprAnalysis">exprAnalysis</a>, designed to streamline my RNA-seq data analysis pipeline. It is available via Github. Instructions for installation and usage can be found <a href="https://shiring.github.io/rna-seq/microarray/2016/09/28/exprAnalysis">here</a>.</p>

<p>This blog will showcase some of the analyses I have been doing with different data sets (all freely available). I will also host teaching materials for students to access in conjunction with R courses I am giving.</p>

<hr />

<h2 id="contact-me">Contact me:</h2>

<ul>
<li><a href="https://www.codecentric.de/team/shirin-glander/">Codecentric AG</a></li>
<li><a href="mailto:shirin.glander@gmail.com">Email</a></li>
<li><a href="http://www.xing.com/profile/Shirin_Glander">Xing</a></li>
<li><a href="http://de.linkedin.com/in/shirin-glander-01120881">Linkedin</a></li>
<li><a href="http://twitter.com/ShirinGlander">Twitter</a></li>
</ul>

<hr />

<p>Also check out <a href="http://www.R-bloggers.com">R-bloggers</a> for lots of cool R stuff!</p>
]]></content>
  </entry>
</feed>