<feed xmlns="http://www.w3.org/2005/Atom">
  <title>student zero </title>
  <link href="/index.xml" rel="self"/>
  <link href="/"/>
  <updated>2018-03-21T00:00:00+00:00</updated>
  <id>/</id>
  <author>
    <name>Jixing Liu</name>
  </author>
  <generator>Hugo -- gohugo.io</generator>
  <entry>
    <title type="html"><![CDATA[Machine Learning in R 1ï¼šintrodution]]></title>
    <link href="/2018/03/machine-learning-in-r-introdution/"/>
    <id>/2018/03/machine-learning-in-r-introdution/</id>
    <published>2018-03-21T00:00:00+00:00</published>
    <updated>2018-03-21T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p>Caret Packageæ˜¯ä¸€ä¸ªç”¨äºåœ¨Rä¸­æ„å»ºæœºå™¨å­¦ä¹ æ¨¡å‹çš„ç»¼åˆæ¡†æ¶ã€‚åœ¨æ­¤åšæ–‡ä¸­ï¼Œæˆ‘ä¼šè§£é‡Š caret åŒ…çš„å‡ ä¹æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼Œå¹¶å¼•å¯¼å®Œæˆæ„å»ºé¢„æµ‹æ¨¡å‹çš„åˆ†æ­¥è¿‡ç¨‹ã€‚</p>
<p>Caret æ˜¯ Classification And REgression Training çš„ç®€ç§°ã€‚</p>
<p>Caret åŒ…å¾ˆå¥½åœ°è®©æ‰€æœ‰ä¸æœºå™¨å­¦ä¹ æ¨¡å‹å¼€å‘ç›¸å…³çš„æ­¥éª¤é›†æˆåˆ°ä¸€ä¸ªç®€åŒ–çš„å·¥ä½œæµç¨‹ä¸­ï¼Œå‡ ä¹æ¯ä¸ªä¸»æµçš„MLç®—æ³•éƒ½å¯ä»¥åœ¨Rä¸­å®ç°ã€‚</p>
<p>ç”±äºRå…·æœ‰å¦‚æ­¤å¤šçš„æœºå™¨å­¦ä¹ ç®—æ³•å®ç°åŒ…ï¼Œå› æ­¤é€‰åˆ™åœ¨å“ªä¸ªåŒ…ä¸­å®ç°æŸç§ç®—æ³•æ˜¯éå¸¸å¤´ç–¼çš„é—®é¢˜ã€‚å¤šæ•°æ—¶å€™ï¼Œå®ç°ç®—æ³•çš„è¯­æ³•å’Œæ–¹æ³•åœ¨ä¸åŒåŒ…ä¸­æœ‰æ‰€ä¸åŒã€‚ ç»“åˆæ•°æ®é¢„å¤„ç†ï¼ŒæŸ¥é˜…è¶…å‚æ•°çš„å¸®åŠ©é¡µé¢ï¼ˆå®šä¹‰ç®—æ³•å¦‚ä½•å­¦ä¹ çš„å‚æ•°ï¼‰å¹¶åŠªåŠ›å¯»æ‰¾æœ€ä½³æ¨¡å‹ï¼Œå¯ä»¥ä½¿æ„å»ºé¢„æµ‹æ¨¡å‹æˆä¸ºä¸€é¡¹ç›¸å…³ä»»åŠ¡ã€‚</p>
<p>åœ¨æœ¬æ•™ç¨‹åé¢çš„éƒ¨åˆ†ï¼Œæˆ‘å°†ä»‹ç»å¦‚ä½•æŸ¥çœ‹æ‰€æœ‰caret æ”¯æŒçš„MLç®—æ³•ï¼ˆè¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„åˆ—è¡¨ï¼‰ä»¥åŠå¯ä»¥è°ƒæ•´å“ªäº›è¶…å‚æ•°ã€‚</p>
<p>æ­¤å¤–ï¼Œæˆ‘ä»¬ä¸ä¼šæ­¢æ­¥äº caret åŒ…ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹å¦‚ä½•å·§å¦™åœ°é›†æˆæ¥è‡ªå¤šä¸ªæœ€ä½³æ¨¡å‹çš„é¢„æµ‹ï¼Œå¹¶å¯èƒ½ä½¿ç”¨ <code>caretEnsemble</code> æ¥äº§ç”Ÿæ›´å¥½çš„é¢„æµ‹ã€‚</p>
<p>è¿™ä¸ªæ•™ç¨‹æ€»å…±åŒ…æ‹¬5éƒ¨åˆ†ï¼Œåˆ†åˆ«æ˜¯ï¼š 1. æ•°æ®å‡†å¤‡å’Œæ¸…ç† 2. å¯è§†åŒ–é‡è¦å˜é‡ 3. ç‰¹å¾é€‰æ‹© 4. è®­ç»ƒæ¨¡å‹å’Œè°ƒèŠ‚æ¨¡å‹ 5. é¢„æµ‹</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[HOW TO USE THE NCBI&#39;S NEW API KEYS]]></title>
    <link href="/2018/03/how-to-use-the-ncbis-new-api-keys/"/>
    <id>/2018/03/how-to-use-the-ncbis-new-api-keys/</id>
    <published>2018-03-19T00:00:00+00:00</published>
    <updated>2018-03-19T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p><a href="https://www.ncbi.nlm.nih.gov/">The NCBI</a> is one of the most important sources of biological data. The centre provides access to information on 28 million scholarly articles through PubMed and 250 million DNA sequences through GenBank. More importantly, records in the [50 public databases] (<a href="https://www.ncbi.nlm.nih.gov/guide/all/#databases" class="uri">https://www.ncbi.nlm.nih.gov/guide/all/#databases</a>) maintained by the NCBI are strongly cross-referenced. As a result, it is possible to pinpoint searches using almost 2 million taxonomic names or a <a href="https://www.nlm.nih.gov/mesh/">controlled vocabulary with 270,000 terms</a>.</p>
<p><strong>Rentrez has been designed to make it easy to search for and download NCBI records and download them from within an R session.</strong></p>
<p>I though it might be fun to use this post to find out where papers describing R packages are published these days</p>
<p>Here we use the <code>entrez_search</code> and <code>entrez_summary</code> functions to get some information on all of the papers published in 2017 with the term â€˜R packageâ€™ in their title:</p>
<pre class="r"><code>if (!require(&quot;rentrez&quot;)) install.packages(&quot;rentrez&quot;)
library(rentrez)

pkg_search &lt;- entrez_search(db=&quot;pubmed&quot;, 
                            term=&quot;(R Package[TITLE]) AND (2018[PDAT])&quot;, 
                            use_history=TRUE)
pkg_summs &lt;- entrez_summary(db=&quot;pubmed&quot;, web_history=pkg_search$web_history)
pkg_summs</code></pre>
<pre><code>## List of  31 esummary records. First record:
## 
##  $`29554216`
## esummary result with 42 items:
##  [1] uid               pubdate           epubdate         
##  [4] source            authors           lastauthor       
##  [7] title             sorttitle         volume           
## [10] issue             pages             lang             
## [13] nlmuniqueid       issn              essn             
## [16] pubtype           recordstatus      pubstatus        
## [19] articleids        history           references       
## [22] attributes        pmcrefcount       fulljournalname  
## [25] elocationid       doctype           srccontriblist   
## [28] booktitle         medium            edition          
## [31] publisherlocation publishername     srcdate          
## [34] reportnumber      availablefromurl  locationlabel    
## [37] doccontriblist    docdate           bookname         
## [40] chapter           sortpubdate       sortfirstauthor</code></pre>
<p>we are interested in the journals in which these papers appear. We can use the helper functionÂ <code>extract_from_esummary</code>Â to isolate the <em>source</em> of each paper, then useÂ <code>table</code>Â to count up the frequency of each journal.</p>
<pre class="r"><code>library(ggplot2)
library(ggpomological)
#scales::show_col(ggpomological:::pomological_palette)

journals &lt;- extract_from_esummary(pkg_summs, &quot;source&quot;)
journal_freq &lt;- as.data.frame(table(journals, dnn=&quot;journal&quot;), responseName=&quot;n.papers&quot;)
pkg_journal &lt;- ggplot(journal_freq, aes(reorder(journal, n.papers), n.papers)) + 
    geom_point(size=2) + 
    coord_flip() + 
    scale_y_continuous(&quot;Number of papers&quot;) +
    scale_x_discrete(&quot;Journal&quot;) +
    theme_bw() +
    ggtitle(&quot;Venues for papers describing R Packages in 2018&quot;)

pkg_journal + ggpomological::theme_pomological()</code></pre>
<p><img src="/post/2018-03-19-how_to_use_NCBI_API_keys_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>So, it looks like <em>Bioinformatics</em>, <em>Plos One</em> and <em>Comput Methods Progams Biomed</em> Resources are popular destinations for papers describing R packages, but these appear in journals all the way across the biological sciences.</p>
<p>The NCBI now gives users the opportunity toÂ <a href="https://ncbiinsights.ncbi.nlm.nih.gov/2017/11/02/new-api-keys-for-the-e-utilities/">register for an access key</a>Â that will allow them to make up to 10 requests per second (non-registered users are limited to 3 requests per second per IP address).For one-off cases, this is as simple as adding the api_key argument to a given function call.</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[A function for ggplot2: input strings for aes()]]></title>
    <link href="/2018/03/a-function-for-ggplot2-input-strings-for-aes/"/>
    <id>/2018/03/a-function-for-ggplot2-input-strings-for-aes/</id>
    <published>2018-03-18T00:00:00+00:00</published>
    <updated>2018-03-18T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p>åœ¨æˆ‘å†™æ–‡ç« ç”»å›¾æ—¶ç»å¸¸é‡åˆ°çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼šggplot2 åæ ‡è½´çš„è¾“å…¥ä¸æ”¯æŒè¾“å…¥æ•°æ®æ¡†çš„å˜é‡åï¼Œé€šå¸¸ä¼šæŠ¥é”™æ‰¾ä¸åˆ°å¯¹è±¡</p>
<div class="section level1">
<h1>ğŸŒ°ï¼šé—®é¢˜æè¿°</h1>
<p>data: <a href="https://github.com/fivethirtyeight/data/tree/master/early-senate-polls">early senate poll</a></p>
<pre class="r"><code>library(tidyverse) # general tasks
library(broom) # tidy model output
library(ggthemes) # style the plots

poll_data &lt;- read_csv(&quot;https://raw.githubusercontent.com/fivethirtyeight/data/master/early-senate-polls/early-senate-polls.csv&quot;)

glimpse(poll_data)</code></pre>
<pre><code>## Observations: 107
## Variables: 4
## $ year                  &lt;int&gt; 2006, 2006, 2006, 2006, 2006, 2006, 2006...
## $ election_result       &lt;int&gt; -39, -10, -9, -16, 40, 10, -2, -41, -31,...
## $ presidential_approval &lt;int&gt; 46, 33, 32, 33, 53, 44, 37, 39, 42, 33, ...
## $ poll_average          &lt;int&gt; -28, -10, -1, -15, 39, 14, 2, -22, -27, ...</code></pre>
<p>background: <strong>there is a strong correlation between polling numbers and the ultimate result of an election</strong></p>
<div id="-" class="section level2">
<h2>æ„å»ºæ¨¡å‹ï¼š çº¿æ€§æ¨¡å‹</h2>
<pre class="r"><code>poll_lm &lt;- lm(election_result ~ poll_average, data = poll_data)

summary(poll_lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = election_result ~ poll_average, data = poll_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -29.4281  -5.0197   0.5601   6.1364  17.9357 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -0.89110    0.76969  -1.158     0.25    
## poll_average  1.04460    0.03777  27.659   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.93 on 105 degrees of freedom
## Multiple R-squared:  0.8793, Adjusted R-squared:  0.8782 
## F-statistic:   765 on 1 and 105 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div class="section level2">
<h2>å†™ä¸ªå‡½æ•°ç”»å‡ºå› å˜é‡å’Œè‡ªå˜é‡çš„å…³ç³»</h2>
<p>ç»“æœå‡ºç°äº†ä¸€ä¸ªä»¤æˆ‘è´¹è§£çš„æŠ¥é”™</p>
<blockquote>
<p><strong>Error in FUN(X[[i]], â€¦) : object â€˜poll_averageâ€™ not found</strong></p>
</blockquote>
<p>æˆ‘ä¸æ–­åœ°æ£€æŸ¥æˆ‘çš„æ‹¼å†™ï¼Œç›´åˆ°æˆ‘å¼€å§‹æ€€ç–‘äººç”Ÿ</p>
</div>
</div>
<div id="define-aesthetic-mappings-programatically" class="section level1">
<h1>è§£å†³åŠæ³•ï¼š<a href="http://ggplot2.tidyverse.org/reference/aes_.html"><strong>Define aesthetic mappings programatically</strong></a></h1>
<pre class="r"><code>plot_model &lt;- function(mod, explanatory, response, .fitted = &quot;.fitted&quot;) {
  augment(mod) %&gt;%
  ggplot() +
    geom_point(aes_string(x = explanatory, y = response), color = &quot;#2CA58D&quot;) +
    geom_line(aes_string(x = explanatory, y = .fitted), color = &quot;#033F63&quot;) +
    theme_solarized() +
    theme(axis.title = element_text()) +
    labs(x = &quot;Poll average&quot;, y = &quot;Election results&quot;)
}

plot_model(poll_lm, &quot;poll_average&quot;, &quot;election_result&quot;)</code></pre>
<p><img src="/post/2018-03-18-a-function-for-ggplot2-input-strings-for-aes_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Hello world]]></title>
    <link href="/2018/03/hello-world/"/>
    <id>/2018/03/hello-world/</id>
    <published>2018-03-15T00:00:00+00:00</published>
    <updated>2018-03-15T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p>Just say hello world!</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Why should I trust you ğŸ¤–?]]></title>
    <link href="/2018/02/why-should-i-trust-you/"/>
    <id>/2018/02/why-should-i-trust-you/</id>
    <published>2018-02-11T00:00:00+00:00</published>
    <updated>2018-02-11T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p>ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ä¸»è¦é›†ä¸­åœ¨æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–ä¸Š; æœ€å¥½çš„æ¨¡å‹é€šå¸¸æ˜¯é€šè¿‡åƒç²¾åº¦æˆ–è€…é”™è¯¯è¿™æ ·çš„æ€§èƒ½åº¦é‡æ¥é€‰æ‹©çš„ï¼Œè€Œä¸”å¦‚æœå®ƒé€šè¿‡äº†è¿™äº›æ€§èƒ½æ ‡å‡†çš„æŸäº›é˜ˆå€¼ï¼Œæˆ‘ä»¬å€¾å‘äºå‡è®¾ä¸€ä¸ªæ¨¡å‹æ˜¯è¶³å¤Ÿå¥½çš„ã€‚åœ¨æœºå™¨å­¦ä¹ çš„è®¸å¤šåº”ç”¨ä¸­ï¼Œç”¨æˆ·ä¼šä½¿ç”¨ä¸€ä¸ªæ¨¡å‹æ¥å¸®åŠ©åšå†³å®šï¼Œ ä¾‹å¦‚ï¼šä¸€ä½åŒ»ç”Ÿä¸ä¼šå¯¹ç—…äººè¿›è¡Œæ‰‹æœ¯ï¼Œä»…ä»…å› ä¸ºè¿™ä¸ªæ¨¡å‹è¯´ä¸åº”è¯¥è¿›è¡Œæ‰‹æœ¯ï¼Ÿ</p>
<p>ç”±äºå¤æ‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯é»‘ç›’å­ï¼Œè€Œä¸”å¤ªå¤æ‚ï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹åšå‡ºçš„åˆ†ç±»å†³å®šé€šå¸¸å¾ˆéš¾è¢«äººç±»çš„å¤§è„‘æ‰€ç†è§£ï¼Œä½†æ˜¯èƒ½å¤Ÿç†è§£å’Œè§£é‡Šè¿™äº›æ¨¡å‹å¯¹äºæé«˜æ¨¡å‹è´¨é‡ï¼Œæé«˜ä¿¡ä»»åº¦å’Œé€æ˜åº¦ä»¥åŠå‡å°‘åè§éå¸¸é‡è¦ï¼Œå› ä¸ºäººç±»å¾€å¾€å…·æœ‰è‰¯å¥½çš„ç›´è§‰å’Œå› æœæ¨ç†ï¼Œè¿™äº›éƒ½æ˜¯éš¾ä»¥åœ¨æ•°æ®è¯„ä¼°æŒ‡æ ‡ä¸­æ•è·ã€‚</p>
<p>å› æ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå½¢è±¡çš„ç†è§£å®ƒä»¬çš„å·¥ä½œåŸç†ï¼šä¸ºä»€ä¹ˆä¸€ä¸ªæ¨¡å‹å°†å…·æœ‰ç‰¹å®šæ ‡ç­¾çš„æ¡ˆä¾‹è¿›è¡Œå‡†ç¡®åˆ†ç±»ã€‚eg: ä¸ºä»€ä¹ˆä¸€ä¸ªä¹³è…ºè‚¿å—æ ·æœ¬è¢«å½’ç±»ä¸ºâ€œæ¶æ€§â€è€Œä¸æ˜¯â€œè‰¯æ€§ï¼Œä»…ä»…å› ä¸ºå®ƒé•¿å¾—ä¸‘å—ï¼Ÿ</p>
<blockquote>
<p><a href="https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime">Local Interpretable Model-Agnostic Explanations (LIME)</a> is an attempt to make these complex models at least partly understandable. The method has been published in <a href="https://arxiv.org/pdf/1602.04938.pdf">â€œWhy Should I Trust You?â€</a> Explaining the Predictions of Any Classifier. By Marco Tulio Ribeiro, Sameer Singh and Carlos Guestrin from the University of Washington in Seattle</p>
</blockquote>
<div id="how-lime-works" class="section level2">
<h2><strong>How LIME works</strong></h2>
<blockquote>
<p>lime is able to explain all models for which we can obtain prediction probabilities (in R, that is every model that works with predict(type = â€œprobâ€)). It makes use of the fact that linear models are easy to explain because they are based on linear relationships between features and class labels: The complex model function is approximated by locally fitting linear models to permutations of the original training set.On each permutation, a linear model is being fit and weights are given so that incorrect classification of instances that are more similar to the original data are penalized (positive weights support a decision, negative weights contradict them). This will give an approximation of how much (and in which way) each feature contributed to a decision made by the model</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7fa56fd7333.jpg" width="30%" /></p>
<blockquote>
<p>We take the image on the left and divide it into interpretable components</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7faba0d302a.jpg" width="30%" /></p>
<blockquote>
<p>we then generate a data set of perturbed instances by turning some of the interpretable components â€œoï¬€â€. For each perturbed instance, we get the probability that a tree frog is in the image according to the model.</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7fac3ca8787.jpg" width="30%" /></p>
<blockquote>
<p>We then learn a simple (linear) model on this data set, which is locally weightedâ€”that is, we care more about making mistakes in perturbed instances that are more similar to the original image</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7fac8382a86.jpg" width="30%" /></p>
<blockquote>
<p>the end, we present the superpixels with highest positive weights as an explanation, graying out everything else</p>
</blockquote>
<p><img src="https://i.loli.net/2018/02/11/5a7faf16f0320.jpg" width="30%" /></p>
<p>ğŸ¤–é¢„æµ‹è¿™å¼ å›¾æ˜¯ä¸ªæ ‘è›™æ˜¯å› ä¸ºè¿™ä¸ªéƒ¨åˆ†,æ‰€ä»¥ğŸ¤–é¢„æµ‹ç»“æœæ˜¯æ¯”è¾ƒå¯ä¿¡çš„ã€‚ <img src="https://i.loli.net/2018/02/11/5a7faebabe34e.jpg" style="display: block; margin: auto;" /></p>
<p>ğŸ¤–é¢„æµ‹è¿™å¼ å›¾æ˜¯å°çƒæ˜¯æ ¹æ®è¿™äº›éƒ¨åˆ†ï¼Œæ‰€ä»¥ğŸ¤–é¢„æµ‹ç»“æœæ˜¯ä¸å¯ä¿¡çš„ã€‚ <img src="https://i.loli.net/2018/02/11/5a7fb61ecb060.jpg" style="display: block; margin: auto;" /></p>
</div>
<div id="example-in-r" class="section level2">
<h2><strong>Example in R</strong></h2>
<div id="prepare-the-breast-cancer-data" class="section level3">
<h3>01.Prepare the breast cancer data</h3>
<p>This <strong>data</strong> of example comes from the book of <strong>R in action</strong></p>
<pre class="r"><code>loc &lt;- &quot;http://archive.ics.uci.edu/ml/machine-learning-databases/&quot;
ds  &lt;- &quot;breast-cancer-wisconsin/breast-cancer-wisconsin.data&quot;
url &lt;- paste(loc, ds, sep=&quot;&quot;)

breast &lt;- read.table(url, sep=&quot;,&quot;, header=FALSE, na.strings=&quot;?&quot;)
names(breast) &lt;- c(&quot;ID&quot;, &quot;clumpThickness&quot;, &quot;sizeUniformity&quot;,
                   &quot;shapeUniformity&quot;, &quot;maginalAdhesion&quot;, 
                   &quot;singleEpithelialCellSize&quot;, &quot;bareNuclei&quot;, 
                   &quot;blandChromatin&quot;, &quot;normalNucleoli&quot;, &quot;mitosis&quot;, &quot;class&quot;)

df &lt;- breast[-1]
df$class &lt;- factor(df$class, levels=c(2,4), 
                   labels=c(&quot;benign&quot;, &quot;malignant&quot;))

set.seed(1234)
train &lt;- sample(nrow(df), 0.7*nrow(df))
df.train &lt;- df[train,]
df.validate &lt;- df[-train,]
table(df.train$class)</code></pre>
<pre><code>## 
##    benign malignant 
##       329       160</code></pre>
<pre class="r"><code>table(df.validate$class)</code></pre>
<pre><code>## 
##    benign malignant 
##       129        81</code></pre>
</div>
<div id="create-decision-tree-model" class="section level3">
<h3>02 Create decision tree model</h3>
<pre class="r"><code>library(rpart)
set.seed(1234)
dtree &lt;- rpart(class ~ ., data=df.train, method=&quot;class&quot;,      
               parms=list(split=&quot;information&quot;))
dtree$cptable</code></pre>
<pre><code>##         CP nsplit rel error  xerror       xstd
## 1 0.800000      0   1.00000 1.00000 0.06484605
## 2 0.046875      1   0.20000 0.30625 0.04150018
## 3 0.012500      3   0.10625 0.20625 0.03467089
## 4 0.010000      4   0.09375 0.18125 0.03264401</code></pre>
<pre class="r"><code>plotcp(dtree)</code></pre>
<p><img src="/post/2018-02-11-why-should-i-trust-you_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>dtree.pruned &lt;- prune(dtree, cp=.0125)</code></pre>
</div>
<div id="predict" class="section level3">
<h3>03 predict</h3>
<pre class="r"><code>dtree.pred &lt;- predict(dtree.pruned, df.validate, type=&quot;class&quot;)
(dtree.perf &lt;- table(df.validate$class, dtree.pred, 
                    dnn=c(&quot;Actual&quot;, &quot;Predicted&quot;)))</code></pre>
<pre><code>##            Predicted
## Actual      benign malignant
##   benign       122         7
##   malignant      2        79</code></pre>
</div>
<div id="plot-decision-tree" class="section level3">
<h3>04 plot decision tree</h3>
<pre class="r"><code>#plot01
library(rpart.plot)
prp(dtree.pruned, type = 2, extra = 104,  
    fallen.leaves = TRUE, main=&quot;Decision Tree&quot;)
#plot02
library(partykit)</code></pre>
<p><img src="/post/2018-02-11-why-should-i-trust-you_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>library(dplyr)
dtree.pruned %&gt;% as.party() %&gt;% plot()</code></pre>
<p><img src="/post/2018-02-11-why-should-i-trust-you_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
</div>
<div id="lime-why-should-i-trust-you" class="section level3">
<h3>LIME: why should I trust you ğŸ¤–?</h3>
<pre class="r"><code>library(lime)
explainer &lt;- lime(df.train, model = dtree.pruned)

# Explain new observation
#[model_type](https://github.com/thomasp85/lime/blob/master/R/models.R)
model_type.rpart &lt;- function(x, ...) &#39;classification&#39;#defined model_type method
test.data &lt;- 
  df.validate %&gt;% 
  dplyr::select(-class) %&gt;% 
  head(3)
explanation &lt;- lime::explain(test.data, explainer, n_labels = 1, n_features = 2)

# The output is provided in a consistent tabular format and includes the
# output from the model.
head(explanation)</code></pre>
<pre><code>##       model_type case     label label_prob  model_r2 model_intercept
## 1 classification    3    benign  0.9933993 0.1754620      0.05039863
## 2 classification    3    benign  0.9933993 0.1754620      0.05039863
## 3 classification    4 malignant  0.9507042 0.2006329      0.53850056
## 4 classification    4 malignant  0.9507042 0.2006329      0.53850056
## 5 classification    5    benign  0.9933993 0.1871606      0.05372340
## 6 classification    5    benign  0.9933993 0.1871606      0.05372340
##   model_prediction                  feature feature_value feature_weight
## 1        0.4588963           blandChromatin             3   -0.001710722
## 2        0.4588963           sizeUniformity             1    0.410208409
## 3        0.9529770 singleEpithelialCellSize             3    0.003570030
## 4        0.9529770           sizeUniformity             8    0.410906399
## 5        0.4660418          maginalAdhesion             3   -0.004419457
## 6        0.4660418           sizeUniformity             1    0.416737849
##                        feature_desc                      data
## 1           2 &lt; blandChromatin &lt;= 3 3, 1, 1, 1, 2, 2, 3, 1, 1
## 2               sizeUniformity &lt;= 4 3, 1, 1, 1, 2, 2, 3, 1, 1
## 3 2 &lt; singleEpithelialCellSize &lt;= 4 6, 8, 8, 1, 3, 4, 3, 7, 1
## 4                4 &lt; sizeUniformity 6, 8, 8, 1, 3, 4, 3, 7, 1
## 5              maginalAdhesion &lt;= 3 4, 1, 1, 3, 2, 1, 3, 1, 1
## 6               sizeUniformity &lt;= 4 4, 1, 1, 3, 2, 1, 3, 1, 1
##               prediction
## 1 0.99339934, 0.00660066
## 2 0.99339934, 0.00660066
## 3 0.04929577, 0.95070423
## 4 0.04929577, 0.95070423
## 5 0.99339934, 0.00660066
## 6 0.99339934, 0.00660066</code></pre>
<pre class="r"><code># And can be visualised directly
plot_features(explanation)</code></pre>
<p><img src="/post/2018-02-11-why-should-i-trust-you_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
</div>
<div id="links" class="section level2">
<h2><strong>Links</strong></h2>
<ul>
<li><a href="http://archive.ics.uci.edu/ml/datasets/Chronic_Kidney_Disease">CKD data set</a></li>
<li><a href="https://github.com/marcotcr/lime">open-source Python code for LIME</a></li>
<li><a href="https://github.com/thomasp85/lime">R package for LIME</a></li>
</ul>
</div>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Conferences, webinars, podcasts and the likes]]></title>
    <link href="/page/conferences_podcasts_webinars/"/>
    <id>/page/conferences_podcasts_webinars/</id>
    <published>2018-02-01T16:06:06+02:00</published>
    <updated>2018-02-01T16:06:06+02:00</updated>
    <content type="html"><![CDATA[

<p>Here, you can find a list of all the talks I gave at conferences, webinars, podcasts, workshops, and all the other places you can and could hear me talk. :-)</p>

<h2 id="workshops-i-am-giving">Workshops I am giving</h2>

<ul>
<li><a href="https://shirinsplayground.netlify.com/2017/11/deep_learning_keras_tensorflow/">Workshop on Deep Learning with Keras and TensorFlow in R</a></li>
</ul>

<blockquote>
<p>I offer a workshop on deep learning with Keras and TensorFlow using R.
Date and place depend on who and how many people are interested, so please contact me either directly or via the workshop page: <a href="https://www.codecentric.de/schulung/deep-learning-mit-keras-und-tensorflow/">https://www.codecentric.de/schulung/deep-learning-mit-keras-und-tensorflow/</a> (the description is in German but I also offer to give the workshop in English).</p>
</blockquote>

<h2 id="upcoming-talks-webinars-podcasts-etc">Upcoming talks, webinars, podcasts, etc.</h2>

<ul>
<li><a href="https://shirinsplayground.netlify.com/2018/02/m3_2018/">Announcing my talk about explainability of machine learning models at Minds Mastering Machines Conference</a></li>
</ul>

<blockquote>
<p>On Wednesday, April 25th 2018 I am going to talk about explainability of machine learning models at the Minds Mastering Machines conference in Cologne.</p>
</blockquote>

<ul>
<li><a href="JAX 2018 talk announcement: Deep Learning - a Primer">JAX 2018 talk announcement: Deep Learning - a Primer</a></li>
</ul>

<blockquote>
<p>Deep Learning is one of the &ldquo;hot&rdquo; topics in the AI area â€“ a lot of hype, a lot of inflated expectation, but also quite some impressive success stories. As some AI experts already predict that Deep Learning will become &ldquo;Software 2.0&rdquo;, it might be a good time to have a closer look at the topic. In this session I will try to give a comprehensive overview of Deep Learning. We will start with a bit of history and some theoretical foundations that we will use to create a little Deep Learning taxonomy. Then we will have a look at current and upcoming application areas: Where can we apply Deep Learning successfully and what does it differentiate from other approaches? Afterwards we will examine the ecosystem: Which tools and libraries are available? What are their strengths and weaknesses? And to complete the session, we will look into some practical code examples and the typical pitfalls of Deep Learning. After this session you will have a much better idea of the why, what and how of Deep Learning, including if and how you might want to apply it to your own work. <a href="https://jax.de/big-data-machine-learning/deep-learning-a-primer/">https://jax.de/big-data-machine-learning/deep-learning-a-primer/</a></p>
</blockquote>

<h2 id="past-talks-webinars-podcasts-etc">Past talks, webinars, podcasts, etc.</h2>

<ul>
<li><a href="https://shirinsplayground.netlify.com/2018/02/herr_mies_wills_wissen/">I talk about machine learning with Daniel Mies (Podcast in German, though)</a></li>
</ul>

<blockquote>
<p>In January 2018 I was interviewed for a tech podcast where I talked about machine learning, neural nets, why I love R and Rstudio and how I became a Data Scientist.</p>
</blockquote>

<ul>
<li><a href="https://shirinsplayground.netlify.com/2017/12/lime_sketchnotes/">Explaining Predictions of Machine Learning Models with LIME - MÃ¼nster Data Science Meetup</a></li>
</ul>

<blockquote>
<p>In December 2017 I talked about Explaining Predictions of Machine Learning Models with LIME at the MÃ¼nster Data Science Meetup.</p>
</blockquote>

<ul>
<li><a href="https://shiring.github.io/blogging/2017/09/20/webinar_biology_to_data_science">From Biology to Industry. A Bloggerâ€™s Journey to Data Science</a></li>
</ul>

<blockquote>
<p>In September 2017 I gave a webinar for the Applied Epidemiology Didactic of the University of Wisconsin - Madison titled â€œFrom Biology to Industry. A Bloggerâ€™s Journey to Data Science.â€
I talked about how blogging about R and Data Science helped me become a Data Scientist. I also gave a short introduction to Machine Learning, Big Data and Neural Networks.</p>
</blockquote>

<ul>
<li><a href="https://shiring.github.io/machine_learning/2017/03/31/webinar_code">Building meaningful machine learning models for disease prediction</a></li>
</ul>

<blockquote>
<p>In March 2017 I gave a webinar for the ISDS R Group about my work on building machine-learning models to predict the course of different diseases. I went over building a model, evaluating its performance, and answering or addressing different disease related questions using machine learning. My talk covered the theory of machine learning as it is applied using R.</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Welcome to my page!]]></title>
    <link href="/page/about/"/>
    <id>/page/about/</id>
    <published>2017-09-12T16:06:06+02:00</published>
    <updated>2017-09-12T16:06:06+02:00</updated>
    <content type="html"><![CDATA[

<p><img src="/img/Bewerbungsfoto_klein.jpg" alt="" /></p>

<p>I&rsquo;m Shirin, a biologist turned bioinformatician turned data scientist.</p>

<p>I&rsquo;m especially interested in machine learning and data visualization. While I am using R most every day at work, I wanted to have an incentive to regularly explore other types of analyses and other types of data that I don&rsquo;t normally work with. I have also very often benefited from other people&rsquo;s published code in that it gave me ideas for my own work; and I hope that sharing my own analyses will inspire others as much as I often am by what can be be done with data.  It&rsquo;s amazing to me what can be learned from analyzing and visualizing data!</p>

<p>My tool of choice for data analysis so far has been R. I also organize the <a href="https://shiring.github.io/r_users_group/2017/05/20/muenster_r_user_group">MÃ¼nsteR R-users group on meetup.com</a>.</p>

<p><img src="http://res.cloudinary.com/shiring/image/upload/v1511852499/my_story_wml3zm.png" alt="My journey to Data Science" /></p>

<p>I love dancing and used to do competitive ballroom and latin dancing. Even though I don&rsquo;t have time for that anymore, I still enjoy teaching &ldquo;social dances&rdquo; once a week with the Hochschulsport (university sports courses).</p>

<p>I created the R package <a href="https://github.com/ShirinG/exprAnalysis">exprAnalysis</a>, designed to streamline my RNA-seq data analysis pipeline. It is available via Github. Instructions for installation and usage can be found <a href="https://shiring.github.io/rna-seq/microarray/2016/09/28/exprAnalysis">here</a>.</p>

<p>This blog will showcase some of the analyses I have been doing with different data sets (all freely available). I will also host teaching materials for students to access in conjunction with R courses I am giving.</p>

<hr />

<h2 id="contact-me">Contact me:</h2>

<ul>
<li><a href="https://www.codecentric.de/team/shirin-glander/">Codecentric AG</a></li>
<li><a href="mailto:shirin.glander@gmail.com">Email</a></li>
<li><a href="http://www.xing.com/profile/Shirin_Glander">Xing</a></li>
<li><a href="http://de.linkedin.com/in/shirin-glander-01120881">Linkedin</a></li>
<li><a href="http://twitter.com/ShirinGlander">Twitter</a></li>
</ul>

<hr />

<p>Also check out <a href="http://www.R-bloggers.com">R-bloggers</a> for lots of cool R stuff!</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Find all my other posts on my old website!]]></title>
    <link href="/2017/07/find-all-my-other-posts-on-my-old-website/"/>
    <id>/2017/07/find-all-my-other-posts-on-my-old-website/</id>
    <published>2017-07-01T00:00:00+00:00</published>
    <updated>2017-07-01T00:00:00+00:00</updated>
    <content type="html"><![CDATA[<p>For all my other posts, see my old website:
<a href="https://shiring.github.io">shiring.github.io</a></p>
]]></content>
  </entry>
</feed>